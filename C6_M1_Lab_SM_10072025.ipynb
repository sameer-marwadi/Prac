{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9556fc2-58f0-478a-bda1-6e1a208dacfe",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f87ac4d-250f-4c39-ae9f-52218369c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing datasetimport numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec9e599-c301-471a-ac0e-cfcc6ee1bdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Target names: ['malignant' 'benign']\n",
      "Shape of data: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Display basic information\n",
    "print(\"Feature names:\", data.feature_names)\n",
    "print(\"Target names:\", data.target_names)\n",
    "print(\"Shape of data:\", data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a577df8-d2a9-4237-9fdc-a802e13e7e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (569, 30)\n",
      "Target shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(\"Data shape:\", X.shape)      \n",
    "print(\"Target shape:\", y.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08425144-de2c-4e3e-8a11-64ad39bede96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 samples:\n",
      "[[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      "  1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      "  6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      "  1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      "  4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 1.326e+03 8.474e-02 7.864e-02 8.690e-02\n",
      "  7.017e-02 1.812e-01 5.667e-02 5.435e-01 7.339e-01 3.398e+00 7.408e+01\n",
      "  5.225e-03 1.308e-02 1.860e-02 1.340e-02 1.389e-02 3.532e-03 2.499e+01\n",
      "  2.341e+01 1.588e+02 1.956e+03 1.238e-01 1.866e-01 2.416e-01 1.860e-01\n",
      "  2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 1.203e+03 1.096e-01 1.599e-01 1.974e-01\n",
      "  1.279e-01 2.069e-01 5.999e-02 7.456e-01 7.869e-01 4.585e+00 9.403e+01\n",
      "  6.150e-03 4.006e-02 3.832e-02 2.058e-02 2.250e-02 4.571e-03 2.357e+01\n",
      "  2.553e+01 1.525e+02 1.709e+03 1.444e-01 4.245e-01 4.504e-01 2.430e-01\n",
      "  3.613e-01 8.758e-02]\n",
      " [1.142e+01 2.038e+01 7.758e+01 3.861e+02 1.425e-01 2.839e-01 2.414e-01\n",
      "  1.052e-01 2.597e-01 9.744e-02 4.956e-01 1.156e+00 3.445e+00 2.723e+01\n",
      "  9.110e-03 7.458e-02 5.661e-02 1.867e-02 5.963e-02 9.208e-03 1.491e+01\n",
      "  2.650e+01 9.887e+01 5.677e+02 2.098e-01 8.663e-01 6.869e-01 2.575e-01\n",
      "  6.638e-01 1.730e-01]\n",
      " [2.029e+01 1.434e+01 1.351e+02 1.297e+03 1.003e-01 1.328e-01 1.980e-01\n",
      "  1.043e-01 1.809e-01 5.883e-02 7.572e-01 7.813e-01 5.438e+00 9.444e+01\n",
      "  1.149e-02 2.461e-02 5.688e-02 1.885e-02 1.756e-02 5.115e-03 2.254e+01\n",
      "  1.667e+01 1.522e+02 1.575e+03 1.374e-01 2.050e-01 4.000e-01 1.625e-01\n",
      "  2.364e-01 7.678e-02]]\n",
      "\n",
      "First 5 labels:\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Example: show first 5 samples\n",
    "print(\"\\nFirst 5 samples:\")\n",
    "print(X[:5])\n",
    "print(\"\\nFirst 5 labels:\")\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2cabc-c202-4dad-b3d3-05e8703b1691",
   "metadata": {},
   "source": [
    "### Step 2: Create a Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351f106e-1458-4854-9e7e-de2c2a2a6e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (364, 30)\n",
      "Validation data shape: (91, 30)\n",
      "Test data shape: (114, 30)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test first\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# Further split train data into train and validation\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training data shape:\", X_train_final.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Test data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c595d-a0a9-46a5-ab36-cc4806cefe12",
   "metadata": {},
   "source": [
    "### Step 3: Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3258ea5d-e33a-4d6d-b93b-dbd39fb55abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature means: [1.40471264e+01 1.91653022e+01 9.13701648e+01 6.47591484e+02\n",
      " 9.60922527e-02 1.02998297e-01 8.70270769e-02 4.77785467e-02\n",
      " 1.82185714e-01 6.28017857e-02 4.03676374e-01 1.19305165e+00\n",
      " 2.86391978e+00 4.05285852e+01 6.99515934e-03 2.52892088e-02\n",
      " 3.18794723e-02 1.18062060e-02 2.07265879e-02 3.77993764e-03\n",
      " 1.61566758e+01 2.54874725e+01 1.06528516e+02 8.69699725e+02\n",
      " 1.31652143e-01 2.51145797e-01 2.67870549e-01 1.13131838e-01\n",
      " 2.91921978e-01 8.39054121e-02]\n",
      "Feature variances: [1.22954150e+01 1.81027963e+01 5.82512659e+02 1.24745757e+05\n",
      " 2.05088538e-04 2.89073507e-03 6.37040418e-03 1.47979228e-03\n",
      " 8.25485400e-04 5.46820943e-05 9.02992540e-02 2.69574983e-01\n",
      " 4.86171181e+00 2.58132556e+03 9.85557768e-06 3.55065734e-04\n",
      " 9.57120932e-04 4.07752003e-05 7.12851177e-05 7.66343662e-06\n",
      " 2.33078435e+01 3.65929271e+01 1.12322841e+03 3.31510460e+05\n",
      " 5.39866671e-04 2.54118361e-02 4.24980368e-02 4.37443437e-03\n",
      " 4.22825144e-03 3.48062506e-04]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_final)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_final)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature means:\", scaler.mean_)\n",
    "print(\"Feature variances:\", scaler.var_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2948d00-f834-43ee-bada-eb8876554b3f",
   "metadata": {},
   "source": [
    "### Step 4: Build a Baseline Model (No Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e744f4ff-21cc-4cc6-98ac-4f335523d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.2798 - mae: 0.4242 - mse: 0.2798 - val_loss: 0.1783 - val_mae: 0.2971 - val_mse: 0.1783\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1253 - mae: 0.2737 - mse: 0.1253 - val_loss: 0.1134 - val_mae: 0.2642 - val_mse: 0.1134\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0893 - mae: 0.2387 - mse: 0.0893 - val_loss: 0.0956 - val_mae: 0.2187 - val_mse: 0.0956\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0699 - mae: 0.2078 - mse: 0.0699 - val_loss: 0.0853 - val_mae: 0.2090 - val_mse: 0.0853\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0597 - mae: 0.1892 - mse: 0.0597 - val_loss: 0.0803 - val_mae: 0.2003 - val_mse: 0.0803\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0500 - mae: 0.1722 - mse: 0.0500 - val_loss: 0.0825 - val_mae: 0.1993 - val_mse: 0.0825\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0434 - mae: 0.1614 - mse: 0.0434 - val_loss: 0.0777 - val_mae: 0.1885 - val_mse: 0.0777\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0381 - mae: 0.1493 - mse: 0.0381 - val_loss: 0.0745 - val_mae: 0.1847 - val_mse: 0.0745\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.1402 - mse: 0.0339 - val_loss: 0.0792 - val_mae: 0.1871 - val_mse: 0.0792\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - mae: 0.1348 - mse: 0.0315 - val_loss: 0.0698 - val_mae: 0.1758 - val_mse: 0.0698\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.1281 - mse: 0.0286 - val_loss: 0.0656 - val_mae: 0.1719 - val_mse: 0.0656\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - mae: 0.1222 - mse: 0.0263 - val_loss: 0.0682 - val_mae: 0.1689 - val_mse: 0.0682\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - mae: 0.1120 - mse: 0.0228 - val_loss: 0.0673 - val_mae: 0.1658 - val_mse: 0.0673\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.1082 - mse: 0.0214 - val_loss: 0.0680 - val_mae: 0.1660 - val_mse: 0.0680\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.1017 - mse: 0.0197 - val_loss: 0.0656 - val_mae: 0.1591 - val_mse: 0.0656\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0178 - mae: 0.0966 - mse: 0.0178 - val_loss: 0.0605 - val_mae: 0.1572 - val_mse: 0.0605\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0956 - mse: 0.0171 - val_loss: 0.0605 - val_mae: 0.1563 - val_mse: 0.0605\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0162 - mae: 0.0919 - mse: 0.0162 - val_loss: 0.0584 - val_mae: 0.1540 - val_mse: 0.0584\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0887 - mse: 0.0154 - val_loss: 0.0595 - val_mae: 0.1508 - val_mse: 0.0595\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0835 - mse: 0.0137 - val_loss: 0.0565 - val_mae: 0.1472 - val_mse: 0.0565\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0789 - mse: 0.0124 - val_loss: 0.0568 - val_mae: 0.1453 - val_mse: 0.0568\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0750 - mse: 0.0115 - val_loss: 0.0563 - val_mae: 0.1444 - val_mse: 0.0563\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0754 - mse: 0.0114 - val_loss: 0.0581 - val_mae: 0.1466 - val_mse: 0.0581\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0734 - mse: 0.0104 - val_loss: 0.0527 - val_mae: 0.1409 - val_mse: 0.0527\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0683 - mse: 0.0096 - val_loss: 0.0524 - val_mae: 0.1415 - val_mse: 0.0524\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0667 - mse: 0.0089 - val_loss: 0.0543 - val_mae: 0.1422 - val_mse: 0.0543\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.0634 - mse: 0.0083 - val_loss: 0.0526 - val_mae: 0.1388 - val_mse: 0.0526\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - mae: 0.0624 - mse: 0.0079 - val_loss: 0.0500 - val_mae: 0.1358 - val_mse: 0.0500\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - mae: 0.0601 - mse: 0.0074 - val_loss: 0.0510 - val_mae: 0.1362 - val_mse: 0.0510\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - mae: 0.0581 - mse: 0.0071 - val_loss: 0.0487 - val_mae: 0.1339 - val_mse: 0.0487\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - mae: 0.0613 - mse: 0.0072 - val_loss: 0.0496 - val_mae: 0.1347 - val_mse: 0.0496\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - mae: 0.0566 - mse: 0.0064 - val_loss: 0.0486 - val_mae: 0.1319 - val_mse: 0.0486\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0553 - mse: 0.0062 - val_loss: 0.0480 - val_mae: 0.1312 - val_mse: 0.0480\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - mae: 0.0528 - mse: 0.0058 - val_loss: 0.0481 - val_mae: 0.1312 - val_mse: 0.0481\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - mae: 0.0528 - mse: 0.0058 - val_loss: 0.0479 - val_mae: 0.1315 - val_mse: 0.0479\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0505 - mse: 0.0053 - val_loss: 0.0501 - val_mae: 0.1329 - val_mse: 0.0501\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - mae: 0.0508 - mse: 0.0051 - val_loss: 0.0485 - val_mae: 0.1344 - val_mse: 0.0485\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - mae: 0.0477 - mse: 0.0047 - val_loss: 0.0466 - val_mae: 0.1267 - val_mse: 0.0466\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0469 - mse: 0.0044 - val_loss: 0.0468 - val_mae: 0.1279 - val_mse: 0.0468\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0450 - mse: 0.0042 - val_loss: 0.0469 - val_mae: 0.1303 - val_mse: 0.0469\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0457 - mse: 0.0042 - val_loss: 0.0475 - val_mae: 0.1286 - val_mse: 0.0475\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - mae: 0.0455 - mse: 0.0041 - val_loss: 0.0472 - val_mae: 0.1282 - val_mse: 0.0472\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0436 - mse: 0.0038 - val_loss: 0.0493 - val_mae: 0.1342 - val_mse: 0.0493\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0432 - mse: 0.0037 - val_loss: 0.0479 - val_mae: 0.1310 - val_mse: 0.0479\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0416 - mse: 0.0035 - val_loss: 0.0463 - val_mae: 0.1294 - val_mse: 0.0463\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0427 - mse: 0.0036 - val_loss: 0.0429 - val_mae: 0.1245 - val_mse: 0.0429\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0430 - mse: 0.0038 - val_loss: 0.0435 - val_mae: 0.1232 - val_mse: 0.0435\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0449 - mse: 0.0038 - val_loss: 0.0422 - val_mae: 0.1201 - val_mse: 0.0422\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0405 - mse: 0.0032 - val_loss: 0.0457 - val_mae: 0.1255 - val_mse: 0.0457\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0423 - mse: 0.0033 - val_loss: 0.0461 - val_mae: 0.1301 - val_mse: 0.0461\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0417 - mse: 0.0032 - val_loss: 0.0459 - val_mae: 0.1231 - val_mse: 0.0459\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0393 - mse: 0.0031 - val_loss: 0.0433 - val_mae: 0.1224 - val_mse: 0.0433\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0350 - mse: 0.0024 - val_loss: 0.0453 - val_mae: 0.1233 - val_mse: 0.0453\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0347 - mse: 0.0024 - val_loss: 0.0428 - val_mae: 0.1199 - val_mse: 0.0428\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0353 - mse: 0.0024 - val_loss: 0.0430 - val_mae: 0.1194 - val_mse: 0.0430\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0352 - mse: 0.0023 - val_loss: 0.0442 - val_mae: 0.1233 - val_mse: 0.0442\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0335 - mse: 0.0023 - val_loss: 0.0451 - val_mae: 0.1269 - val_mse: 0.0451\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0333 - mse: 0.0022 - val_loss: 0.0435 - val_mae: 0.1212 - val_mse: 0.0435\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0306 - mse: 0.0018 - val_loss: 0.0434 - val_mae: 0.1189 - val_mse: 0.0434\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0016 - val_loss: 0.0428 - val_mae: 0.1233 - val_mse: 0.0428\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0279 - mse: 0.0016 - val_loss: 0.0439 - val_mae: 0.1232 - val_mse: 0.0439\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0286 - mse: 0.0017 - val_loss: 0.0431 - val_mae: 0.1192 - val_mse: 0.0431\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0017 - val_loss: 0.0407 - val_mae: 0.1181 - val_mse: 0.0407\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0017 - val_loss: 0.0416 - val_mae: 0.1176 - val_mse: 0.0416\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0317 - mse: 0.0019 - val_loss: 0.0438 - val_mae: 0.1247 - val_mse: 0.0438\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mae: 0.0334 - mse: 0.0021 - val_loss: 0.0435 - val_mae: 0.1221 - val_mse: 0.0435\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0295 - mse: 0.0017 - val_loss: 0.0423 - val_mae: 0.1232 - val_mse: 0.0423\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0300 - mse: 0.0017 - val_loss: 0.0437 - val_mae: 0.1244 - val_mse: 0.0437\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0322 - mse: 0.0019 - val_loss: 0.0423 - val_mae: 0.1220 - val_mse: 0.0423\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0017 - val_loss: 0.0410 - val_mae: 0.1180 - val_mse: 0.0410\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0013 - val_loss: 0.0425 - val_mae: 0.1216 - val_mse: 0.0425\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0296 - mse: 0.0015 - val_loss: 0.0441 - val_mae: 0.1237 - val_mse: 0.0441\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0270 - mse: 0.0014 - val_loss: 0.0410 - val_mae: 0.1188 - val_mse: 0.0410\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0243 - mse: 0.0011 - val_loss: 0.0429 - val_mae: 0.1243 - val_mse: 0.0429\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0241 - mse: 0.0011 - val_loss: 0.0397 - val_mae: 0.1179 - val_mse: 0.0397\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0232 - mse: 0.0011 - val_loss: 0.0421 - val_mae: 0.1197 - val_mse: 0.0421\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0265 - mse: 0.0013 - val_loss: 0.0418 - val_mae: 0.1204 - val_mse: 0.0418\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0254 - mse: 0.0014 - val_loss: 0.0419 - val_mae: 0.1233 - val_mse: 0.0419\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0343 - mse: 0.0025 - val_loss: 0.0403 - val_mae: 0.1187 - val_mse: 0.0403\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0385 - mse: 0.0029 - val_loss: 0.0435 - val_mae: 0.1278 - val_mse: 0.0435\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0427 - mse: 0.0038 - val_loss: 0.0431 - val_mae: 0.1347 - val_mse: 0.0431\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0398 - mse: 0.0029 - val_loss: 0.0418 - val_mae: 0.1228 - val_mse: 0.0418\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0379 - mse: 0.0031 - val_loss: 0.0451 - val_mae: 0.1215 - val_mse: 0.0451\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0426 - mse: 0.0035 - val_loss: 0.0416 - val_mae: 0.1249 - val_mse: 0.0416\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0391 - mse: 0.0030 - val_loss: 0.0382 - val_mae: 0.1154 - val_mse: 0.0382\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0326 - mse: 0.0022 - val_loss: 0.0462 - val_mae: 0.1259 - val_mse: 0.0462\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0371 - mse: 0.0025 - val_loss: 0.0387 - val_mae: 0.1224 - val_mse: 0.0387\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - mae: 0.0349 - mse: 0.0021 - val_loss: 0.0412 - val_mae: 0.1200 - val_mse: 0.0412\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0280 - mse: 0.0013 - val_loss: 0.0407 - val_mae: 0.1196 - val_mse: 0.0407\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0244 - mse: 0.0011 - val_loss: 0.0382 - val_mae: 0.1193 - val_mse: 0.0382\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0239 - mse: 0.0010 - val_loss: 0.0397 - val_mae: 0.1210 - val_mse: 0.0397\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0403 - val_mae: 0.1217 - val_mse: 0.0403\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9503e-04 - mae: 0.0220 - mse: 8.9503e-04 - val_loss: 0.0391 - val_mae: 0.1173 - val_mse: 0.0391\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5388e-04 - mae: 0.0238 - mse: 9.5388e-04 - val_loss: 0.0382 - val_mae: 0.1153 - val_mse: 0.0382\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4121e-04 - mae: 0.0210 - mse: 8.4121e-04 - val_loss: 0.0383 - val_mae: 0.1174 - val_mse: 0.0383\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0131e-04 - mae: 0.0221 - mse: 9.0131e-04 - val_loss: 0.0399 - val_mae: 0.1195 - val_mse: 0.0399\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0250 - mse: 0.0011 - val_loss: 0.0374 - val_mae: 0.1180 - val_mse: 0.0374\n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0274 - mse: 0.0013 - val_loss: 0.0419 - val_mae: 0.1234 - val_mse: 0.0419\n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1729e-04 - mae: 0.0210 - mse: 8.1729e-04 - val_loss: 0.0402 - val_mae: 0.1206 - val_mse: 0.0402\n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5052e-04 - mae: 0.0193 - mse: 6.5052e-04 - val_loss: 0.0407 - val_mae: 0.1202 - val_mse: 0.0407\n"
     ]
    }
   ],
   "source": [
    "baseline_model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_baseline = baseline_model.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc95d31a-c9c7-44b3-b146-f3f690fb9dea",
   "metadata": {},
   "source": [
    "### Step 5: Add Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76821411-f5bf-4bf6-bdf7-e316a05b306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.3922 - mae: 0.4779 - mse: 0.3922 - val_loss: 0.3424 - val_mae: 0.4991 - val_mse: 0.3424\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1750 - mae: 0.3197 - mse: 0.1750 - val_loss: 0.2440 - val_mae: 0.3995 - val_mse: 0.2440\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1402 - mae: 0.2817 - mse: 0.1402 - val_loss: 0.2669 - val_mae: 0.4300 - val_mse: 0.2669\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0960 - mae: 0.2333 - mse: 0.0960 - val_loss: 0.2614 - val_mae: 0.4374 - val_mse: 0.2614\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0825 - mae: 0.2212 - mse: 0.0825 - val_loss: 0.1937 - val_mae: 0.3707 - val_mse: 0.1937\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0594 - mae: 0.1940 - mse: 0.0594 - val_loss: 0.1776 - val_mae: 0.3600 - val_mse: 0.1776\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0681 - mae: 0.2033 - mse: 0.0681 - val_loss: 0.1540 - val_mae: 0.3366 - val_mse: 0.1540\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0646 - mae: 0.1972 - mse: 0.0646 - val_loss: 0.1296 - val_mae: 0.3088 - val_mse: 0.1296\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0606 - mae: 0.1890 - mse: 0.0606 - val_loss: 0.1126 - val_mae: 0.2870 - val_mse: 0.1126\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0512 - mae: 0.1750 - mse: 0.0512 - val_loss: 0.0981 - val_mae: 0.2654 - val_mse: 0.0981\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0495 - mae: 0.1685 - mse: 0.0495 - val_loss: 0.0945 - val_mae: 0.2638 - val_mse: 0.0945\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0453 - mae: 0.1678 - mse: 0.0453 - val_loss: 0.0812 - val_mae: 0.2338 - val_mse: 0.0812\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0460 - mae: 0.1656 - mse: 0.0460 - val_loss: 0.0775 - val_mae: 0.2278 - val_mse: 0.0775\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0511 - mae: 0.1671 - mse: 0.0511 - val_loss: 0.0688 - val_mae: 0.2089 - val_mse: 0.0688\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0467 - mae: 0.1673 - mse: 0.0467 - val_loss: 0.0651 - val_mae: 0.1991 - val_mse: 0.0651\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0389 - mae: 0.1501 - mse: 0.0389 - val_loss: 0.0709 - val_mae: 0.2130 - val_mse: 0.0709\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0476 - mae: 0.1635 - mse: 0.0476 - val_loss: 0.0634 - val_mae: 0.1959 - val_mse: 0.0634\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0349 - mae: 0.1423 - mse: 0.0349 - val_loss: 0.0577 - val_mae: 0.1773 - val_mse: 0.0577\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0333 - mae: 0.1394 - mse: 0.0333 - val_loss: 0.0575 - val_mae: 0.1743 - val_mse: 0.0575\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0438 - mae: 0.1593 - mse: 0.0438 - val_loss: 0.0569 - val_mae: 0.1734 - val_mse: 0.0569\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - mae: 0.1306 - mse: 0.0304 - val_loss: 0.0576 - val_mae: 0.1676 - val_mse: 0.0576\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0301 - mae: 0.1330 - mse: 0.0301 - val_loss: 0.0551 - val_mae: 0.1690 - val_mse: 0.0551\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0320 - mae: 0.1311 - mse: 0.0320 - val_loss: 0.0527 - val_mae: 0.1603 - val_mse: 0.0527\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - mae: 0.1425 - mse: 0.0358 - val_loss: 0.0541 - val_mae: 0.1693 - val_mse: 0.0541\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0402 - mae: 0.1448 - mse: 0.0402 - val_loss: 0.0518 - val_mae: 0.1665 - val_mse: 0.0518\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - mae: 0.1416 - mse: 0.0360 - val_loss: 0.0521 - val_mae: 0.1559 - val_mse: 0.0521\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - mae: 0.1250 - mse: 0.0323 - val_loss: 0.0515 - val_mae: 0.1537 - val_mse: 0.0515\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - mae: 0.1325 - mse: 0.0304 - val_loss: 0.0525 - val_mae: 0.1554 - val_mse: 0.0525\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0296 - mae: 0.1258 - mse: 0.0296 - val_loss: 0.0555 - val_mae: 0.1568 - val_mse: 0.0555\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.1270 - mse: 0.0303 - val_loss: 0.0633 - val_mae: 0.1640 - val_mse: 0.0633\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0373 - mae: 0.1342 - mse: 0.0373 - val_loss: 0.0537 - val_mae: 0.1494 - val_mse: 0.0537\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - mae: 0.1150 - mse: 0.0250 - val_loss: 0.0519 - val_mae: 0.1484 - val_mse: 0.0519\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0224 - mae: 0.1095 - mse: 0.0224 - val_loss: 0.0511 - val_mae: 0.1469 - val_mse: 0.0511\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - mae: 0.1255 - mse: 0.0319 - val_loss: 0.0561 - val_mae: 0.1631 - val_mse: 0.0561\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1220 - mse: 0.0274 - val_loss: 0.0513 - val_mae: 0.1474 - val_mse: 0.0513\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0249 - mae: 0.1181 - mse: 0.0249 - val_loss: 0.0534 - val_mae: 0.1538 - val_mse: 0.0534\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0267 - mae: 0.1165 - mse: 0.0267 - val_loss: 0.0498 - val_mae: 0.1438 - val_mse: 0.0498\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - mae: 0.1271 - mse: 0.0323 - val_loss: 0.0512 - val_mae: 0.1485 - val_mse: 0.0512\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0230 - mae: 0.1100 - mse: 0.0230 - val_loss: 0.0510 - val_mae: 0.1467 - val_mse: 0.0510\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - mae: 0.1190 - mse: 0.0268 - val_loss: 0.0498 - val_mae: 0.1507 - val_mse: 0.0498\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0255 - mae: 0.1165 - mse: 0.0255 - val_loss: 0.0478 - val_mae: 0.1421 - val_mse: 0.0478\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.1113 - mse: 0.0210 - val_loss: 0.0460 - val_mae: 0.1372 - val_mse: 0.0460\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0202 - mae: 0.1042 - mse: 0.0202 - val_loss: 0.0459 - val_mae: 0.1380 - val_mse: 0.0459\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0300 - mae: 0.1251 - mse: 0.0300 - val_loss: 0.0445 - val_mae: 0.1307 - val_mse: 0.0445\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0237 - mae: 0.1117 - mse: 0.0237 - val_loss: 0.0487 - val_mae: 0.1423 - val_mse: 0.0487\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.1097 - mse: 0.0214 - val_loss: 0.0504 - val_mae: 0.1358 - val_mse: 0.0504\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - mae: 0.1120 - mse: 0.0253 - val_loss: 0.0435 - val_mae: 0.1300 - val_mse: 0.0435\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.1163 - mse: 0.0257 - val_loss: 0.0441 - val_mae: 0.1333 - val_mse: 0.0441\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0199 - mae: 0.1021 - mse: 0.0199 - val_loss: 0.0428 - val_mae: 0.1260 - val_mse: 0.0428\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0252 - mae: 0.1119 - mse: 0.0252 - val_loss: 0.0456 - val_mae: 0.1340 - val_mse: 0.0456\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0980 - mse: 0.0175 - val_loss: 0.0518 - val_mae: 0.1537 - val_mse: 0.0518\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.1061 - mse: 0.0210 - val_loss: 0.0439 - val_mae: 0.1267 - val_mse: 0.0439\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0214 - mae: 0.1032 - mse: 0.0214 - val_loss: 0.0451 - val_mae: 0.1415 - val_mse: 0.0451\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0187 - mae: 0.0998 - mse: 0.0187 - val_loss: 0.0453 - val_mae: 0.1316 - val_mse: 0.0453\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0213 - mae: 0.1054 - mse: 0.0213 - val_loss: 0.0432 - val_mae: 0.1259 - val_mse: 0.0432\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - mae: 0.0917 - mse: 0.0155 - val_loss: 0.0428 - val_mae: 0.1295 - val_mse: 0.0428\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0234 - mae: 0.1016 - mse: 0.0234 - val_loss: 0.0426 - val_mae: 0.1268 - val_mse: 0.0426\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0175 - mae: 0.1026 - mse: 0.0175 - val_loss: 0.0432 - val_mae: 0.1299 - val_mse: 0.0432\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0315 - mae: 0.1251 - mse: 0.0315 - val_loss: 0.0447 - val_mae: 0.1344 - val_mse: 0.0447\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0171 - mae: 0.1001 - mse: 0.0171 - val_loss: 0.0484 - val_mae: 0.1422 - val_mse: 0.0484\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0191 - mae: 0.0993 - mse: 0.0191 - val_loss: 0.0481 - val_mae: 0.1386 - val_mse: 0.0481\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0280 - mae: 0.1217 - mse: 0.0280 - val_loss: 0.0447 - val_mae: 0.1283 - val_mse: 0.0447\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0159 - mae: 0.0929 - mse: 0.0159 - val_loss: 0.0433 - val_mae: 0.1249 - val_mse: 0.0433\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0207 - mae: 0.1030 - mse: 0.0207 - val_loss: 0.0472 - val_mae: 0.1349 - val_mse: 0.0472\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0211 - mae: 0.1112 - mse: 0.0211 - val_loss: 0.0450 - val_mae: 0.1311 - val_mse: 0.0450\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0153 - mae: 0.0923 - mse: 0.0153 - val_loss: 0.0458 - val_mae: 0.1300 - val_mse: 0.0458\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - mae: 0.0832 - mse: 0.0120 - val_loss: 0.0391 - val_mae: 0.1189 - val_mse: 0.0391\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0228 - mae: 0.1081 - mse: 0.0228 - val_loss: 0.0438 - val_mae: 0.1234 - val_mse: 0.0438\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0190 - mae: 0.1015 - mse: 0.0190 - val_loss: 0.0443 - val_mae: 0.1440 - val_mse: 0.0443\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0361 - mae: 0.1306 - mse: 0.0361 - val_loss: 0.0472 - val_mae: 0.1450 - val_mse: 0.0472\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0175 - mae: 0.0999 - mse: 0.0175 - val_loss: 0.0467 - val_mae: 0.1369 - val_mse: 0.0467\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0201 - mae: 0.0964 - mse: 0.0201 - val_loss: 0.0428 - val_mae: 0.1340 - val_mse: 0.0428\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0152 - mae: 0.0869 - mse: 0.0152 - val_loss: 0.0425 - val_mae: 0.1308 - val_mse: 0.0425\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0139 - mae: 0.0852 - mse: 0.0139 - val_loss: 0.0396 - val_mae: 0.1168 - val_mse: 0.0396\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0188 - mae: 0.0991 - mse: 0.0188 - val_loss: 0.0416 - val_mae: 0.1216 - val_mse: 0.0416\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.1054 - mse: 0.0209 - val_loss: 0.0440 - val_mae: 0.1227 - val_mse: 0.0440\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0140 - mae: 0.0885 - mse: 0.0140 - val_loss: 0.0409 - val_mae: 0.1279 - val_mse: 0.0409\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0153 - mae: 0.0839 - mse: 0.0153 - val_loss: 0.0408 - val_mae: 0.1198 - val_mse: 0.0408\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0168 - mae: 0.0876 - mse: 0.0168 - val_loss: 0.0400 - val_mae: 0.1186 - val_mse: 0.0400\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0954 - mse: 0.0181 - val_loss: 0.0414 - val_mae: 0.1247 - val_mse: 0.0414\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0147 - mae: 0.0812 - mse: 0.0147 - val_loss: 0.0406 - val_mae: 0.1228 - val_mse: 0.0406\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.1029 - mse: 0.0188 - val_loss: 0.0413 - val_mae: 0.1214 - val_mse: 0.0413\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0907 - mse: 0.0154 - val_loss: 0.0404 - val_mae: 0.1197 - val_mse: 0.0404\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0937 - mse: 0.0168 - val_loss: 0.0391 - val_mae: 0.1214 - val_mse: 0.0391\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - mae: 0.0812 - mse: 0.0110 - val_loss: 0.0389 - val_mae: 0.1172 - val_mse: 0.0389\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0111 - mae: 0.0758 - mse: 0.0111 - val_loss: 0.0389 - val_mae: 0.1149 - val_mse: 0.0389\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0136 - mae: 0.0837 - mse: 0.0136 - val_loss: 0.0380 - val_mae: 0.1171 - val_mse: 0.0380\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0265 - mae: 0.1158 - mse: 0.0265 - val_loss: 0.0397 - val_mae: 0.1166 - val_mse: 0.0397\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0201 - mae: 0.1048 - mse: 0.0201 - val_loss: 0.0437 - val_mae: 0.1297 - val_mse: 0.0437\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0235 - mae: 0.1161 - mse: 0.0235 - val_loss: 0.0421 - val_mae: 0.1230 - val_mse: 0.0421\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0897 - mse: 0.0178 - val_loss: 0.0379 - val_mae: 0.1185 - val_mse: 0.0379\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0229 - mae: 0.1123 - mse: 0.0229 - val_loss: 0.0417 - val_mae: 0.1270 - val_mse: 0.0417\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.1022 - mse: 0.0197 - val_loss: 0.0475 - val_mae: 0.1365 - val_mse: 0.0475\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0280 - mae: 0.1052 - mse: 0.0280 - val_loss: 0.0404 - val_mae: 0.1143 - val_mse: 0.0404\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0333 - mae: 0.1315 - mse: 0.0333 - val_loss: 0.0471 - val_mae: 0.1443 - val_mse: 0.0471\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0135 - mae: 0.0854 - mse: 0.0135 - val_loss: 0.0435 - val_mae: 0.1288 - val_mse: 0.0435\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0152 - mae: 0.0913 - mse: 0.0152 - val_loss: 0.0387 - val_mae: 0.1122 - val_mse: 0.0387\n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0874 - mse: 0.0131 - val_loss: 0.0395 - val_mae: 0.1128 - val_mse: 0.0395\n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0150 - mae: 0.0851 - mse: 0.0150 - val_loss: 0.0375 - val_mae: 0.1094 - val_mse: 0.0375\n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0912 - mse: 0.0201 - val_loss: 0.0382 - val_mae: 0.1201 - val_mse: 0.0382\n"
     ]
    }
   ],
   "source": [
    "model_bn = keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_bn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_bn = model_bn.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d4b34-3baf-465b-ab93-ec5275e94076",
   "metadata": {},
   "source": [
    "### Step 6: Incorporate Regularization (L2 + Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3be054e-dc80-4c24-b261-2bb13ff03838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1753 - mae: 0.7770 - mse: 1.1647 - val_loss: 0.2526 - val_mae: 0.4149 - val_mse: 0.2421\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5200 - mae: 0.5672 - mse: 0.5095 - val_loss: 0.3033 - val_mae: 0.4773 - val_mse: 0.2927\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3733 - mae: 0.4740 - mse: 0.3628 - val_loss: 0.1889 - val_mae: 0.3430 - val_mse: 0.1783\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3009 - mae: 0.4197 - mse: 0.2904 - val_loss: 0.1345 - val_mae: 0.2692 - val_mse: 0.1240\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3025 - mae: 0.4099 - mse: 0.2920 - val_loss: 0.1407 - val_mae: 0.2794 - val_mse: 0.1303\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2699 - mae: 0.3900 - mse: 0.2594 - val_loss: 0.1487 - val_mae: 0.2918 - val_mse: 0.1383\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2133 - mae: 0.3569 - mse: 0.2029 - val_loss: 0.1287 - val_mae: 0.2722 - val_mse: 0.1183\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1976 - mae: 0.3508 - mse: 0.1872 - val_loss: 0.1227 - val_mae: 0.2711 - val_mse: 0.1123\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1797 - mae: 0.3264 - mse: 0.1694 - val_loss: 0.1172 - val_mae: 0.2646 - val_mse: 0.1069\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2009 - mae: 0.3483 - mse: 0.1905 - val_loss: 0.1073 - val_mae: 0.2487 - val_mse: 0.0970\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1871 - mae: 0.3289 - mse: 0.1767 - val_loss: 0.1008 - val_mae: 0.2351 - val_mse: 0.0905\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1778 - mae: 0.3157 - mse: 0.1675 - val_loss: 0.1066 - val_mae: 0.2453 - val_mse: 0.0963\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1567 - mae: 0.2950 - mse: 0.1464 - val_loss: 0.1143 - val_mae: 0.2593 - val_mse: 0.1040\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1372 - mae: 0.2747 - mse: 0.1270 - val_loss: 0.1085 - val_mae: 0.2508 - val_mse: 0.0982\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1458 - mae: 0.2813 - mse: 0.1356 - val_loss: 0.0935 - val_mae: 0.2258 - val_mse: 0.0833\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1641 - mae: 0.3000 - mse: 0.1539 - val_loss: 0.0978 - val_mae: 0.2381 - val_mse: 0.0876\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1359 - mae: 0.2800 - mse: 0.1257 - val_loss: 0.0981 - val_mae: 0.2388 - val_mse: 0.0879\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.2762 - mse: 0.1198 - val_loss: 0.1018 - val_mae: 0.2370 - val_mse: 0.0916\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1141 - mae: 0.2574 - mse: 0.1039 - val_loss: 0.0975 - val_mae: 0.2276 - val_mse: 0.0873\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1309 - mae: 0.2659 - mse: 0.1208 - val_loss: 0.0875 - val_mae: 0.2133 - val_mse: 0.0773\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1080 - mae: 0.2371 - mse: 0.0978 - val_loss: 0.0931 - val_mae: 0.2268 - val_mse: 0.0829\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1049 - mae: 0.2487 - mse: 0.0948 - val_loss: 0.0912 - val_mae: 0.2243 - val_mse: 0.0811\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1070 - mae: 0.2461 - mse: 0.0969 - val_loss: 0.0857 - val_mae: 0.2162 - val_mse: 0.0756\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1012 - mae: 0.2356 - mse: 0.0911 - val_loss: 0.0873 - val_mae: 0.2221 - val_mse: 0.0773\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1054 - mae: 0.2425 - mse: 0.0953 - val_loss: 0.0880 - val_mae: 0.2238 - val_mse: 0.0779\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1000 - mae: 0.2304 - mse: 0.0900 - val_loss: 0.0835 - val_mae: 0.2156 - val_mse: 0.0734\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1058 - mae: 0.2410 - mse: 0.0958 - val_loss: 0.0814 - val_mae: 0.2107 - val_mse: 0.0714\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1009 - mae: 0.2351 - mse: 0.0909 - val_loss: 0.0825 - val_mae: 0.2102 - val_mse: 0.0725\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1003 - mae: 0.2315 - mse: 0.0903 - val_loss: 0.0868 - val_mae: 0.2191 - val_mse: 0.0768\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0858 - mae: 0.2148 - mse: 0.0758 - val_loss: 0.0780 - val_mae: 0.2045 - val_mse: 0.0680\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0851 - mae: 0.2113 - mse: 0.0752 - val_loss: 0.0847 - val_mae: 0.2169 - val_mse: 0.0748\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0764 - mae: 0.2037 - mse: 0.0665 - val_loss: 0.0809 - val_mae: 0.2074 - val_mse: 0.0710\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0916 - mae: 0.2261 - mse: 0.0816 - val_loss: 0.0776 - val_mae: 0.2006 - val_mse: 0.0677\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0827 - mae: 0.2109 - mse: 0.0727 - val_loss: 0.0852 - val_mae: 0.2172 - val_mse: 0.0753\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0897 - mae: 0.2211 - mse: 0.0798 - val_loss: 0.0798 - val_mae: 0.2057 - val_mse: 0.0699\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0840 - mae: 0.2087 - mse: 0.0741 - val_loss: 0.0841 - val_mae: 0.2124 - val_mse: 0.0742\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0789 - mae: 0.2054 - mse: 0.0690 - val_loss: 0.0824 - val_mae: 0.2095 - val_mse: 0.0726\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0796 - mae: 0.2093 - mse: 0.0697 - val_loss: 0.0831 - val_mae: 0.2104 - val_mse: 0.0733\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0860 - mae: 0.2230 - mse: 0.0761 - val_loss: 0.0803 - val_mae: 0.2033 - val_mse: 0.0705\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0741 - mae: 0.1974 - mse: 0.0643 - val_loss: 0.0810 - val_mae: 0.2041 - val_mse: 0.0712\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0669 - mae: 0.1894 - mse: 0.0570 - val_loss: 0.0753 - val_mae: 0.1927 - val_mse: 0.0654\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0699 - mae: 0.1927 - mse: 0.0600 - val_loss: 0.0729 - val_mae: 0.1859 - val_mse: 0.0630\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0714 - mae: 0.1959 - mse: 0.0616 - val_loss: 0.0720 - val_mae: 0.1881 - val_mse: 0.0622\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0756 - mae: 0.2001 - mse: 0.0658 - val_loss: 0.0687 - val_mae: 0.1810 - val_mse: 0.0589\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0647 - mae: 0.1787 - mse: 0.0549 - val_loss: 0.0697 - val_mae: 0.1841 - val_mse: 0.0599\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0647 - mae: 0.1797 - mse: 0.0549 - val_loss: 0.0678 - val_mae: 0.1825 - val_mse: 0.0580\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0666 - mae: 0.1856 - mse: 0.0568 - val_loss: 0.0706 - val_mae: 0.1889 - val_mse: 0.0608\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0618 - mae: 0.1747 - mse: 0.0520 - val_loss: 0.0648 - val_mae: 0.1769 - val_mse: 0.0551\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.1666 - mse: 0.0474 - val_loss: 0.0641 - val_mae: 0.1752 - val_mse: 0.0544\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0673 - mae: 0.1910 - mse: 0.0576 - val_loss: 0.0691 - val_mae: 0.1867 - val_mse: 0.0593\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0580 - mae: 0.1695 - mse: 0.0483 - val_loss: 0.0629 - val_mae: 0.1720 - val_mse: 0.0532\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0595 - mae: 0.1700 - mse: 0.0498 - val_loss: 0.0604 - val_mae: 0.1679 - val_mse: 0.0507\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0657 - mae: 0.1814 - mse: 0.0560 - val_loss: 0.0697 - val_mae: 0.1889 - val_mse: 0.0600\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0736 - mae: 0.1944 - mse: 0.0639 - val_loss: 0.0655 - val_mae: 0.1793 - val_mse: 0.0558\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0570 - mae: 0.1654 - mse: 0.0473 - val_loss: 0.0718 - val_mae: 0.1919 - val_mse: 0.0621\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0556 - mae: 0.1647 - mse: 0.0459 - val_loss: 0.0641 - val_mae: 0.1729 - val_mse: 0.0544\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0660 - mae: 0.1816 - mse: 0.0563 - val_loss: 0.0619 - val_mae: 0.1687 - val_mse: 0.0523\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0582 - mae: 0.1704 - mse: 0.0485 - val_loss: 0.0629 - val_mae: 0.1705 - val_mse: 0.0533\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0564 - mae: 0.1675 - mse: 0.0467 - val_loss: 0.0699 - val_mae: 0.1845 - val_mse: 0.0603\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0484 - mae: 0.1531 - mse: 0.0388 - val_loss: 0.0643 - val_mae: 0.1719 - val_mse: 0.0547\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0551 - mae: 0.1577 - mse: 0.0455 - val_loss: 0.0567 - val_mae: 0.1548 - val_mse: 0.0471\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0553 - mae: 0.1653 - mse: 0.0457 - val_loss: 0.0601 - val_mae: 0.1668 - val_mse: 0.0505\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0499 - mae: 0.1557 - mse: 0.0403 - val_loss: 0.0603 - val_mae: 0.1667 - val_mse: 0.0507\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0541 - mae: 0.1627 - mse: 0.0445 - val_loss: 0.0551 - val_mae: 0.1517 - val_mse: 0.0455\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0557 - mae: 0.1629 - mse: 0.0461 - val_loss: 0.0625 - val_mae: 0.1741 - val_mse: 0.0529\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0535 - mae: 0.1649 - mse: 0.0440 - val_loss: 0.0588 - val_mae: 0.1622 - val_mse: 0.0493\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0515 - mae: 0.1547 - mse: 0.0420 - val_loss: 0.0596 - val_mae: 0.1636 - val_mse: 0.0501\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0533 - mae: 0.1665 - mse: 0.0437 - val_loss: 0.0617 - val_mae: 0.1694 - val_mse: 0.0522\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0506 - mae: 0.1571 - mse: 0.0411 - val_loss: 0.0614 - val_mae: 0.1672 - val_mse: 0.0519\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0474 - mae: 0.1501 - mse: 0.0379 - val_loss: 0.0573 - val_mae: 0.1563 - val_mse: 0.0478\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0452 - mae: 0.1493 - mse: 0.0357 - val_loss: 0.0655 - val_mae: 0.1796 - val_mse: 0.0560\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0477 - mae: 0.1519 - mse: 0.0382 - val_loss: 0.0618 - val_mae: 0.1726 - val_mse: 0.0523\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0452 - mae: 0.1439 - mse: 0.0358 - val_loss: 0.0591 - val_mae: 0.1680 - val_mse: 0.0496\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0523 - mae: 0.1583 - mse: 0.0429 - val_loss: 0.0578 - val_mae: 0.1669 - val_mse: 0.0483\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0440 - mae: 0.1448 - mse: 0.0346 - val_loss: 0.0622 - val_mae: 0.1786 - val_mse: 0.0528\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0445 - mae: 0.1475 - mse: 0.0351 - val_loss: 0.0566 - val_mae: 0.1579 - val_mse: 0.0472\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0466 - mae: 0.1430 - mse: 0.0372 - val_loss: 0.0573 - val_mae: 0.1580 - val_mse: 0.0479\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0471 - mae: 0.1507 - mse: 0.0377 - val_loss: 0.0637 - val_mae: 0.1777 - val_mse: 0.0543\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0410 - mae: 0.1367 - mse: 0.0316 - val_loss: 0.0560 - val_mae: 0.1591 - val_mse: 0.0466\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0486 - mae: 0.1483 - mse: 0.0393 - val_loss: 0.0549 - val_mae: 0.1571 - val_mse: 0.0455\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0437 - mae: 0.1458 - mse: 0.0344 - val_loss: 0.0554 - val_mae: 0.1570 - val_mse: 0.0460\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0426 - mae: 0.1362 - mse: 0.0332 - val_loss: 0.0570 - val_mae: 0.1597 - val_mse: 0.0477\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0424 - mae: 0.1400 - mse: 0.0330 - val_loss: 0.0529 - val_mae: 0.1439 - val_mse: 0.0436\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0449 - mae: 0.1431 - mse: 0.0356 - val_loss: 0.0631 - val_mae: 0.1761 - val_mse: 0.0538\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0443 - mae: 0.1431 - mse: 0.0350 - val_loss: 0.0579 - val_mae: 0.1610 - val_mse: 0.0486\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0406 - mae: 0.1352 - mse: 0.0313 - val_loss: 0.0543 - val_mae: 0.1507 - val_mse: 0.0450\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0392 - mae: 0.1318 - mse: 0.0299 - val_loss: 0.0538 - val_mae: 0.1510 - val_mse: 0.0445\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0397 - mae: 0.1317 - mse: 0.0304 - val_loss: 0.0596 - val_mae: 0.1696 - val_mse: 0.0504\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0400 - mae: 0.1344 - mse: 0.0308 - val_loss: 0.0599 - val_mae: 0.1670 - val_mse: 0.0507\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0400 - mae: 0.1359 - mse: 0.0308 - val_loss: 0.0593 - val_mae: 0.1657 - val_mse: 0.0501\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0363 - mae: 0.1272 - mse: 0.0270 - val_loss: 0.0596 - val_mae: 0.1678 - val_mse: 0.0504\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0391 - mae: 0.1321 - mse: 0.0299 - val_loss: 0.0553 - val_mae: 0.1530 - val_mse: 0.0461\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0389 - mae: 0.1346 - mse: 0.0296 - val_loss: 0.0552 - val_mae: 0.1538 - val_mse: 0.0460\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0383 - mae: 0.1323 - mse: 0.0291 - val_loss: 0.0531 - val_mae: 0.1469 - val_mse: 0.0439\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0355 - mae: 0.1273 - mse: 0.0264 - val_loss: 0.0549 - val_mae: 0.1502 - val_mse: 0.0457\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0359 - mae: 0.1240 - mse: 0.0267 - val_loss: 0.0531 - val_mae: 0.1438 - val_mse: 0.0439\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0370 - mae: 0.1233 - mse: 0.0278 - val_loss: 0.0550 - val_mae: 0.1533 - val_mse: 0.0458\n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0341 - mae: 0.1253 - mse: 0.0249 - val_loss: 0.0537 - val_mae: 0.1513 - val_mse: 0.0446\n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0355 - mae: 0.1240 - mse: 0.0263 - val_loss: 0.0536 - val_mae: 0.1475 - val_mse: 0.0444\n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0387 - mae: 0.1329 - mse: 0.0296 - val_loss: 0.0536 - val_mae: 0.1436 - val_mse: 0.0445\n"
     ]
    }
   ],
   "source": [
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.3\n",
    "\n",
    "model_reg = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_reg.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg = model_reg.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b88fb-190a-4eab-8f48-983e362f6e4a",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate and Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd152fb-9d97-46e9-bd1a-751e07e1e2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Model ===\n",
      "Train MAE: 0.0182, Train MSE: 0.0006\n",
      "Val   MAE: 0.1202, Val   MSE: 0.0407\n",
      "\n",
      "=== BatchNorm Model ===\n",
      "Train MAE: 0.0545, Train MSE: 0.0055\n",
      "Val   MAE: 0.1201, Val   MSE: 0.0382\n",
      "\n",
      "=== Regularized Model (L2 + Dropout) ===\n",
      "Train MAE: 0.1148, Train MSE: 0.0181\n",
      "Val   MAE: 0.1436, Val   MSE: 0.0445\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline Model ===\")\n",
    "train_scores = baseline_model.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores   = baseline_model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores[1]:.4f}, Train MSE: {train_scores[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores[1]:.4f}, Val   MSE: {val_scores[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== BatchNorm Model ===\")\n",
    "train_scores_bn = model_bn.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores_bn   = model_bn.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_bn[1]:.4f}, Train MSE: {train_scores_bn[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_bn[1]:.4f}, Val   MSE: {val_scores_bn[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "train_scores_reg = model_reg.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores_reg   = model_reg.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg[1]:.4f}, Train MSE: {train_scores_reg[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg[1]:.4f}, Val   MSE: {val_scores_reg[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3d4a09-c98a-4c3c-8260-e936892df5fd",
   "metadata": {},
   "source": [
    "### Step 8: Test Set for Final Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e66089-1988-4f8a-ba88-f109310a5a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Regularized Model on Test Set]\n",
      "Test MAE: 0.1367, Test MSE: 0.0365\n"
     ]
    }
   ],
   "source": [
    "test_scores_reg = model_reg.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"\\n[Regularized Model on Test Set]\")\n",
    "print(f\"Test MAE: {test_scores_reg[1]:.4f}, Test MSE: {test_scores_reg[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b79944-ff2d-4a3b-85d6-dfe4abd63e6b",
   "metadata": {},
   "source": [
    "### Step 9: Visualize Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec60af27-a569-4175-9779-e6c7ee5ac6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history_reg.history['loss'], label='Training Loss')\n",
    "plt.plot(history_reg.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Regularized Model Training vs. Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ff5b5-ab76-4432-93cf-78de541545a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
