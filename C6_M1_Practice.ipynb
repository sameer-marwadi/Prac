{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b70c20a-99bc-445d-a3d5-dce84693ff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.3.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (1.24.4)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m769.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.8.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.8.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow) (2.16.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.6/620.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.6-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.4/82.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.0/402.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, typing_extensions, termcolor, tensorboard-data-server, protobuf, opt_einsum, numpy, mdurl, markdown, google_pasta, gast, astunparse, absl-py, optree, ml_dtypes, markdown-it-py, h5py, grpcio, tensorboard, scikit-learn, rich, matplotlib, keras, tensorflow\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.24.3\n",
      "    Uninstalling protobuf-4.24.3:\n",
      "      Successfully uninstalled protobuf-4.24.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.10.0\n",
      "    Uninstalling h5py-3.10.0:\n",
      "      Successfully uninstalled h5py-3.10.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.1\n",
      "    Uninstalling scikit-learn-1.3.1:\n",
      "      Successfully uninstalled scikit-learn-1.3.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.8.0\n",
      "    Uninstalling matplotlib-3.8.0:\n",
      "      Successfully uninstalled matplotlib-3.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 h5py-3.14.0 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 matplotlib-3.10.6 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 numpy-1.26.4 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.32.1 rich-14.1.0 scikit-learn-1.7.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 typing_extensions-4.15.0 werkzeug-3.1.3 wrapt-1.17.3\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade tensorflow scikit-learn numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5976f-5687-4cae-87c1-c2fc2073c084",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d69de4-ed27-4ff0-94e8-b396846f49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing datasetimport numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff6b065-b85c-4f52-a31d-6f8b16e14fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (20640, 8)\n",
      "Target shape: (20640,)\n"
     ]
    }
   ],
   "source": [
    "cal_data = fetch_california_housing()\n",
    "X = cal_data.data\n",
    "y = cal_data.target\n",
    "\n",
    "print(\"Data shape:\", X.shape)        # Should be (20640, 8)\n",
    "print(\"Target shape:\", y.shape)      # Should be (20640,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad765966-3a4e-4462-aa57-91d8468733ff",
   "metadata": {},
   "source": [
    "### Step 2: Create a Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0d73b0-60c9-4732-8b65-cb3d818d6fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (13209, 8)\n",
      "Validation data shape: (3303, 8)\n",
      "Test data shape: (4128, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test first\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# Further split train data into train and validation\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training data shape:\", X_train_final.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc53cb-76ae-4b9a-9e5e-3c386acbdff6",
   "metadata": {},
   "source": [
    "### Step 3: Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "736135aa-bc4d-421a-8337-51e3c177bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature means: [ 3.86893364e+00  2.85672647e+01  5.42040408e+00  1.09433536e+00\n",
      "  1.42691650e+03  3.02944025e+00  3.56468476e+01 -1.19583303e+02]\n",
      "Feature variances: [3.57143560e+00 1.58482738e+02 4.48993988e+00 1.45205080e-01\n",
      " 1.29315681e+06 4.70353691e+01 4.55294423e+00 4.02078197e+00]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_final)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_final)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature means:\", scaler.mean_)\n",
    "print(\"Feature variances:\", scaler.var_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb5ba83-7e4b-44e4-9f79-c57faac9c035",
   "metadata": {},
   "source": [
    "### Step 4: Build a Baseline Model (No Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d40cb9f-b923-4c00-bb90-bf7c7299df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.0211 - mae: 0.6271 - mse: 1.0211 - val_loss: 0.4878 - val_mae: 0.4877 - val_mse: 0.4878\n",
      "Epoch 2/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4098 - mae: 0.4543 - mse: 0.4098 - val_loss: 0.4712 - val_mae: 0.4551 - val_mse: 0.4712\n",
      "Epoch 3/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3838 - mae: 0.4320 - mse: 0.3838 - val_loss: 0.6763 - val_mae: 0.4461 - val_mse: 0.6763\n",
      "Epoch 4/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3724 - mae: 0.4184 - mse: 0.3724 - val_loss: 0.3872 - val_mae: 0.4247 - val_mse: 0.3872\n",
      "Epoch 5/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3358 - mae: 0.4069 - mse: 0.3358 - val_loss: 0.3715 - val_mae: 0.4185 - val_mse: 0.3715\n",
      "Epoch 6/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3289 - mae: 0.3984 - mse: 0.3289 - val_loss: 0.4100 - val_mae: 0.4309 - val_mse: 0.4100\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3317 - mae: 0.3952 - mse: 0.3317 - val_loss: 0.7136 - val_mae: 0.4160 - val_mse: 0.7136\n",
      "Epoch 8/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3384 - mae: 0.3920 - mse: 0.3384 - val_loss: 1.6354 - val_mae: 0.4301 - val_mse: 1.6354\n",
      "Epoch 9/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3808 - mae: 0.3899 - mse: 0.3808 - val_loss: 0.3352 - val_mae: 0.4118 - val_mse: 0.3352\n",
      "Epoch 10/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2977 - mae: 0.3790 - mse: 0.2977 - val_loss: 0.3207 - val_mae: 0.3888 - val_mse: 0.3207\n",
      "Epoch 11/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2949 - mae: 0.3773 - mse: 0.2949 - val_loss: 0.3706 - val_mae: 0.3968 - val_mse: 0.3706\n",
      "Epoch 12/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2946 - mae: 0.3742 - mse: 0.2946 - val_loss: 0.3182 - val_mae: 0.3989 - val_mse: 0.3182\n",
      "Epoch 13/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2884 - mae: 0.3709 - mse: 0.2884 - val_loss: 0.3746 - val_mae: 0.3917 - val_mse: 0.3746\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2866 - mae: 0.3696 - mse: 0.2866 - val_loss: 0.3167 - val_mae: 0.3884 - val_mse: 0.3167\n",
      "Epoch 15/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2834 - mae: 0.3680 - mse: 0.2834 - val_loss: 0.3804 - val_mae: 0.3953 - val_mse: 0.3804\n",
      "Epoch 16/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3050 - mae: 0.3697 - mse: 0.3050 - val_loss: 0.5833 - val_mae: 0.3986 - val_mse: 0.5833\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2988 - mae: 0.3670 - mse: 0.2988 - val_loss: 0.3192 - val_mae: 0.3805 - val_mse: 0.3192\n",
      "Epoch 18/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2796 - mae: 0.3629 - mse: 0.2796 - val_loss: 0.3068 - val_mae: 0.3786 - val_mse: 0.3068\n",
      "Epoch 19/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2758 - mae: 0.3617 - mse: 0.2758 - val_loss: 0.3216 - val_mae: 0.3785 - val_mse: 0.3216\n",
      "Epoch 20/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2733 - mae: 0.3605 - mse: 0.2733 - val_loss: 0.3155 - val_mae: 0.3789 - val_mse: 0.3155\n",
      "Epoch 21/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2686 - mae: 0.3567 - mse: 0.2686 - val_loss: 0.3097 - val_mae: 0.3866 - val_mse: 0.3097\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2703 - mae: 0.3559 - mse: 0.2703 - val_loss: 0.5143 - val_mae: 0.3859 - val_mse: 0.5143\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2746 - mae: 0.3574 - mse: 0.2746 - val_loss: 0.3478 - val_mae: 0.3854 - val_mse: 0.3478\n",
      "Epoch 24/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2671 - mae: 0.3534 - mse: 0.2671 - val_loss: 0.3002 - val_mae: 0.3695 - val_mse: 0.3002\n",
      "Epoch 25/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2659 - mae: 0.3548 - mse: 0.2659 - val_loss: 0.3108 - val_mae: 0.3713 - val_mse: 0.3108\n",
      "Epoch 26/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2681 - mae: 0.3530 - mse: 0.2681 - val_loss: 0.4729 - val_mae: 0.3829 - val_mse: 0.4729\n",
      "Epoch 27/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2689 - mae: 0.3526 - mse: 0.2689 - val_loss: 0.3310 - val_mae: 0.3827 - val_mse: 0.3310\n",
      "Epoch 28/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2608 - mae: 0.3501 - mse: 0.2608 - val_loss: 0.3123 - val_mae: 0.3865 - val_mse: 0.3123\n",
      "Epoch 29/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2669 - mae: 0.3521 - mse: 0.2669 - val_loss: 0.3555 - val_mae: 0.3775 - val_mse: 0.3555\n",
      "Epoch 30/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2621 - mae: 0.3509 - mse: 0.2621 - val_loss: 0.3156 - val_mae: 0.3961 - val_mse: 0.3156\n",
      "Epoch 31/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2585 - mae: 0.3471 - mse: 0.2585 - val_loss: 0.3134 - val_mae: 0.3689 - val_mse: 0.3134\n",
      "Epoch 32/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2576 - mae: 0.3468 - mse: 0.2576 - val_loss: 0.3085 - val_mae: 0.3721 - val_mse: 0.3085\n",
      "Epoch 33/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2556 - mae: 0.3468 - mse: 0.2556 - val_loss: 0.2929 - val_mae: 0.3668 - val_mse: 0.2929\n",
      "Epoch 34/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2560 - mae: 0.3468 - mse: 0.2560 - val_loss: 0.3148 - val_mae: 0.3786 - val_mse: 0.3148\n",
      "Epoch 35/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2573 - mae: 0.3465 - mse: 0.2573 - val_loss: 0.3448 - val_mae: 0.3710 - val_mse: 0.3448\n",
      "Epoch 36/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2530 - mae: 0.3429 - mse: 0.2530 - val_loss: 0.2866 - val_mae: 0.3655 - val_mse: 0.2866\n",
      "Epoch 37/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2540 - mae: 0.3445 - mse: 0.2540 - val_loss: 0.2919 - val_mae: 0.3683 - val_mse: 0.2919\n",
      "Epoch 38/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2498 - mae: 0.3418 - mse: 0.2498 - val_loss: 0.3138 - val_mae: 0.3749 - val_mse: 0.3138\n",
      "Epoch 39/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2513 - mae: 0.3426 - mse: 0.2513 - val_loss: 0.2849 - val_mae: 0.3588 - val_mse: 0.2849\n",
      "Epoch 40/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2500 - mae: 0.3411 - mse: 0.2500 - val_loss: 0.3201 - val_mae: 0.4008 - val_mse: 0.3201\n",
      "Epoch 41/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2536 - mae: 0.3444 - mse: 0.2536 - val_loss: 0.3055 - val_mae: 0.3681 - val_mse: 0.3055\n",
      "Epoch 42/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2479 - mae: 0.3399 - mse: 0.2479 - val_loss: 0.2924 - val_mae: 0.3641 - val_mse: 0.2924\n",
      "Epoch 43/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2477 - mae: 0.3404 - mse: 0.2477 - val_loss: 0.2918 - val_mae: 0.3655 - val_mse: 0.2918\n",
      "Epoch 44/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2448 - mae: 0.3380 - mse: 0.2448 - val_loss: 0.3023 - val_mae: 0.3759 - val_mse: 0.3023\n",
      "Epoch 45/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2461 - mae: 0.3382 - mse: 0.2461 - val_loss: 0.3070 - val_mae: 0.3672 - val_mse: 0.3070\n",
      "Epoch 46/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2487 - mae: 0.3399 - mse: 0.2487 - val_loss: 0.3296 - val_mae: 0.3896 - val_mse: 0.3296\n",
      "Epoch 47/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2446 - mae: 0.3381 - mse: 0.2446 - val_loss: 0.2804 - val_mae: 0.3577 - val_mse: 0.2804\n",
      "Epoch 48/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2416 - mae: 0.3366 - mse: 0.2416 - val_loss: 0.2958 - val_mae: 0.3599 - val_mse: 0.2958\n",
      "Epoch 49/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2417 - mae: 0.3368 - mse: 0.2417 - val_loss: 0.2852 - val_mae: 0.3567 - val_mse: 0.2852\n",
      "Epoch 50/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2408 - mae: 0.3357 - mse: 0.2408 - val_loss: 0.3175 - val_mae: 0.3839 - val_mse: 0.3175\n",
      "Epoch 51/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2413 - mae: 0.3359 - mse: 0.2413 - val_loss: 0.3119 - val_mae: 0.3653 - val_mse: 0.3119\n",
      "Epoch 52/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2419 - mae: 0.3359 - mse: 0.2419 - val_loss: 0.2794 - val_mae: 0.3607 - val_mse: 0.2794\n",
      "Epoch 53/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2408 - mae: 0.3334 - mse: 0.2408 - val_loss: 0.2861 - val_mae: 0.3566 - val_mse: 0.2861\n",
      "Epoch 54/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2395 - mae: 0.3344 - mse: 0.2395 - val_loss: 0.2811 - val_mae: 0.3586 - val_mse: 0.2811\n",
      "Epoch 55/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2367 - mae: 0.3321 - mse: 0.2367 - val_loss: 0.2905 - val_mae: 0.3662 - val_mse: 0.2905\n",
      "Epoch 56/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2357 - mae: 0.3325 - mse: 0.2357 - val_loss: 0.2802 - val_mae: 0.3533 - val_mse: 0.2802\n",
      "Epoch 57/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2348 - mae: 0.3306 - mse: 0.2348 - val_loss: 0.3019 - val_mae: 0.3621 - val_mse: 0.3019\n",
      "Epoch 58/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2387 - mae: 0.3338 - mse: 0.2387 - val_loss: 0.3107 - val_mae: 0.3598 - val_mse: 0.3107\n",
      "Epoch 59/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2343 - mae: 0.3296 - mse: 0.2343 - val_loss: 0.2989 - val_mae: 0.3673 - val_mse: 0.2989\n",
      "Epoch 60/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2344 - mae: 0.3295 - mse: 0.2344 - val_loss: 0.2792 - val_mae: 0.3573 - val_mse: 0.2792\n",
      "Epoch 61/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2325 - mae: 0.3305 - mse: 0.2325 - val_loss: 0.2959 - val_mae: 0.3624 - val_mse: 0.2959\n",
      "Epoch 62/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2317 - mae: 0.3281 - mse: 0.2317 - val_loss: 0.2773 - val_mae: 0.3522 - val_mse: 0.2773\n",
      "Epoch 63/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2303 - mae: 0.3276 - mse: 0.2303 - val_loss: 0.2870 - val_mae: 0.3653 - val_mse: 0.2870\n",
      "Epoch 64/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2327 - mae: 0.3295 - mse: 0.2327 - val_loss: 0.2816 - val_mae: 0.3502 - val_mse: 0.2816\n",
      "Epoch 65/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2342 - mae: 0.3287 - mse: 0.2342 - val_loss: 0.2893 - val_mae: 0.3559 - val_mse: 0.2893\n",
      "Epoch 66/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2299 - mae: 0.3266 - mse: 0.2299 - val_loss: 0.2842 - val_mae: 0.3547 - val_mse: 0.2842\n",
      "Epoch 67/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2309 - mae: 0.3275 - mse: 0.2309 - val_loss: 0.2954 - val_mae: 0.3700 - val_mse: 0.2954\n",
      "Epoch 68/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2270 - mae: 0.3248 - mse: 0.2270 - val_loss: 0.2781 - val_mae: 0.3537 - val_mse: 0.2781\n",
      "Epoch 69/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2289 - mae: 0.3274 - mse: 0.2289 - val_loss: 0.2911 - val_mae: 0.3599 - val_mse: 0.2911\n",
      "Epoch 70/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2270 - mae: 0.3256 - mse: 0.2270 - val_loss: 0.2889 - val_mae: 0.3728 - val_mse: 0.2889\n",
      "Epoch 71/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2269 - mae: 0.3247 - mse: 0.2269 - val_loss: 0.2907 - val_mae: 0.3539 - val_mse: 0.2907\n",
      "Epoch 72/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2261 - mae: 0.3250 - mse: 0.2261 - val_loss: 0.2897 - val_mae: 0.3534 - val_mse: 0.2897\n",
      "Epoch 73/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2277 - mae: 0.3266 - mse: 0.2277 - val_loss: 0.2852 - val_mae: 0.3678 - val_mse: 0.2852\n",
      "Epoch 74/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2253 - mae: 0.3240 - mse: 0.2253 - val_loss: 0.2941 - val_mae: 0.3578 - val_mse: 0.2941\n",
      "Epoch 75/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2250 - mae: 0.3232 - mse: 0.2250 - val_loss: 0.2911 - val_mae: 0.3569 - val_mse: 0.2911\n",
      "Epoch 76/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2253 - mae: 0.3238 - mse: 0.2253 - val_loss: 0.3114 - val_mae: 0.3886 - val_mse: 0.3114\n",
      "Epoch 77/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2222 - mae: 0.3228 - mse: 0.2222 - val_loss: 0.2917 - val_mae: 0.3604 - val_mse: 0.2917\n",
      "Epoch 78/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2235 - mae: 0.3237 - mse: 0.2235 - val_loss: 0.2877 - val_mae: 0.3567 - val_mse: 0.2877\n",
      "Epoch 79/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2213 - mae: 0.3227 - mse: 0.2213 - val_loss: 0.2794 - val_mae: 0.3548 - val_mse: 0.2794\n",
      "Epoch 80/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2209 - mae: 0.3221 - mse: 0.2209 - val_loss: 0.2909 - val_mae: 0.3643 - val_mse: 0.2909\n",
      "Epoch 81/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2230 - mae: 0.3228 - mse: 0.2230 - val_loss: 0.2857 - val_mae: 0.3574 - val_mse: 0.2857\n",
      "Epoch 82/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2189 - mae: 0.3201 - mse: 0.2189 - val_loss: 0.3082 - val_mae: 0.3806 - val_mse: 0.3082\n",
      "Epoch 83/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2186 - mae: 0.3206 - mse: 0.2186 - val_loss: 0.3006 - val_mae: 0.3747 - val_mse: 0.3006\n",
      "Epoch 84/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2212 - mae: 0.3218 - mse: 0.2212 - val_loss: 0.2793 - val_mae: 0.3549 - val_mse: 0.2793\n",
      "Epoch 85/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2212 - mae: 0.3219 - mse: 0.2212 - val_loss: 0.2856 - val_mae: 0.3591 - val_mse: 0.2856\n",
      "Epoch 86/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2172 - mae: 0.3189 - mse: 0.2172 - val_loss: 0.2745 - val_mae: 0.3469 - val_mse: 0.2745\n",
      "Epoch 87/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2157 - mae: 0.3182 - mse: 0.2157 - val_loss: 0.2803 - val_mae: 0.3542 - val_mse: 0.2803\n",
      "Epoch 88/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2162 - mae: 0.3185 - mse: 0.2162 - val_loss: 0.2786 - val_mae: 0.3509 - val_mse: 0.2786\n",
      "Epoch 89/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2163 - mae: 0.3176 - mse: 0.2163 - val_loss: 0.3090 - val_mae: 0.3592 - val_mse: 0.3090\n",
      "Epoch 90/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2174 - mae: 0.3179 - mse: 0.2174 - val_loss: 0.2749 - val_mae: 0.3483 - val_mse: 0.2749\n",
      "Epoch 91/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2146 - mae: 0.3179 - mse: 0.2146 - val_loss: 0.3444 - val_mae: 0.3706 - val_mse: 0.3444\n",
      "Epoch 92/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2145 - mae: 0.3187 - mse: 0.2145 - val_loss: 0.2971 - val_mae: 0.3574 - val_mse: 0.2971\n",
      "Epoch 93/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2153 - mae: 0.3193 - mse: 0.2153 - val_loss: 0.3861 - val_mae: 0.3603 - val_mse: 0.3861\n",
      "Epoch 94/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2186 - mae: 0.3183 - mse: 0.2186 - val_loss: 0.2920 - val_mae: 0.3653 - val_mse: 0.2920\n",
      "Epoch 95/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2137 - mae: 0.3172 - mse: 0.2137 - val_loss: 0.2840 - val_mae: 0.3659 - val_mse: 0.2840\n",
      "Epoch 96/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2116 - mae: 0.3146 - mse: 0.2116 - val_loss: 0.2852 - val_mae: 0.3575 - val_mse: 0.2852\n",
      "Epoch 97/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2107 - mae: 0.3156 - mse: 0.2107 - val_loss: 0.3120 - val_mae: 0.3716 - val_mse: 0.3120\n",
      "Epoch 98/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2106 - mae: 0.3142 - mse: 0.2106 - val_loss: 0.2746 - val_mae: 0.3487 - val_mse: 0.2746\n",
      "Epoch 99/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2128 - mae: 0.3159 - mse: 0.2128 - val_loss: 0.2795 - val_mae: 0.3541 - val_mse: 0.2795\n",
      "Epoch 100/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2122 - mae: 0.3161 - mse: 0.2122 - val_loss: 0.2797 - val_mae: 0.3574 - val_mse: 0.2797\n"
     ]
    }
   ],
   "source": [
    "baseline_model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_baseline = baseline_model.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd780a-4c05-44f7-9ada-9cd3d8fc4d9a",
   "metadata": {},
   "source": [
    "### Step 5: Add Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5403e19-7a2c-4fbb-87fc-5eac2d784c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8759 - mae: 0.6483 - mse: 0.8759 - val_loss: 0.7403 - val_mae: 0.4858 - val_mse: 0.7403\n",
      "Epoch 2/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4275 - mae: 0.4730 - mse: 0.4275 - val_loss: 2.4989 - val_mae: 0.4652 - val_mse: 2.4989\n",
      "Epoch 3/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4015 - mae: 0.4543 - mse: 0.4015 - val_loss: 0.5384 - val_mae: 0.4780 - val_mse: 0.5384\n",
      "Epoch 4/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3835 - mae: 0.4453 - mse: 0.3835 - val_loss: 0.4226 - val_mae: 0.4548 - val_mse: 0.4226\n",
      "Epoch 5/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3737 - mae: 0.4390 - mse: 0.3737 - val_loss: 2.0782 - val_mae: 0.4745 - val_mse: 2.0782\n",
      "Epoch 6/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3676 - mae: 0.4306 - mse: 0.3676 - val_loss: 2.4189 - val_mae: 0.4701 - val_mse: 2.4189\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3642 - mae: 0.4280 - mse: 0.3642 - val_loss: 1.3922 - val_mae: 0.4671 - val_mse: 1.3922\n",
      "Epoch 8/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3612 - mae: 0.4286 - mse: 0.3612 - val_loss: 1.1038 - val_mae: 0.4412 - val_mse: 1.1038\n",
      "Epoch 9/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3539 - mae: 0.4207 - mse: 0.3539 - val_loss: 0.5461 - val_mae: 0.4135 - val_mse: 0.5461\n",
      "Epoch 10/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3606 - mae: 0.4263 - mse: 0.3606 - val_loss: 0.9056 - val_mae: 0.4707 - val_mse: 0.9056\n",
      "Epoch 11/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3440 - mae: 0.4156 - mse: 0.3440 - val_loss: 0.6310 - val_mae: 0.4655 - val_mse: 0.6310\n",
      "Epoch 12/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3466 - mae: 0.4182 - mse: 0.3466 - val_loss: 0.7646 - val_mae: 0.4571 - val_mse: 0.7646\n",
      "Epoch 13/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3530 - mae: 0.4235 - mse: 0.3530 - val_loss: 1.4242 - val_mae: 0.4380 - val_mse: 1.4242\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3448 - mae: 0.4164 - mse: 0.3448 - val_loss: 0.5635 - val_mae: 0.4781 - val_mse: 0.5635\n",
      "Epoch 15/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3406 - mae: 0.4138 - mse: 0.3406 - val_loss: 1.0354 - val_mae: 0.4626 - val_mse: 1.0354\n",
      "Epoch 16/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3371 - mae: 0.4106 - mse: 0.3371 - val_loss: 0.5752 - val_mae: 0.4379 - val_mse: 0.5752\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3385 - mae: 0.4116 - mse: 0.3385 - val_loss: 0.5084 - val_mae: 0.4615 - val_mse: 0.5084\n",
      "Epoch 18/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3402 - mae: 0.4125 - mse: 0.3402 - val_loss: 0.4880 - val_mae: 0.4583 - val_mse: 0.4880\n",
      "Epoch 19/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3369 - mae: 0.4119 - mse: 0.3369 - val_loss: 0.4676 - val_mae: 0.4448 - val_mse: 0.4676\n",
      "Epoch 20/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3367 - mae: 0.4104 - mse: 0.3367 - val_loss: 0.4819 - val_mae: 0.4448 - val_mse: 0.4819\n",
      "Epoch 21/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3356 - mae: 0.4108 - mse: 0.3356 - val_loss: 0.6515 - val_mae: 0.4459 - val_mse: 0.6515\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3365 - mae: 0.4096 - mse: 0.3365 - val_loss: 0.5390 - val_mae: 0.4584 - val_mse: 0.5390\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3331 - mae: 0.4062 - mse: 0.3331 - val_loss: 0.5187 - val_mae: 0.4518 - val_mse: 0.5187\n",
      "Epoch 24/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3272 - mae: 0.4042 - mse: 0.3272 - val_loss: 0.5159 - val_mae: 0.4647 - val_mse: 0.5159\n",
      "Epoch 25/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3394 - mae: 0.4125 - mse: 0.3394 - val_loss: 0.7845 - val_mae: 0.5085 - val_mse: 0.7845\n",
      "Epoch 26/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3342 - mae: 0.4108 - mse: 0.3342 - val_loss: 0.6592 - val_mae: 0.5055 - val_mse: 0.6592\n",
      "Epoch 27/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3328 - mae: 0.4099 - mse: 0.3328 - val_loss: 0.6542 - val_mae: 0.4360 - val_mse: 0.6542\n",
      "Epoch 28/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3286 - mae: 0.4072 - mse: 0.3286 - val_loss: 1.5864 - val_mae: 0.4586 - val_mse: 1.5864\n",
      "Epoch 29/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3237 - mae: 0.4031 - mse: 0.3237 - val_loss: 0.6812 - val_mae: 0.4971 - val_mse: 0.6812\n",
      "Epoch 30/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3276 - mae: 0.4053 - mse: 0.3276 - val_loss: 0.5249 - val_mae: 0.4644 - val_mse: 0.5249\n",
      "Epoch 31/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3288 - mae: 0.4060 - mse: 0.3288 - val_loss: 1.2979 - val_mae: 0.4482 - val_mse: 1.2979\n",
      "Epoch 32/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3231 - mae: 0.4034 - mse: 0.3231 - val_loss: 0.5993 - val_mae: 0.4913 - val_mse: 0.5993\n",
      "Epoch 33/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3198 - mae: 0.4016 - mse: 0.3198 - val_loss: 0.5064 - val_mae: 0.4457 - val_mse: 0.5064\n",
      "Epoch 34/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3231 - mae: 0.4012 - mse: 0.3231 - val_loss: 0.8987 - val_mae: 0.5226 - val_mse: 0.8987\n",
      "Epoch 35/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3203 - mae: 0.4005 - mse: 0.3203 - val_loss: 1.0681 - val_mae: 0.4607 - val_mse: 1.0681\n",
      "Epoch 36/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3233 - mae: 0.4009 - mse: 0.3233 - val_loss: 0.5595 - val_mae: 0.4520 - val_mse: 0.5595\n",
      "Epoch 37/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3180 - mae: 0.4005 - mse: 0.3180 - val_loss: 0.6136 - val_mae: 0.4684 - val_mse: 0.6136\n",
      "Epoch 38/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3184 - mae: 0.3984 - mse: 0.3184 - val_loss: 0.7321 - val_mae: 0.5241 - val_mse: 0.7321\n",
      "Epoch 39/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3161 - mae: 0.3972 - mse: 0.3161 - val_loss: 0.8589 - val_mae: 0.4389 - val_mse: 0.8589\n",
      "Epoch 40/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3167 - mae: 0.3984 - mse: 0.3167 - val_loss: 0.6644 - val_mae: 0.5299 - val_mse: 0.6644\n",
      "Epoch 41/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3097 - mae: 0.3938 - mse: 0.3097 - val_loss: 0.5660 - val_mae: 0.4846 - val_mse: 0.5660\n",
      "Epoch 42/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3136 - mae: 0.3967 - mse: 0.3136 - val_loss: 0.5970 - val_mae: 0.4715 - val_mse: 0.5970\n",
      "Epoch 43/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3153 - mae: 0.3974 - mse: 0.3153 - val_loss: 0.6913 - val_mae: 0.4903 - val_mse: 0.6913\n",
      "Epoch 44/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3134 - mae: 0.3958 - mse: 0.3134 - val_loss: 0.5584 - val_mae: 0.4760 - val_mse: 0.5584\n",
      "Epoch 45/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3115 - mae: 0.3943 - mse: 0.3115 - val_loss: 0.4943 - val_mae: 0.4593 - val_mse: 0.4943\n",
      "Epoch 46/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3174 - mae: 0.3990 - mse: 0.3174 - val_loss: 0.8095 - val_mae: 0.4391 - val_mse: 0.8095\n",
      "Epoch 47/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3068 - mae: 0.3914 - mse: 0.3068 - val_loss: 0.5039 - val_mae: 0.4570 - val_mse: 0.5039\n",
      "Epoch 48/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3102 - mae: 0.3926 - mse: 0.3102 - val_loss: 0.7011 - val_mae: 0.5164 - val_mse: 0.7011\n",
      "Epoch 49/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3131 - mae: 0.3965 - mse: 0.3131 - val_loss: 0.5657 - val_mae: 0.4533 - val_mse: 0.5657\n",
      "Epoch 50/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3113 - mae: 0.3920 - mse: 0.3113 - val_loss: 0.6038 - val_mae: 0.5074 - val_mse: 0.6038\n",
      "Epoch 51/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3041 - mae: 0.3904 - mse: 0.3041 - val_loss: 0.6568 - val_mae: 0.5096 - val_mse: 0.6568\n",
      "Epoch 52/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3047 - mae: 0.3891 - mse: 0.3047 - val_loss: 0.5455 - val_mae: 0.4491 - val_mse: 0.5455\n",
      "Epoch 53/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3071 - mae: 0.3937 - mse: 0.3071 - val_loss: 0.6300 - val_mae: 0.4942 - val_mse: 0.6300\n",
      "Epoch 54/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3025 - mae: 0.3874 - mse: 0.3025 - val_loss: 0.6693 - val_mae: 0.5316 - val_mse: 0.6693\n",
      "Epoch 55/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3070 - mae: 0.3895 - mse: 0.3070 - val_loss: 0.5950 - val_mae: 0.4483 - val_mse: 0.5950\n",
      "Epoch 56/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3064 - mae: 0.3924 - mse: 0.3064 - val_loss: 0.6193 - val_mae: 0.5112 - val_mse: 0.6193\n",
      "Epoch 57/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2980 - mae: 0.3859 - mse: 0.2980 - val_loss: 0.7843 - val_mae: 0.4728 - val_mse: 0.7843\n",
      "Epoch 58/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2978 - mae: 0.3840 - mse: 0.2978 - val_loss: 0.5547 - val_mae: 0.4813 - val_mse: 0.5547\n",
      "Epoch 59/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2976 - mae: 0.3838 - mse: 0.2976 - val_loss: 0.6741 - val_mae: 0.5418 - val_mse: 0.6741\n",
      "Epoch 60/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3022 - mae: 0.3900 - mse: 0.3022 - val_loss: 0.7610 - val_mae: 0.5257 - val_mse: 0.7610\n",
      "Epoch 61/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3015 - mae: 0.3877 - mse: 0.3015 - val_loss: 1.1054 - val_mae: 0.5319 - val_mse: 1.1054\n",
      "Epoch 62/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3025 - mae: 0.3879 - mse: 0.3025 - val_loss: 0.5262 - val_mae: 0.4621 - val_mse: 0.5262\n",
      "Epoch 63/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2994 - mae: 0.3866 - mse: 0.2994 - val_loss: 0.9622 - val_mae: 0.4365 - val_mse: 0.9622\n",
      "Epoch 64/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2996 - mae: 0.3869 - mse: 0.2996 - val_loss: 0.6148 - val_mae: 0.5025 - val_mse: 0.6148\n",
      "Epoch 65/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2997 - mae: 0.3854 - mse: 0.2997 - val_loss: 0.8049 - val_mae: 0.5043 - val_mse: 0.8049\n",
      "Epoch 66/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2924 - mae: 0.3816 - mse: 0.2924 - val_loss: 0.6062 - val_mae: 0.5064 - val_mse: 0.6062\n",
      "Epoch 67/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2953 - mae: 0.3837 - mse: 0.2953 - val_loss: 0.6333 - val_mae: 0.5167 - val_mse: 0.6333\n",
      "Epoch 68/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2947 - mae: 0.3830 - mse: 0.2947 - val_loss: 0.6218 - val_mae: 0.4744 - val_mse: 0.6218\n",
      "Epoch 69/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2997 - mae: 0.3856 - mse: 0.2997 - val_loss: 0.5132 - val_mae: 0.4385 - val_mse: 0.5132\n",
      "Epoch 70/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3006 - mae: 0.3880 - mse: 0.3006 - val_loss: 0.4101 - val_mae: 0.4264 - val_mse: 0.4101\n",
      "Epoch 71/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2974 - mae: 0.3842 - mse: 0.2974 - val_loss: 0.5550 - val_mae: 0.4812 - val_mse: 0.5550\n",
      "Epoch 72/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2941 - mae: 0.3834 - mse: 0.2941 - val_loss: 0.7037 - val_mae: 0.4502 - val_mse: 0.7037\n",
      "Epoch 73/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2963 - mae: 0.3856 - mse: 0.2963 - val_loss: 0.6115 - val_mae: 0.5025 - val_mse: 0.6115\n",
      "Epoch 74/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3007 - mae: 0.3855 - mse: 0.3007 - val_loss: 0.4623 - val_mae: 0.4384 - val_mse: 0.4623\n",
      "Epoch 75/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2999 - mae: 0.3862 - mse: 0.2999 - val_loss: 0.5910 - val_mae: 0.4827 - val_mse: 0.5910\n",
      "Epoch 76/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2975 - mae: 0.3849 - mse: 0.2975 - val_loss: 0.6735 - val_mae: 0.5090 - val_mse: 0.6735\n",
      "Epoch 77/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2970 - mae: 0.3820 - mse: 0.2970 - val_loss: 0.5928 - val_mae: 0.5082 - val_mse: 0.5928\n",
      "Epoch 78/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2916 - mae: 0.3824 - mse: 0.2916 - val_loss: 0.5760 - val_mae: 0.4778 - val_mse: 0.5760\n",
      "Epoch 79/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2945 - mae: 0.3835 - mse: 0.2945 - val_loss: 0.7036 - val_mae: 0.5414 - val_mse: 0.7036\n",
      "Epoch 80/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2888 - mae: 0.3810 - mse: 0.2888 - val_loss: 0.6008 - val_mae: 0.4695 - val_mse: 0.6008\n",
      "Epoch 81/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2931 - mae: 0.3819 - mse: 0.2931 - val_loss: 0.6883 - val_mae: 0.5323 - val_mse: 0.6883\n",
      "Epoch 82/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2884 - mae: 0.3784 - mse: 0.2884 - val_loss: 0.5895 - val_mae: 0.4918 - val_mse: 0.5895\n",
      "Epoch 83/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2994 - mae: 0.3827 - mse: 0.2994 - val_loss: 0.5087 - val_mae: 0.4518 - val_mse: 0.5087\n",
      "Epoch 84/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2928 - mae: 0.3780 - mse: 0.2928 - val_loss: 0.5519 - val_mae: 0.4680 - val_mse: 0.5519\n",
      "Epoch 85/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2959 - mae: 0.3821 - mse: 0.2959 - val_loss: 1.0852 - val_mae: 0.4502 - val_mse: 1.0852\n",
      "Epoch 86/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2968 - mae: 0.3860 - mse: 0.2968 - val_loss: 0.7142 - val_mae: 0.5074 - val_mse: 0.7142\n",
      "Epoch 87/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2916 - mae: 0.3815 - mse: 0.2916 - val_loss: 0.6096 - val_mae: 0.4999 - val_mse: 0.6096\n",
      "Epoch 88/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2951 - mae: 0.3827 - mse: 0.2951 - val_loss: 0.6531 - val_mae: 0.4861 - val_mse: 0.6531\n",
      "Epoch 89/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2892 - mae: 0.3778 - mse: 0.2892 - val_loss: 0.6341 - val_mae: 0.4899 - val_mse: 0.6341\n",
      "Epoch 90/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2959 - mae: 0.3845 - mse: 0.2959 - val_loss: 1.0011 - val_mae: 0.4476 - val_mse: 1.0011\n",
      "Epoch 91/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2918 - mae: 0.3804 - mse: 0.2918 - val_loss: 0.8201 - val_mae: 0.5419 - val_mse: 0.8201\n",
      "Epoch 92/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2888 - mae: 0.3789 - mse: 0.2888 - val_loss: 0.6467 - val_mae: 0.5038 - val_mse: 0.6467\n",
      "Epoch 93/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2934 - mae: 0.3824 - mse: 0.2934 - val_loss: 0.4790 - val_mae: 0.4319 - val_mse: 0.4790\n",
      "Epoch 94/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2874 - mae: 0.3784 - mse: 0.2874 - val_loss: 0.5652 - val_mae: 0.4680 - val_mse: 0.5652\n",
      "Epoch 95/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2872 - mae: 0.3771 - mse: 0.2872 - val_loss: 0.8913 - val_mae: 0.5152 - val_mse: 0.8913\n",
      "Epoch 96/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2903 - mae: 0.3786 - mse: 0.2903 - val_loss: 0.6213 - val_mae: 0.5084 - val_mse: 0.6213\n",
      "Epoch 97/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2921 - mae: 0.3805 - mse: 0.2921 - val_loss: 0.8338 - val_mae: 0.4786 - val_mse: 0.8338\n",
      "Epoch 98/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2866 - mae: 0.3777 - mse: 0.2866 - val_loss: 0.5784 - val_mae: 0.4827 - val_mse: 0.5784\n",
      "Epoch 99/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2856 - mae: 0.3762 - mse: 0.2856 - val_loss: 0.9917 - val_mae: 0.5470 - val_mse: 0.9917\n",
      "Epoch 100/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2849 - mae: 0.3734 - mse: 0.2849 - val_loss: 0.7263 - val_mae: 0.5100 - val_mse: 0.7263\n"
     ]
    }
   ],
   "source": [
    "model_bn = keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_bn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_bn = model_bn.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f1da5-3536-4caf-8362-f343ea9646fc",
   "metadata": {},
   "source": [
    "### Step 6: Incorporate Regularization (L2 + Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe1dfea-e850-49be-992b-72b2197e30a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.3445 - mae: 0.7831 - mse: 1.3364 - val_loss: 0.7958 - val_mae: 0.5288 - val_mse: 0.7877\n",
      "Epoch 2/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6578 - mae: 0.5722 - mse: 0.6496 - val_loss: 0.4550 - val_mae: 0.4706 - val_mse: 0.4468\n",
      "Epoch 3/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5519 - mae: 0.5298 - mse: 0.5437 - val_loss: 0.4438 - val_mae: 0.4539 - val_mse: 0.4355\n",
      "Epoch 4/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5247 - mae: 0.5125 - mse: 0.5163 - val_loss: 0.4774 - val_mae: 0.4537 - val_mse: 0.4690\n",
      "Epoch 5/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4896 - mae: 0.4954 - mse: 0.4812 - val_loss: 0.4696 - val_mae: 0.4473 - val_mse: 0.4611\n",
      "Epoch 6/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4799 - mae: 0.4877 - mse: 0.4714 - val_loss: 0.3946 - val_mae: 0.4394 - val_mse: 0.3860\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4662 - mae: 0.4805 - mse: 0.4576 - val_loss: 0.4772 - val_mae: 0.4607 - val_mse: 0.4687\n",
      "Epoch 8/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4403 - mae: 0.4672 - mse: 0.4317 - val_loss: 0.3861 - val_mae: 0.4347 - val_mse: 0.3775\n",
      "Epoch 9/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4400 - mae: 0.4660 - mse: 0.4314 - val_loss: 0.4191 - val_mae: 0.4347 - val_mse: 0.4104\n",
      "Epoch 10/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4317 - mae: 0.4620 - mse: 0.4230 - val_loss: 0.3870 - val_mae: 0.4229 - val_mse: 0.3782\n",
      "Epoch 11/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4251 - mae: 0.4559 - mse: 0.4163 - val_loss: 0.4693 - val_mae: 0.4295 - val_mse: 0.4604\n",
      "Epoch 12/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4174 - mae: 0.4496 - mse: 0.4085 - val_loss: 0.3730 - val_mae: 0.4239 - val_mse: 0.3640\n",
      "Epoch 13/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4065 - mae: 0.4444 - mse: 0.3975 - val_loss: 0.4109 - val_mae: 0.4308 - val_mse: 0.4017\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4039 - mae: 0.4404 - mse: 0.3947 - val_loss: 0.3609 - val_mae: 0.4123 - val_mse: 0.3516\n",
      "Epoch 15/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3982 - mae: 0.4392 - mse: 0.3890 - val_loss: 0.3678 - val_mae: 0.4222 - val_mse: 0.3584\n",
      "Epoch 16/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3907 - mae: 0.4353 - mse: 0.3813 - val_loss: 0.3583 - val_mae: 0.4088 - val_mse: 0.3488\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3824 - mae: 0.4290 - mse: 0.3729 - val_loss: 0.3618 - val_mae: 0.4120 - val_mse: 0.3523\n",
      "Epoch 18/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3833 - mae: 0.4279 - mse: 0.3737 - val_loss: 0.3497 - val_mae: 0.4060 - val_mse: 0.3401\n",
      "Epoch 19/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3797 - mae: 0.4263 - mse: 0.3700 - val_loss: 0.3447 - val_mae: 0.4065 - val_mse: 0.3350\n",
      "Epoch 20/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3729 - mae: 0.4225 - mse: 0.3632 - val_loss: 0.3360 - val_mae: 0.3946 - val_mse: 0.3262\n",
      "Epoch 21/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3656 - mae: 0.4203 - mse: 0.3557 - val_loss: 0.3319 - val_mae: 0.3908 - val_mse: 0.3220\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3696 - mae: 0.4202 - mse: 0.3596 - val_loss: 0.3498 - val_mae: 0.3937 - val_mse: 0.3397\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3660 - mae: 0.4185 - mse: 0.3560 - val_loss: 0.3421 - val_mae: 0.4020 - val_mse: 0.3320\n",
      "Epoch 24/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3721 - mae: 0.4186 - mse: 0.3620 - val_loss: 0.3510 - val_mae: 0.3987 - val_mse: 0.3409\n",
      "Epoch 25/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3616 - mae: 0.4161 - mse: 0.3515 - val_loss: 0.3373 - val_mae: 0.3971 - val_mse: 0.3272\n",
      "Epoch 26/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3620 - mae: 0.4136 - mse: 0.3519 - val_loss: 0.3384 - val_mae: 0.3936 - val_mse: 0.3282\n",
      "Epoch 27/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3676 - mae: 0.4157 - mse: 0.3574 - val_loss: 0.3329 - val_mae: 0.3959 - val_mse: 0.3227\n",
      "Epoch 28/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3600 - mae: 0.4140 - mse: 0.3497 - val_loss: 0.3325 - val_mae: 0.3954 - val_mse: 0.3222\n",
      "Epoch 29/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3582 - mae: 0.4107 - mse: 0.3479 - val_loss: 0.3279 - val_mae: 0.3899 - val_mse: 0.3176\n",
      "Epoch 30/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3542 - mae: 0.4100 - mse: 0.3439 - val_loss: 0.3417 - val_mae: 0.4026 - val_mse: 0.3314\n",
      "Epoch 31/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3581 - mae: 0.4138 - mse: 0.3477 - val_loss: 0.3394 - val_mae: 0.3970 - val_mse: 0.3289\n",
      "Epoch 32/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3522 - mae: 0.4093 - mse: 0.3418 - val_loss: 0.3298 - val_mae: 0.3944 - val_mse: 0.3195\n",
      "Epoch 33/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3619 - mae: 0.4119 - mse: 0.3515 - val_loss: 0.3317 - val_mae: 0.3978 - val_mse: 0.3213\n",
      "Epoch 34/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3536 - mae: 0.4103 - mse: 0.3431 - val_loss: 0.3310 - val_mae: 0.3917 - val_mse: 0.3205\n",
      "Epoch 35/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3477 - mae: 0.4081 - mse: 0.3372 - val_loss: 0.3245 - val_mae: 0.3839 - val_mse: 0.3140\n",
      "Epoch 36/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3562 - mae: 0.4128 - mse: 0.3456 - val_loss: 0.3304 - val_mae: 0.3942 - val_mse: 0.3198\n",
      "Epoch 37/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3503 - mae: 0.4096 - mse: 0.3398 - val_loss: 0.3239 - val_mae: 0.3911 - val_mse: 0.3134\n",
      "Epoch 38/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3440 - mae: 0.4078 - mse: 0.3335 - val_loss: 0.3306 - val_mae: 0.3900 - val_mse: 0.3200\n",
      "Epoch 39/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3533 - mae: 0.4099 - mse: 0.3427 - val_loss: 0.3234 - val_mae: 0.3856 - val_mse: 0.3129\n",
      "Epoch 40/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3481 - mae: 0.4089 - mse: 0.3376 - val_loss: 0.3334 - val_mae: 0.3918 - val_mse: 0.3229\n",
      "Epoch 41/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3454 - mae: 0.4060 - mse: 0.3349 - val_loss: 0.3236 - val_mae: 0.3883 - val_mse: 0.3131\n",
      "Epoch 42/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3507 - mae: 0.4089 - mse: 0.3402 - val_loss: 0.3229 - val_mae: 0.3891 - val_mse: 0.3124\n",
      "Epoch 43/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3414 - mae: 0.4017 - mse: 0.3309 - val_loss: 0.3243 - val_mae: 0.3848 - val_mse: 0.3137\n",
      "Epoch 44/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3413 - mae: 0.4050 - mse: 0.3308 - val_loss: 0.3211 - val_mae: 0.3863 - val_mse: 0.3105\n",
      "Epoch 45/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3396 - mae: 0.4030 - mse: 0.3290 - val_loss: 0.3190 - val_mae: 0.3875 - val_mse: 0.3084\n",
      "Epoch 46/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3394 - mae: 0.4016 - mse: 0.3288 - val_loss: 0.3221 - val_mae: 0.3922 - val_mse: 0.3115\n",
      "Epoch 47/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3371 - mae: 0.4018 - mse: 0.3264 - val_loss: 0.3181 - val_mae: 0.3736 - val_mse: 0.3075\n",
      "Epoch 48/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3382 - mae: 0.4020 - mse: 0.3275 - val_loss: 0.3185 - val_mae: 0.3829 - val_mse: 0.3078\n",
      "Epoch 49/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3369 - mae: 0.4016 - mse: 0.3263 - val_loss: 0.3201 - val_mae: 0.3846 - val_mse: 0.3094\n",
      "Epoch 50/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3418 - mae: 0.4043 - mse: 0.3311 - val_loss: 0.3137 - val_mae: 0.3806 - val_mse: 0.3031\n",
      "Epoch 51/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3363 - mae: 0.4002 - mse: 0.3256 - val_loss: 0.3302 - val_mae: 0.3963 - val_mse: 0.3194\n",
      "Epoch 52/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3399 - mae: 0.4033 - mse: 0.3292 - val_loss: 0.3153 - val_mae: 0.3847 - val_mse: 0.3045\n",
      "Epoch 53/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3369 - mae: 0.3997 - mse: 0.3261 - val_loss: 0.3108 - val_mae: 0.3784 - val_mse: 0.3000\n",
      "Epoch 54/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3418 - mae: 0.4024 - mse: 0.3310 - val_loss: 0.3139 - val_mae: 0.3844 - val_mse: 0.3031\n",
      "Epoch 55/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3379 - mae: 0.4035 - mse: 0.3271 - val_loss: 0.3152 - val_mae: 0.3872 - val_mse: 0.3045\n",
      "Epoch 56/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3339 - mae: 0.3994 - mse: 0.3231 - val_loss: 0.3148 - val_mae: 0.3845 - val_mse: 0.3041\n",
      "Epoch 57/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3355 - mae: 0.4013 - mse: 0.3247 - val_loss: 0.3192 - val_mae: 0.3789 - val_mse: 0.3085\n",
      "Epoch 58/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3333 - mae: 0.3984 - mse: 0.3226 - val_loss: 0.3132 - val_mae: 0.3786 - val_mse: 0.3025\n",
      "Epoch 59/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3349 - mae: 0.4011 - mse: 0.3242 - val_loss: 0.3126 - val_mae: 0.3764 - val_mse: 0.3018\n",
      "Epoch 60/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3345 - mae: 0.3997 - mse: 0.3237 - val_loss: 0.3165 - val_mae: 0.3777 - val_mse: 0.3057\n",
      "Epoch 61/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3343 - mae: 0.3986 - mse: 0.3235 - val_loss: 0.3130 - val_mae: 0.3738 - val_mse: 0.3023\n",
      "Epoch 62/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3362 - mae: 0.3996 - mse: 0.3254 - val_loss: 0.3171 - val_mae: 0.3833 - val_mse: 0.3063\n",
      "Epoch 63/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3399 - mae: 0.4024 - mse: 0.3291 - val_loss: 0.3482 - val_mae: 0.3833 - val_mse: 0.3375\n",
      "Epoch 64/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3409 - mae: 0.4002 - mse: 0.3302 - val_loss: 0.3198 - val_mae: 0.3777 - val_mse: 0.3090\n",
      "Epoch 65/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3349 - mae: 0.4001 - mse: 0.3242 - val_loss: 0.3091 - val_mae: 0.3727 - val_mse: 0.2984\n",
      "Epoch 66/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3259 - mae: 0.3962 - mse: 0.3152 - val_loss: 0.3124 - val_mae: 0.3812 - val_mse: 0.3016\n",
      "Epoch 67/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3312 - mae: 0.4001 - mse: 0.3204 - val_loss: 0.3346 - val_mae: 0.3932 - val_mse: 0.3239\n",
      "Epoch 68/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3321 - mae: 0.3970 - mse: 0.3213 - val_loss: 0.3108 - val_mae: 0.3768 - val_mse: 0.3001\n",
      "Epoch 69/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3341 - mae: 0.4011 - mse: 0.3233 - val_loss: 0.3200 - val_mae: 0.3872 - val_mse: 0.3092\n",
      "Epoch 70/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3363 - mae: 0.4014 - mse: 0.3254 - val_loss: 0.3089 - val_mae: 0.3711 - val_mse: 0.2980\n",
      "Epoch 71/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3332 - mae: 0.4008 - mse: 0.3223 - val_loss: 0.3099 - val_mae: 0.3783 - val_mse: 0.2990\n",
      "Epoch 72/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3286 - mae: 0.3977 - mse: 0.3177 - val_loss: 0.3094 - val_mae: 0.3784 - val_mse: 0.2984\n",
      "Epoch 73/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3277 - mae: 0.3966 - mse: 0.3167 - val_loss: 0.3203 - val_mae: 0.3914 - val_mse: 0.3094\n",
      "Epoch 74/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3300 - mae: 0.3994 - mse: 0.3191 - val_loss: 0.3067 - val_mae: 0.3759 - val_mse: 0.2958\n",
      "Epoch 75/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3331 - mae: 0.3998 - mse: 0.3222 - val_loss: 0.3112 - val_mae: 0.3798 - val_mse: 0.3003\n",
      "Epoch 76/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3319 - mae: 0.3982 - mse: 0.3209 - val_loss: 0.3082 - val_mae: 0.3766 - val_mse: 0.2972\n",
      "Epoch 77/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3282 - mae: 0.3967 - mse: 0.3172 - val_loss: 0.3087 - val_mae: 0.3780 - val_mse: 0.2977\n",
      "Epoch 78/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3304 - mae: 0.3971 - mse: 0.3194 - val_loss: 0.3217 - val_mae: 0.3853 - val_mse: 0.3108\n",
      "Epoch 79/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3345 - mae: 0.3992 - mse: 0.3236 - val_loss: 0.3071 - val_mae: 0.3809 - val_mse: 0.2962\n",
      "Epoch 80/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3275 - mae: 0.3961 - mse: 0.3166 - val_loss: 0.3139 - val_mae: 0.3792 - val_mse: 0.3030\n",
      "Epoch 81/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3315 - mae: 0.3970 - mse: 0.3206 - val_loss: 0.3115 - val_mae: 0.3807 - val_mse: 0.3006\n",
      "Epoch 82/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3318 - mae: 0.3984 - mse: 0.3209 - val_loss: 0.3063 - val_mae: 0.3743 - val_mse: 0.2954\n",
      "Epoch 83/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3296 - mae: 0.3951 - mse: 0.3187 - val_loss: 0.3049 - val_mae: 0.3765 - val_mse: 0.2940\n",
      "Epoch 84/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3272 - mae: 0.3971 - mse: 0.3163 - val_loss: 0.3084 - val_mae: 0.3737 - val_mse: 0.2975\n",
      "Epoch 85/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3260 - mae: 0.3948 - mse: 0.3151 - val_loss: 0.3054 - val_mae: 0.3743 - val_mse: 0.2945\n",
      "Epoch 86/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3270 - mae: 0.3967 - mse: 0.3160 - val_loss: 0.3106 - val_mae: 0.3815 - val_mse: 0.2997\n",
      "Epoch 87/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3292 - mae: 0.3980 - mse: 0.3181 - val_loss: 0.3105 - val_mae: 0.3692 - val_mse: 0.2994\n",
      "Epoch 88/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3305 - mae: 0.3980 - mse: 0.3194 - val_loss: 0.3107 - val_mae: 0.3816 - val_mse: 0.2996\n",
      "Epoch 89/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3270 - mae: 0.3967 - mse: 0.3159 - val_loss: 0.3199 - val_mae: 0.3852 - val_mse: 0.3089\n",
      "Epoch 90/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3291 - mae: 0.3976 - mse: 0.3180 - val_loss: 0.3105 - val_mae: 0.3846 - val_mse: 0.2994\n",
      "Epoch 91/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3285 - mae: 0.3961 - mse: 0.3174 - val_loss: 0.3114 - val_mae: 0.3780 - val_mse: 0.3003\n",
      "Epoch 92/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3238 - mae: 0.3958 - mse: 0.3128 - val_loss: 0.3073 - val_mae: 0.3759 - val_mse: 0.2964\n",
      "Epoch 93/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3273 - mae: 0.3943 - mse: 0.3163 - val_loss: 0.3089 - val_mae: 0.3739 - val_mse: 0.2979\n",
      "Epoch 94/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3321 - mae: 0.3980 - mse: 0.3211 - val_loss: 0.3111 - val_mae: 0.3928 - val_mse: 0.3001\n",
      "Epoch 95/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3319 - mae: 0.3973 - mse: 0.3209 - val_loss: 0.3137 - val_mae: 0.3737 - val_mse: 0.3027\n",
      "Epoch 96/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3298 - mae: 0.3960 - mse: 0.3189 - val_loss: 0.3139 - val_mae: 0.3935 - val_mse: 0.3030\n",
      "Epoch 97/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3294 - mae: 0.3993 - mse: 0.3185 - val_loss: 0.3078 - val_mae: 0.3815 - val_mse: 0.2970\n",
      "Epoch 98/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3214 - mae: 0.3955 - mse: 0.3105 - val_loss: 0.3128 - val_mae: 0.3821 - val_mse: 0.3019\n",
      "Epoch 99/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3250 - mae: 0.3958 - mse: 0.3141 - val_loss: 0.3092 - val_mae: 0.3823 - val_mse: 0.2983\n",
      "Epoch 100/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3275 - mae: 0.3952 - mse: 0.3166 - val_loss: 0.3025 - val_mae: 0.3691 - val_mse: 0.2916\n"
     ]
    }
   ],
   "source": [
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.3\n",
    "\n",
    "model_reg = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_reg.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg = model_reg.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408223d4-402b-44b4-b4c5-e67ee023ca47",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate and Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2efdea05-b10f-4ed8-8d1d-66d7a65b48bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Model ===\n",
      "Train MAE: 0.3107, Train MSE: 0.2014\n",
      "Val   MAE: 0.3574, Val   MSE: 0.2797\n",
      "\n",
      "=== BatchNorm Model ===\n",
      "Train MAE: 0.4835, Train MSE: 0.5547\n",
      "Val   MAE: 0.5100, Val   MSE: 0.7263\n",
      "\n",
      "=== Regularized Model (L2 + Dropout) ===\n",
      "Train MAE: 0.3472, Train MSE: 0.2630\n",
      "Val   MAE: 0.3691, Val   MSE: 0.2916\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline Model ===\")\n",
    "train_scores = baseline_model.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores   = baseline_model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores[1]:.4f}, Train MSE: {train_scores[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores[1]:.4f}, Val   MSE: {val_scores[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== BatchNorm Model ===\")\n",
    "train_scores_bn = model_bn.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores_bn   = model_bn.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_bn[1]:.4f}, Train MSE: {train_scores_bn[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_bn[1]:.4f}, Val   MSE: {val_scores_bn[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "train_scores_reg = model_reg.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores_reg   = model_reg.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg[1]:.4f}, Train MSE: {train_scores_reg[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg[1]:.4f}, Val   MSE: {val_scores_reg[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5e5ff-da1c-4fef-bc5e-68727a705ec7",
   "metadata": {},
   "source": [
    "### Step 8: Test Set for Final Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464a7b66-265b-4dee-9896-c856d7d449df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Regularized Model on Test Set]\n",
      "Test MAE: 0.3601, Test MSE: 0.2851\n"
     ]
    }
   ],
   "source": [
    "test_scores_reg = model_reg.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"\\n[Regularized Model on Test Set]\")\n",
    "print(f\"Test MAE: {test_scores_reg[1]:.4f}, Test MSE: {test_scores_reg[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad417d-c1be-494d-bec4-aaacf3f27b47",
   "metadata": {},
   "source": [
    "### Step 9: Visualize Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f35fa9b9-bdb0-4bfd-a644-1492202ba4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAj0xJREFUeJzs3Xd4k1X/BvA7u3tv2lIoZZchSzZoEQErCAoiyhJ8VVCGONAXFAf83LzgQHEAKltAlC2yt+w9S1tKd+keaZLn98dp0qa7NE1puT/XlSvtkyd5TvKkcOfke86RSZIkgYiIiIioDpLXdgOIiIiIiO4WwywRERER1VkMs0RERERUZzHMEhEREVGdxTBLRERERHUWwywRERER1VkMs0RERERUZzHMEhEREVGdxTBLRERERHUWwyxRLdm9ezdkMhl2795t0ccdO3YsgoKCLPqYFbl58yZkMhmWLFli1eNWRVBQEMaOHXtX95XJZHjvvfcs2p67sWTJEshkMty8ebPK962p99v9pPj7oCrnozrvv7LUxt860b2IYZbqHeN/MMaLUqlEgwYNMHbsWMTExNR28+5rxkAlk8nw66+/lrpP9+7dIZPJ0Lp1ayu37u716dPH7D1X1uVeCMT3g1dffRUymQzXrl0rc5933nkHMpkMZ86csWLLqu727dt47733cOrUqdpuionxw+tnn31W200hAgAoa7sBRDXl/fffR6NGjZCbm4vDhw9jyZIl2L9/P86dOwcbG5vabl6NWbx4MQwGQ203o1w2NjZYvnw5nn32WbPtN2/exMGDB+vc+XnnnXcwYcIE0+/Hjh3DggUL8Pbbb6NFixam7W3atKnWcZ577jk8/fTT0Gg0Vb5vr169kJOTA7VaXa021AWjRo3CwoULsXz5csyePbvUfVasWIHQ0NBqnZPqnI/Kun37NubMmYOgoCC0a9fO7La68LdOZA0Ms1RvDRgwAB07dgQATJgwAR4eHvj444+xceNGDB8+vJZbZ3lZWVmwt7eHSqWq7aZUaODAgdi4cSOSkpLg4eFh2r58+XJ4e3sjJCQEd+7cqcUWVk2/fv3MfrexscGCBQvQr18/9OnTp8z7Gc9ZZSkUCigUirtqo1wur3MfEu5Wly5d0KRJE6xYsaLUMHvo0CFERETg//7v/6p1nOqcD0uoC3/rRNbAMgO6b/Ts2RMAcP36dbPtly5dwpNPPgk3NzfY2NigY8eO2LhxY4n7nzlzBr1794atrS38/f3x4Ycf4ueffy5RM1fW18mVqZnbt28fnnrqKQQGBkKj0SAgIADTpk1DTk6O2X5jx46Fg4MDrl+/joEDB8LR0RGjRo0y3Va0jq68r8CL1rimpqZi6tSpCAgIgEajQZMmTfDxxx+X6PlJTU3F2LFj4ezsDBcXF4wZMwapqanlPq/iBg8eDI1GgzVr1phtX758OYYPH15qQNDpdPjggw8QHBwMjUaDoKAgvP3228jLyzPbT5IkfPjhh/D394ednR369u2L8+fPl9qOyj5nS3jvvfcgk8lw4cIFPPPMM3B1dUWPHj0AiPfW2LFj0bhxY9jY2MDHxwfjx49HcnKy2WOUVqMZFBSExx57DPv370fnzp1hY2ODxo0bY9myZWb3La1mtk+fPmjdujUuXLiAvn37ws7ODg0aNMAnn3xSov2RkZF4/PHHYW9vDy8vL0ybNg3btm2rsA537dq1kMlk2LNnT4nbvvvuO8hkMpw7dw4AEBcXh3HjxsHf3x8ajQa+vr4YPHjwXdUIjxo1CpcuXcKJEydK3LZ8+XLIZDKMHDkSWq0Ws2fPRocOHeDs7Ax7e3v07NkTu3btqvAYpZ2Pyr7/UlJSMGPGDISGhsLBwQFOTk4YMGAATp8+bdpn9+7d6NSpEwBg3LhxJf5uS6uZzcrKwmuvvWZ6Tzdr1gyfffYZJEky208mk2Hy5MnYsGEDWrduDY1Gg1atWmHr1q0VPu/KSkhIwPPPPw9vb2/Y2Nigbdu2WLp0aYn9Vq5ciQ4dOsDR0RFOTk4IDQ3F//73P9Pt+fn5mDNnDkJCQmBjYwN3d3f06NEDO3bssFhbqW5jzyzdN4z/4bi6upq2nT9/Ht27d0eDBg3w1ltvwd7eHqtXr8aQIUPw+++/44knngAAxMTEoG/fvpDJZJg5cybs7e3xww8/WPzrxTVr1iA7OxsvvfQS3N3dcfToUSxcuBC3bt0qEfx0Oh369++PHj164LPPPoOdnV2pj1n8K3AA+PXXX7Ft2zZ4eXkBALKzs9G7d2/ExMTgP//5DwIDA3Hw4EHMnDkTsbGxmD9/PgDxH/XgwYOxf/9+vPjii2jRogXWr1+PMWPGVOl52tnZYfDgwVixYgVeeuklAMDp06dx/vx5/PDDD6XWMU6YMAFLly7Fk08+iddeew1HjhzBvHnzcPHiRaxfv9603+zZs/Hhhx9i4MCBGDhwIE6cOIFHHnkEWq3W7PEq+5wt7amnnkJISAjmzp1rChg7duzAjRs3MG7cOPj4+OD8+fP4/vvvcf78eRw+fBgymazcx7x27RqefPJJPP/88xgzZgx++uknjB07Fh06dECrVq3Kve+dO3fw6KOPYujQoRg+fDjWrl2LN998E6GhoRgwYAAAEZAeeughxMbGYsqUKfDx8cHy5csrFfgGDRoEBwcHrF69Gr179za7bdWqVWjVqpWpPnrYsGE4f/48XnnlFQQFBSEhIQE7duxAVFRUlQc6jRo1CnPmzMHy5cvxwAMPmLbr9XqsXr0aPXv2RGBgIJKSkvDDDz9g5MiRmDhxIjIyMvDjjz+if//+OHr0aImv9itS2fffjRs3sGHDBjz11FNo1KgR4uPj8d1336F37964cOEC/Pz80KJFC7z//vuYPXs2XnjhBdMH8m7dupV6bEmS8Pjjj2PXrl14/vnn0a5dO2zbtg2vv/46YmJi8OWXX5rtv3//fqxbtw4vv/wyHB0dsWDBAgwbNgxRUVFwd3ev0vMuLicnB3369MG1a9cwefJkNGrUCGvWrMHYsWORmpqKKVOmABDv/ZEjR+Lhhx/Gxx9/DAC4ePEiDhw4YNrnvffew7x58zBhwgR07twZ6enp+Pfff3HixIkS34rQfUoiqmd+/vlnCYD0999/S4mJiVJ0dLS0du1aydPTU9JoNFJ0dLRp34cfflgKDQ2VcnNzTdsMBoPUrVs3KSQkxLTtlVdekWQymXTy5EnTtuTkZMnNzU0CIEVERJi2A5DefffdEu1q2LChNGbMGNPvu3btkgBIu3btMm3Lzs4ucb958+ZJMplMioyMNG0bM2aMBEB66623Suw/ZswYqWHDhmW8OpJ04MABSaVSSePHjzdt++CDDyR7e3vpypUrZvu+9dZbkkKhkKKioiRJkqQNGzZIAKRPPvnEtI9Op5N69uwpAZB+/vnnMo9b9DmvWbNG+uuvvySZTGZ67Ndff11q3LixJEmS1Lt3b6lVq1am+506dUoCIE2YMMHs8WbMmCEBkP755x9JkiQpISFBUqvV0qBBgySDwWDa7+2335YAmL3+lX3OklT2OS3LmjVrSpzbd999VwIgjRw5ssT+pZ33FStWSACkvXv3mrYZ39tF328NGzYssV9CQoKk0Wik1157zbSttPdb7969JQDSsmXLTNvy8vIkHx8fadiwYaZtn3/+uQRA2rBhg2lbTk6O1Lx58xKPWZqRI0dKXl5ekk6nM22LjY2V5HK59P7770uSJEl37tyRAEiffvppuY9VFZ06dZL8/f0lvV5v2rZ161YJgPTdd99JkiTev3l5eWb3u3PnjuTt7W32NyJJJd8Hxc9HVd5/ubm5Zu2SJEmKiIiQNBqN6TWRJEk6duxYmX9bxf/WjX+fH374odl+Tz75pCSTyaRr166ZPRe1Wm227fTp0xIAaeHChSWOVbydFZ2r+fPnSwCkX3/91bRNq9VKXbt2lRwcHKT09HRJkiRpypQpkpOTk9l7o7i2bdtKgwYNKrdNdH9jmQHVW2FhYfD09ERAQACefPJJ2NvbY+PGjfD39wcgvub7559/MHz4cGRkZCApKQlJSUlITk5G//79cfXqVdPsB1u3bkXXrl3Nemnc3NxMX+1biq2trennrKwsJCUloVu3bpAkCSdPniyxv7FXs7Li4uLw5JNPol27dvjmm29M29esWYOePXvC1dXV9DokJSUhLCwMer0ee/fuBQBs3rwZSqXS7LgKhQKvvPJKVZ8qHnnkEbi5uWHlypWQJAkrV67EyJEjS9138+bNAIDp06ebbX/ttdcAAJs2bQIA/P3339BqtXjllVfMejOnTp1a4jEr+5wt7cUXXyyxreh5z83NRVJSEh588EEAKPVr8uJatmxp6rUDAE9PTzRr1gw3btyo8L4ODg5mA/HUajU6d+5sdt+tW7eiQYMGePzxx03bbGxsMHHixAofHwBGjBiBhIQEs3KEtWvXwmAwYMSIEQDEa6BWq7F7926L1Us/++yzuHXrltm5XL58OdRqNZ566ikA4v1rHBRnMBiQkpICnU6Hjh07Vuq1L6oq7z+NRgO5XPwXrNfrkZycDAcHBzRr1qzKxzXavHkzFAoFXn31VbPtr732GiRJwpYtW8y2h4WFITg42PR7mzZt4OTkVKn3TWXa4uPjY/Y3rVKp8OqrryIzM9NUduLi4oKsrKxySwZcXFxw/vx5XL16tdrtovqJYZbqra+//ho7duzA2rVrMXDgQCQlJZmVBVy7dg2SJGHWrFnw9PQ0u7z77rsARM0XIOoFmzRpUuIYpW2rjqioKIwdOxZubm5wcHCAp6en6avZtLQ0s32VSqUpmFeGTqfD8OHDodfrsW7dOrPX4urVq9i6dWuJ1yEsLAyA+evg6+sLBwcHs8du1qxZlZ+rSqXCU089heXLl2Pv3r2Ijo7GM888U+q+kZGRkMvlJV5vHx8fuLi4IDIy0rQfAISEhJjt5+npaVZeUpXnbGmNGjUqsS0lJQVTpkyBt7c3bG1t4enpadqv+HkvTWBgYIltrq6ulQqF/v7+JcoYit83MjISwcHBJfar7Pv/0UcfhbOzM1atWmXatmrVKrRr1w5NmzYFIMLdxx9/jC1btsDb2xu9evXCJ598gri4uEodozRPP/00FAoFli9fDkB8UFi/fj0GDBhg9n5YunQp2rRpY6rH9PT0xKZNmyr12hdVlfefwWDAl19+iZCQEGg0Gnh4eMDT0xNnzpyp8nGLHt/Pzw+Ojo5m240zahjbZ1Sd901l2hISEmIK7GW15eWXX0bTpk0xYMAA+Pv7Y/z48SXqdt9//32kpqaiadOmCA0Nxeuvv37PT6lG1sWaWaq3OnfubJrNYMiQIejRoweeeeYZXL58GQ4ODqZBPjNmzED//v1LfQxLhlW9Xl/h7f369UNKSgrefPNNNG/eHPb29oiJicHYsWNLDEoq2rNTGa+//joOHTqEv//+u0QINhgM6NevH954441S72sMHJb2zDPPYNGiRXjvvffQtm1btGzZstz9K6odrYraes5Fe2GNhg8fjoMHD+L1119Hu3btTO/PRx99tFKD0coaUS8VG/Rj6ftWlkajwZAhQ7B+/Xp88803iI+Px4EDBzB37lyz/aZOnYrw8HBs2LAB27Ztw6xZszBv3jz8888/aN++fZWP6+XlhX79+uH333/H119/jT///BMZGRlm36j8+uuvGDt2LIYMGYLXX38dXl5eUCgUmDdvXonBopY0d+5czJo1C+PHj8cHH3wANzc3yOVyTJ061WrTbVnj3FfEy8sLp06dwrZt27BlyxZs2bIFP//8M0aPHm0aLNarVy9cv34df/zxB7Zv344ffvgBX375JRYtWlRiPADdnxhm6b5g/M+pb9+++Oqrr/DWW2+hcePGAEQPobE3riwNGzYsdQL20ra5urqWGN2v1WoRGxtb7jHOnj2LK1euYOnSpRg9erRpuyVG7K5cuRLz58/H/PnzSwzCAYDg4GBkZmZW6nXYuXMnMjMzzXpnL1++fFft6tGjBwIDA7F7927T4I+yjmswGHD16lWzeVvj4+ORmpqKhg0bmvYDRK+r8fwCQGJiYonepso+55p2584d7Ny5E3PmzDGbRupe+kq1YcOGuHDhAiRJMvtAUd6iBMWNGDECS5cuxc6dO3Hx4kVIkmQqMSgqODgYr732Gl577TVcvXoV7dq1w+eff17mIhsVGTVqFLZu3YotW7Zg+fLlcHJyQnh4uOn2tWvXonHjxli3bp3ZczN+O1MVVXn/rV27Fn379sWPP/5otj01NdVsurqqfIBr2LAh/v77b2RkZJj1zl66dMmsfdbQsGFDnDlzBgaDwexDd2ltUavVCA8PR3h4OAwGA15++WV89913mDVrlqlDwc3NDePGjcO4ceOQmZmJXr164b333mOYJQAsM6D7SJ8+fdC5c2fMnz8fubm58PLyQp8+ffDdd9+VGjQTExNNP/fv3x+HDh0yW4UnJSUFv/32W4n7BQcHl6i3/P777yvsmTX2khTtFZEkyWyKmrtx7tw5TJgwAc8++6xpdHBxw4cPx6FDh7Bt27YSt6WmpkKn0wEQ88PqdDp8++23ptv1ej0WLlx4V22TyWRYsGAB3n33XTz33HNl7jdw4EAAKDHDwBdffAFAjJgHRA2gSqXCwoULzV7H0mYmqOxzrmmlnXeg9DbXlv79+yMmJsZsyrrc3FwsXry40o8RFhYGNzc3rFq1CqtWrULnzp3NSi6ys7ORm5trdp/g4GA4OjqaTb8WGxuLS5cuIT8/v1LHHTJkCOzs7PDNN99gy5YtGDp0qNl8u6W9/keOHMGhQ4cq/dyKPsfKvv8UCkWJc75mzZoSqxQa5yGuzPR3AwcOhF6vx1dffWW2/csvv4RMJjPNTmENAwcORFxcnFlpiU6nw8KFC+Hg4GD6UF18+jm5XG5ayMJ43ovv4+DggCZNmpSYlo/uX+yZpfvK66+/jqeeegpLlizBiy++iK+//ho9evRAaGgoJk6ciMaNGyM+Ph6HDh3CrVu3THM+vvHGG/j111/Rr18/vPLKK6apuQIDA5GSkmLWezJhwgS8+OKLGDZsGPr164fTp09j27ZtZr0tpWnevDmCg4MxY8YMxMTEwMnJCb///nu169fGjRsHQHxVV7x3q1u3bmjcuDFef/11bNy4EY899phpSqesrCycPXsWa9euxc2bN+Hh4YHw8HB0794db731Fm7evImWLVti3bp1d13jB4g5ZwcPHlzuPm3btsWYMWPw/fffIzU1Fb1798bRo0exdOlSDBkyBH379gUgahNnzJiBefPm4bHHHsPAgQNx8uRJbNmypcTrX9nnXNOcnJxM9aH5+flo0KABtm/fjoiIiBo/dmX95z//wVdffYWRI0diypQp8PX1xW+//WYKhZXpPVSpVBg6dChWrlyJrKysEkuhXrlyBQ8//DCGDx+Oli1bQqlUYv369YiPj8fTTz9t2m/mzJlYunQpIiIiKjVdl4ODA4YMGWKqmy0+aPOxxx7DunXr8MQTT2DQoEGIiIjAokWL0LJlS2RmZlb4+EVV5f332GOP4f3338e4cePQrVs3nD17Fr/99ptZjy4gAr2LiwsWLVoER0dH2Nvbo0uXLqXWXoeHh6Nv37545513cPPmTbRt2xbbt2/HH3/8galTp5oN9rKEnTt3lvgAAogPEC+88AK+++47jB07FsePH0dQUBDWrl2LAwcOYP78+aae4wkTJiAlJQUPPfQQ/P39ERkZiYULF6Jdu3amb2FatmyJPn36oEOHDnBzc8O///6LtWvXYvLkyRZ9PlSHWX8CBaKaZZwu59ixYyVu0+v1UnBwsBQcHGyaCub69evS6NGjJR8fH0mlUkkNGjSQHnvsMWnt2rVm9z158qTUs2dPSaPRSP7+/tK8efOkBQsWSACkuLg4s2O8+eabkoeHh2RnZyf1799funbtWqWm5rpw4YIUFhYmOTg4SB4eHtLEiRNN0+UUnZpnzJgxkr29fanPv/h0Pcapm0q7FH3MjIwMaebMmVKTJk0ktVoteXh4SN26dZM+++wzSavVmvZLTk6WnnvuOcnJyUlydnaWnnvuOenkyZNVnpqrPMWn5pIkScrPz5fmzJkjNWrUSFKpVFJAQIA0c+ZMs2nVJEm8/nPmzJF8fX0lW1tbqU+fPtK5c+dKvP5Vec6w4NRciYmJJfa/deuW9MQTT0guLi6Ss7Oz9NRTT0m3b9+ucCooSRLnt7Rpi3r37i317t3b9HtZU3MVf50lqfTp3W7cuCENGjRIsrW1lTw9PaXXXntN+v333yUA0uHDhyt8TSRJknbs2CEBkGQymdkUeZIkSUlJSdKkSZOk5s2bS/b29pKzs7PUpUsXafXq1SXaVvw1qMimTZskAJKvr2+J6bAMBoM0d+5cqWHDhpJGo5Hat28v/fXXX6W+BpU5H5V9/+Xm5kqvvfaaab/u3btLhw4dKnHeJEmS/vjjD6lly5aSUqk0+zsrrY0ZGRnStGnTJD8/P0mlUkkhISHSp59+ajZVmPG5TJo0qcRrVdrfSXHGqbnKuvzyyy+SJElSfHy8NG7cOMnDw0NSq9VSaGhoiX8j1q5dKz3yyCOSl5eXpFarpcDAQOk///mPFBsba9rnww8/lDp37iy5uLhItra2UvPmzaWPPvrI7G+U7m8ySbJipTdRPTN16lR89913yMzMrNVlLYlqw/z58zFt2jTcunULDRo0qO3mENF9imGWqJJycnLMRqInJyejadOmeOCBB7isItV7xd//ubm5aN++PfR6Pa5cuVKLLSOi+x1rZokqqWvXrujTpw9atGiB+Ph4/Pjjj0hPT8esWbNqu2lENW7o0KEIDAxEu3btkJaWhl9//RWXLl0qdRAkEZE1McwSVdLAgQOxdu1afP/995DJZHjggQfw448/olevXrXdNKIa179/f/zwww/47bffoNfr0bJlS6xcubLU6bWIiKyJZQZEREREVGdxnlkiIiIiqrMYZomIiIiozrrvamYNBgNu374NR0dHi67zTkRERESWIUkSMjIy4OfnZ7YkcmnuuzB7+/ZtBAQE1HYziIiIiKgC0dHR8Pf3L3ef+y7MGpfQi46OhpOTUy23hoiIiIiKS09PR0BAgCm3lee+C7PG0gInJyeGWSIiIqJ7WGVKQjkAjIiIiIjqLIZZIiIiIqqzGGaJiIiIqM6672pmiYiIqPIkSYJOp4Ner6/tplA9o1KpoFAoqv04DLNERERUKq1Wi9jYWGRnZ9d2U6gekslk8Pf3h4ODQ7Ueh2GWiIiISjAYDIiIiIBCoYCfnx/UajUXGyKLkSQJiYmJuHXrFkJCQqrVQ8swS0RERCVotVoYDAYEBATAzs6utptD9ZCnpydu3ryJ/Pz8aoVZDgAjIiKiMlW0lCjR3bJUTz/foURERERUZzHMEhEREVGdxTBLREREVI6goCDMnz+/0vvv3r0bMpkMqampNdYmKsQwS0RERPWCTCYr9/Lee+/d1eMeO3YML7zwQqX379atG2JjY+Hs7HxXx6sshmaBsxkQERFRvRAbG2v6edWqVZg9ezYuX75s2lZ0PlNJkqDX66FUVhyFPD09q9QOtVoNHx+fKt2H7h57ZomIiKhCkiQhW6urlYskSZVqo4+Pj+ni7OwMmUxm+v3SpUtwdHTEli1b0KFDB2g0Guzfvx/Xr1/H4MGD4e3tDQcHB3Tq1Al///232eMWLzOQyWT44Ycf8MQTT8DOzg4hISHYuHGj6fbiPaZLliyBi4sLtm3bhhYtWsDBwQGPPvqoWfjW6XR49dVX4eLiAnd3d7z55psYM2YMhgwZctfn7M6dOxg9ejRcXV1hZ2eHAQMG4OrVq6bbIyMjER4eDldXV9jb26NVq1bYvHmz6b6jRo2Cp6cnbG1tERISgp9//vmu21KT2DNLREREFcrJ16Pl7G21cuwL7/eHndoykeWtt97CZ599hsaNG8PV1RXR0dEYOHAgPvroI2g0Gixbtgzh4eG4fPkyAgMDy3ycOXPm4JNPPsGnn36KhQsXYtSoUYiMjISbm1up+2dnZ+Ozzz7DL7/8ArlcjmeffRYzZszAb7/9BgD4+OOP8dtvv+Hnn39GixYt8L///Q8bNmxA37597/q5jh07FlevXsXGjRvh5OSEN998EwMHDsSFCxegUqkwadIkaLVa7N27F/b29rhw4YKp93rWrFm4cOECtmzZAg8PD1y7dg05OTl33ZaaxDBLRERE9433338f/fr1M/3u5uaGtm3bmn7/4IMPsH79emzcuBGTJ08u83HGjh2LkSNHAgDmzp2LBQsW4OjRo3j00UdL3T8/Px+LFi1CcHAwAGDy5Ml4//33TbcvXLgQM2fOxBNPPAEA+Oqrr0y9pHfDGGIPHDiAbt26AQB+++03BAQEYMOGDXjqqacQFRWFYcOGITQ0FADQuHFj0/2joqLQvn17dOzYEYDonb5XMczWsAu30xGZnIUmXg4I8Xas7eYQERHdFVuVAhfe719rx7YUYzgzyszMxHvvvYdNmzYhNjYWOp0OOTk5iIqKKvdx2rRpY/rZ3t4eTk5OSEhIKHN/Ozs7U5AFAF9fX9P+aWlpiI+PR+fOnU23KxQKdOjQAQaDoUrPz+jixYtQKpXo0qWLaZu7uzuaNWuGixcvAgBeffVVvPTSS9i+fTvCwsIwbNgw0/N66aWXMGzYMJw4cQKPPPIIhgwZYgrF9xrWzNaw345E4qXfTmDT2diKdyYiIrpHyWQy2KmVtXKx1EpRgAieRc2YMQPr16/H3LlzsW/fPpw6dQqhoaHQarXlPo5KpSrx+pQXPEvbv7K1wDVlwoQJuHHjBp577jmcPXsWHTt2xMKFCwEAAwYMQGRkJKZNm4bbt2/j4YcfxowZM2q1vWVhmK1hKoV4ifP1d/fJioiIiGrOgQMHMHbsWDzxxBMIDQ2Fj48Pbt68adU2ODs7w9vbG8eOHTNt0+v1OHHixF0/ZosWLaDT6XDkyBHTtuTkZFy+fBktW7Y0bQsICMCLL76IdevW4bXXXsPixYtNt3l6emLMmDH49ddfMX/+fHz//fd33Z6axDKDGqZSiE+TOn3tfvoiIiKikkJCQrBu3TqEh4dDJpNh1qxZd/3VfnW88sormDdvHpo0aYLmzZtj4cKFuHPnTqV6pc+ePQtHx8JSRplMhrZt22Lw4MGYOHEivvvuOzg6OuKtt95CgwYNMHjwYADA1KlTMWDAADRt2hR37tzBrl270KJFCwDA7Nmz0aFDB7Rq1Qp5eXn466+/TLfdaxhma5jS1DPLMEtERHSv+eKLLzB+/Hh069YNHh4eePPNN5Genm71drz55puIi4vD6NGjoVAo8MILL6B///5QKCquF+7Vq5fZ7wqFAjqdDj///DOmTJmCxx57DFqtFr169cLmzZtNJQ96vR6TJk3CrVu34OTkhEcffRRffvklADFX7syZM3Hz5k3Y2tqiZ8+eWLlypeWfuAXIpNou2LCy9PR0ODs7Iy0tDU5OTjV+vC+2X8aCf65hdNeGeH9w6xo/HhERkSXk5uYiIiICjRo1go2NTW03575jMBjQokULDB8+HB988EFtN6dGlPceq0peY89sDWPNLBEREVUkMjIS27dvR+/evZGXl4evvvoKEREReOaZZ2q7afc8DgCrYSwzICIioorI5XIsWbIEnTp1Qvfu3XH27Fn8/fff92yd6r2EPbM1rHAAGHtmiYiIqHQBAQE4cOBAbTejTmLPbA1TykWYzTewZ5aIiIjI0hhma5hKWVBmoGPPLBEREZGlMczWMJVcvMQ69swSERERWRzDbA1TFtTMcjYDIiIiIstjmK1hxqm5uAIYERERkeUxzNYwFXtmiYiIiGoMw2wNUxbUzHI2AyIiorqhT58+mDp1qun3oKAgzJ8/v9z7yGQybNiwodrHttTj3E8YZmuYkvPMEhERWUV4eDgeffTRUm/bt28fZDIZzpw5U+XHPXbsGF544YXqNs/Me++9h3bt2pXYHhsbiwEDBlj0WMUtWbIELi4uNXoMa2KYrWFq1swSERFZxfPPP48dO3bg1q1bJW77+eef0bFjR7Rp06bKj+vp6Qk7OztLNLFCPj4+0Gg0VjlWfcEwW8MKl7NlzywREdVhkgRos2rnIlWuQ+ixxx6Dp6cnlixZYrY9MzMTa9aswfPPP4/k5GSMHDkSDRo0gJ2dHUJDQ7FixYpyH7d4mcHVq1fRq1cv2NjYoGXLltixY0eJ+7z55pto2rQp7Ozs0LhxY8yaNQv5+fkARM/onDlzcPr0achkMshkMlObi5cZnD17Fg899BBsbW3h7u6OF154AZmZmabbx44diyFDhuCzzz6Dr68v3N3dMWnSJNOx7kZUVBQGDx4MBwcHODk5Yfjw4YiPjzfdfvr0afTt2xeOjo5wcnJChw4d8O+//wIAIiMjER4eDldXV9jb26NVq1bYvHnzXbelMricbQ0zTc1lYJglIqI6LD8bmOtXO8d++zagtq9wN6VSidGjR2PJkiV45513IJOJ/4PXrFkDvV6PkSNHIjMzEx06dMCbb74JJycnbNq0Cc899xyCg4PRuXPnCo9hMBgwdOhQeHt748iRI0hLSzOrrzVydHTEkiVL4Ofnh7Nnz2LixIlwdHTEG2+8gREjRuDcuXPYunUr/v77bwCAs7NzicfIyspC//790bVrVxw7dgwJCQmYMGECJk+ebBbYd+3aBV9fX+zatQvXrl3DiBEj0K5dO0ycOLHC51Pa8zMG2T179kCn02HSpEkYMWIEdu/eDQAYNWoU2rdvj2+//RYKhQKnTp2CSqUCAEyaNAlarRZ79+6Fvb09Lly4AAcHhyq3oyoYZmuYadEElhkQERHVuPHjx+PTTz/Fnj170KdPHwCixGDYsGFwdnaGs7MzZsyYYdr/lVdewbZt27B69epKhdm///4bly5dwrZt2+DnJ8L93LlzS9S5/ve//zX9HBQUhBkzZmDlypV44403YGtrCwcHByiVSvj4+JR5rOXLlyM3NxfLli2Dvb0I81999RXCw8Px8ccfw9vbGwDg6uqKr776CgqFAs2bN8egQYOwc+fOuwqzO3fuxNmzZxEREYGAgAAAwLJly9CqVSscO3YMnTp1QlRUFF5//XU0b94cABASEmK6f1RUFIYNG4bQ0FAAQOPGjavchqpimK1hKiWn5iIionpAZSd6SGvr2JXUvHlzdOvWDT/99BP69OmDa9euYd++fXj//fcBAHq9HnPnzsXq1asRExMDrVaLvLy8StfEXrx4EQEBAaYgCwBdu3Ytsd+qVauwYMECXL9+HZmZmdDpdHBycqr08zAeq23btqYgCwDdu3eHwWDA5cuXTWG2VatWUCgUpn18fX1x9uzZKh2r6DEDAgJMQRYAWrZsCRcXF1y8eBGdOnXC9OnTMWHCBPzyyy8ICwvDU089heDgYADAq6++ipdeegnbt29HWFgYhg0bdld1ylXBmtkaZpqaiz2zRERUl8lk4qv+2rgUlAtU1vPPP4/ff/8dGRkZ+PnnnxEcHIzevXsDAD799FP873//w5tvvoldu3bh1KlT6N+/P7RarcVeqkOHDmHUqFEYOHAg/vrrL5w8eRLvvPOORY9RlPErfiOZTAZDDZY3vvfeezh//jwGDRqEf/75By1btsT69esBABMmTMCNGzfw3HPP4ezZs+jYsSMWLlxYY20BGGZrnIpTcxEREVnV8OHDIZfLsXz5cixbtgzjx4831c8eOHAAgwcPxrPPPou2bduicePGuHLlSqUfu0WLFoiOjkZsbKxp2+HDh832OXjwIBo2bIh33nkHHTt2REhICCIjI832UavV0Ov1FR7r9OnTyMrKMm07cOAA5HI5mjVrVuk2V4Xx+UVHR5u2XbhwAampqWjZsqVpW9OmTTFt2jRs374dQ4cOxc8//2y6LSAgAC+++CLWrVuH1157DYsXL66RthoxzNYw02wGXDSBiIjIKhwcHDBixAjMnDkTsbGxGDt2rOm2kJAQ7NixAwcPHsTFixfxn//8x2ykfkXCwsLQtGlTjBkzBqdPn8a+ffvwzjvvmO0TEhKCqKgorFy5EtevX8eCBQtMPZdGQUFBiIiIwKlTp5CUlIS8vLwSxxo1ahRsbGwwZswYnDt3Drt27cIrr7yC5557zlRicLf0ej1OnTpldrl48SLCwsIQGhqKUaNG4cSJEzh69ChGjx6N3r17o2PHjsjJycHkyZOxe/duREZG4sCBAzh27BhatGgBAJg6dSq2bduGiIgInDhxArt27TLdVlMYZmsYl7MlIiKyvueffx537txB//79zepb//vf/+KBBx5A//790adPH/j4+GDIkCGVfly5XI7169cjJycHnTt3xoQJE/DRRx+Z7fP4449j2rRpmDx5Mtq1a4eDBw9i1qxZZvsMGzYMjz76KPr27QtPT89Spwezs7PDtm3bkJKSgk6dOuHJJ5/Eww8/jK+++qpqL0YpMjMz0b59e7NLeHg4ZDIZ/vjjD7i6uqJXr14ICwtD48aNsWrVKgCAQqFAcnIyRo8ejaZNm2L48OEYMGAA5syZA0CE5EmTJqFFixZ49NFH0bRpU3zzzTfVbm95ZJJUycnb6on09HQ4OzsjLS2tyoXYd+NOlhbtPxDzz12fOxAKedXqfoiIiGpDbm4uIiIi0KhRI9jY2NR2c6geKu89VpW8xp7ZGmacZxZg7ywRERGRpTHM1jCVovAl1rFuloiIiMiiGGZrWNEwm69jzywRERGRJTHM1jCFXGaaHo9L2hIRERFZFsOsFXBJWyIiqqvus3HiZEWWem8xzFpB4cIJ/AeBiIjqBuOqUtnZ2bXcEqqvjCuiFV2K924oLdEYKp9YOEEPLWczICKiOkKhUMDFxQUJCQkAxJynsiouK0tUFoPBgMTERNjZ2UGprF4cZZi1AlPPLGtmiYioDvHx8QEAU6AlsiS5XI7AwMBqf0himLUCJWtmiYioDpLJZPD19YWXlxfy8/NruzlUz6jVasjl1a94ZZi1ApWSS9oSEVHdpVAoql3XSFRTOADMCoyzGeSzZ5aIiIjIohhmrUBpms2APbNERERElsQwawXGmtl8LmdLREREZFEMs1agUhaEWS5nS0RERGRRDLNWoJJzai4iIiKimsAwawXGmlkOACMiIiKyLIZZK1ApCuaZZc8sERERkUUxzFqBMczm69gzS0RERGRJDLNWoCyomc1nzywRERGRRTHMWoGpzIA1s0REREQWxTBrBSoFl7MlIiIiqgkMs1agVHA5WyIiIqKawDBrBSouZ0tERERUIxhmrYDL2RIRERHVDIZZKygcAMaeWSIiIiJLYpi1Ag4AIyIiIqoZDLNWwOVsiYiIiGoGw6wVGGtmuZwtERERkWUxzFqBWslFE4iIiIhqQq2G2b179yI8PBx+fn6QyWTYsGFDufuvW7cO/fr1g6enJ5ycnNC1a1ds27bNOo2tBuNytlrWzBIRERFZVK2G2aysLLRt2xZff/11pfbfu3cv+vXrh82bN+P48ePo27cvwsPDcfLkyRpuafUouZwtERERUY1Q1ubBBwwYgAEDBlR6//nz55v9PnfuXPzxxx/4888/0b59ewu3znJMiyawZpaIiIjIomo1zFaXwWBARkYG3NzcytwnLy8PeXl5pt/T09Ot0TQzxnlmtTr2zBIRERFZUp0eAPbZZ58hMzMTw4cPL3OfefPmwdnZ2XQJCAiwYgsFY80se2aJiIiILKvOhtnly5djzpw5WL16Nby8vMrcb+bMmUhLSzNdoqOjrdhKQcWaWSIiIqIaUSfLDFauXIkJEyZgzZo1CAsLK3dfjUYDjUZjpZaVzhhmuQIYERERkWXVuZ7ZFStWYNy4cVixYgUGDRpU282pFCWXsyUiIiKqEbXaM5uZmYlr166Zfo+IiMCpU6fg5uaGwMBAzJw5EzExMVi2bBkAUVowZswY/O9//0OXLl0QFxcHALC1tYWzs3OtPIfKKJzNgGUGRERERJZUqz2z//77L9q3b2+aVmv69Olo3749Zs+eDQCIjY1FVFSUaf/vv/8eOp0OkyZNgq+vr+kyZcqUWml/ZRmXs81nzSwRERGRRdVqz2yfPn0gSWUHvCVLlpj9vnv37pptUA0pHADGMgMiIiIiS6pzNbN1kYo1s0REREQ1gmHWCpQKlhkQERER1QSGWSvgoglERERENYNh1grUSi6aQERERFQTGGatwNgzq2XNLBEREZFFMcxaAZezJSIiIqoZDLNWoFSwZpaIiIioJjDMWoGqyGwG5c2rS0RERERVwzBrBSp54cvMJW2JiIiILIdh1gqMZQYA62aJiIiILIlh1gqMZQYAkM+6WSIiIiKLYZi1AlWRntl8HcMsERERkaUwzFqBTCaDwrQKGMsMiIiIiCyFYdZKjAsn5HPhBCIiIiKLYZi1EjUXTiAiIiKyOIZZKzHOaMCeWSIiIiLLYZi1EmWRhROIiIiIyDIYZq1EJeeStkRERESWxjBrJSole2aJiIiILI1h1ko4mwERERGR5THMWomKsxkQERERWRzDrJWYZjNgzSwRERGRxTDMWgl7ZomIiIgsj2HWSlRy4wAw9swSERERWQrDrJVw0QQiIiIiy2OYtRKWGRARERFZHsOslagUXDSBiIiIyNIYZq1EWVAzq2XPLBEREZHFMMxaibFmVseaWSIiIiKLYZi1EjVrZomIiIgsjmHWSow9s1r2zBIRERFZDMOslSjZM0tERERkcQyzVqKSczYDIiIiIktjmLUS4zyz+eyZJSIiIrIYhlkrUSq4nC0RERGRpTHMWomKU3MRERERWRzDrJUYF03IN7DMgIiIiMhSGGatRKVkzywRERGRpTHMWolKzgFgRERERJbGMGslxkUTOACMiIiIyHIYZq2EiyYQERERWR7DrJWoFVw0gYiIiMjSGGatxDibgZY9s0REREQWwzBrJUrOM0tERERkcQyzVqJmzSwRERGRxTHMWolpOVvWzBIRERFZDMOslXBqLiIiIiLLY5i1EuOiCSwzICIiIrIchlkrUbFnloiIiMjiGGatxFQzy55ZIiIiIothmLUSFafmIiIiIrI4hlkrMS6akG9gzywRERGRpTDMWolayZ5ZIiIiIktjmLUSU88sa2aJiIiILIZh1ko4zywRERGR5THMWonKuJwta2aJiIiILIZh1kqMYVZvkGBgoCUiIiKyCIZZKzGWGQBAvoGlBkRERESWwDBrJcblbAEuaUtERERkKQyzVqIq0jPLMEtERERkGQyzVqKQs8yAiIiIyNIYZq1EJpOZemc5PRcRERGRZTDMWpFx4QSWGRARERFZBsOsFbFnloiIiMiyGGatiAsnEBEREVkWw6wVGeea1erYM0tERERkCQyzVmSqmWXPLBEREZFFMMxakVppHADGnlkiIiIiS2CYtSJlwVyzWoZZIiIiIotgmLUipYJTcxERERFZUq2G2b179yI8PBx+fn6QyWTYsGFDhffZvXs3HnjgAWg0GjRp0gRLliyp8XZainFqLh1XACMiIiKyiFoNs1lZWWjbti2+/vrrSu0fERGBQYMGoW/fvjh16hSmTp2KCRMmYNu2bTXcUsswTs2Vz55ZIiIiIotQ1ubBBwwYgAEDBlR6/0WLFqFRo0b4/PPPAQAtWrTA/v378eWXX6J///411UyLMdbMctEEIiIiIsuoUzWzhw4dQlhYmNm2/v3749ChQ2XeJy8vD+np6WaX2qJizSwRERGRRdWpMBsXFwdvb2+zbd7e3khPT0dOTk6p95k3bx6cnZ1Nl4CAAGs0tVRczpaIiIjIsupUmL0bM2fORFpamukSHR1da21RcjlbIiIiIouq1ZrZqvLx8UF8fLzZtvj4eDg5OcHW1rbU+2g0Gmg0Gms0r0LsmSUiIiKyrDrVM9u1a1fs3LnTbNuOHTvQtWvXWmpR1RiXs+VsBkRERESWUathNjMzE6dOncKpU6cAiKm3Tp06haioKACiRGD06NGm/V988UXcuHEDb7zxBi5duoRvvvkGq1evxrRp02qj+VVWOACMPbNEREREllCrYfbff/9F+/bt0b59ewDA9OnT0b59e8yePRsAEBsbawq2ANCoUSNs2rQJO3bsQNu2bfH555/jhx9+qBPTcgFFF01gzywRERGRJdRqzWyfPn0gSWUHu9JW9+rTpw9OnjxZg62qOcqCMKvVsWeWiIiIyBLqVM1sXWesmeVytkRERESWwTBrRWolF00gIiIisiSGWSsqXM6WYZaIiIjIEhhmrci4aALnmSUiIiKyDIZZK1LJjbMZMMwSERERWQLDrBWplFw0gYiIiMiSGGatqLBmlj2zRERERJbAMGtFhSuAsWeWiIiIyBIYZq1IxQFgRERERBbFMGtFSi5nS0RERGRRDLNWpFKwZpaIiIjIkhhmrci4nC3DLBEREZFlMMxaEQeAEREREVkWw6wVmcoMWDNLREREZBEMs1ZkWs5WxzIDIiIiIktgmLUiLmdLREREZFkMs1ZkXM6WNbNERERElsEwa0Wm5WzZM0tERERkEQyzVmRaAUzHnlkiIiIiS2CYtaLCFcDYM0tERERkCQyzVmTqmWXNLBEREZFFMMxakUpuHADGnlkiIiIiS2CYtSJjmQF7ZomIiIgsg2HWikxhljWzRERERBbBMGtF6oKaWUkC9FzSloiIiKjaGGatyLicLQDks26WiIiIqNoYZq3IuGgCwDBLREREZAkMs1akKtIzyyVtiYiIiKqPYdaKFHIZjJ2zHARGREREVH0Ms1am5MIJRERERBbDMGtlqoKuWS6cQERERFR9DLNWplKyZ5aIiIjIUhhmrUxpXNKWNbNERERE1VblMJuTk4Ps7GzT75GRkZg/fz62b99u0YbVVyrjKmA69swSERERVVeVw+zgwYOxbNkyAEBqaiq6dOmCzz//HIMHD8a3335r8QbWN1zSloiIiMhyqhxmT5w4gZ49ewIA1q5dC29vb0RGRmLZsmVYsGCBxRtY3xjnmuU8s0RERETVV+Uwm52dDUdHRwDA9u3bMXToUMjlcjz44IOIjIy0eAPrG5WxZpazGRARERFVW5XDbJMmTbBhwwZER0dj27ZteOSRRwAACQkJcHJysngD6xtjmYGWYZaIiIio2qocZmfPno0ZM2YgKCgIXbp0QdeuXQGIXtr27dtbvIH1jZJlBkREREQWo6zqHZ588kn06NEDsbGxaNu2rWn7ww8/jCeeeMKijauP1AU9s5yai4iIiKj6qhxmAcDHxwc+Pj4AgPT0dPzzzz9o1qwZmjdvbtHG1UfGeWa5aAIRERFR9VW5zGD48OH46quvAIg5Zzt27Ijhw4ejTZs2+P333y3ewPrGNDUXa2aJiIiIqq3KYXbv3r2mqbnWr18PSZKQmpqKBQsW4MMPP7R4A+sbNWtmiYiIiCymymE2LS0Nbm5uAICtW7di2LBhsLOzw6BBg3D16lWLN7C+4aIJRERERJZT5TAbEBCAQ4cOISsrC1u3bjVNzXXnzh3Y2NhYvIH1jXE2g3wdwywRERFRdVV5ANjUqVMxatQoODg4oGHDhujTpw8AUX4QGhpq6fbVOyq5cTYDlhkQERERVVeVw+zLL7+Mzp07Izo6Gv369YO8YHR+48aNWTNbCcblbDmbAREREVH13dXUXB07dkTHjh0hSRIkSYJMJsOgQYMs3bZ6qXDRBJYZEBEREVVXlWtmAWDZsmUIDQ2Fra0tbG1t0aZNG/zyyy+Wblu9pOLUXEREREQWU+We2S+++AKzZs3C5MmT0b17dwDA/v378eKLLyIpKQnTpk2zeCPrE9OiCayZJSIiIqq2KofZhQsX4ttvv8Xo0aNN2x5//HG0atUK7733HsNsBVTKggFg7JklIiIiqrYqlxnExsaiW7duJbZ369YNsbGxFmlUfabicrZEREREFlPlMNukSROsXr26xPZVq1YhJCTEIo2qz7icLREREZHlVLnMYM6cORgxYgT27t1rqpk9cOAAdu7cWWrIJXMqLmdLREREZDFV7pkdNmwYjhw5Ag8PD2zYsAEbNmyAh4cHjh49iieeeKIm2livqLicLREREZHF3NU8sx06dMCvv/5qti0hIQFz587F22+/bZGG1VfG2QzYM0tERERUfXc1z2xpYmNjMWvWLEs9XL3FeWaJiIiILMdiYZYqh8vZEhEREVkOw6yVmZazZc0sERERUbUxzFqZscyANbNERERE1VfpAWDTp08v9/bExMRqN+Z+YBwApmXNLBEREVG1VTrMnjx5ssJ9evXqVa3G3A8Ke2YZZomIiIiqq9JhdteuXTXZjvuGadEEA8sMiIiIiKqLNbNWZlzOVqtjzywRERFRdTHMWplp0QT2zBIRERFVG8OslamVrJklIiIishSGWSsz9sxy0QQiIiKi6mOYtTIll7MlIiIisphKh9lPPvkEOTk5pt8PHDiAvLw80+8ZGRl4+eWXLdu6eoizGRARERFZTqXD7MyZM5GRkWH6fcCAAYiJiTH9np2dje+++67KDfj6668RFBQEGxsbdOnSBUePHi13//nz56NZs2awtbVFQEAApk2bhtzc3Coft7YYwyx7ZomIiIiqr9JhVpKkcn+/G6tWrcL06dPx7rvv4sSJE2jbti369++PhISEUvdfvnw53nrrLbz77ru4ePEifvzxR6xatQpvv/12tdtiLUo5l7MlIiIispRarZn94osvMHHiRIwbNw4tW7bEokWLYGdnh59++qnU/Q8ePIju3bvjmWeeQVBQEB555BGMHDmywt7cewl7ZomIiIgsp9bCrFarxfHjxxEWFlbYGLkcYWFhOHToUKn36datG44fP24Krzdu3MDmzZsxcODAMo+Tl5eH9PR0s0ttMi1na5As0rtNREREdD+r9HK2APDDDz/AwcEBAKDT6bBkyRJ4eHgAgFk9bWUkJSVBr9fD29vbbLu3tzcuXbpU6n2eeeYZJCUloUePHpAkCTqdDi+++GK5ZQbz5s3DnDlzqtQ2i8pKArISAVs3wNEbSkXh5wedQTKFWyIiIiKqukqH2cDAQCxevNj0u4+PD3755ZcS+9Sk3bt3Y+7cufjmm2/QpUsXXLt2DVOmTMEHH3yAWbNmlXqfmTNnYvr06abf09PTERAQUKPtNLPzfeDEUqDvf4Her5uFV51egkphvaYQERER1TeVDrM3b9606IE9PDygUCgQHx9vtj0+Ph4+Pj6l3mfWrFl47rnnMGHCBABAaGgosrKy8MILL+Cdd96BXF6yakKj0UCj0Vi07VWishPX+VkAChdNAACt3gBbMM0SERER3a1aq5lVq9Xo0KEDdu7cadpmMBiwc+dOdO3atdT7ZGdnlwisCoUIg/ds/anaGGbFHL3mPbMcBEZERERUHZUOs4cOHcJff/1ltm3ZsmVo1KgRvLy88MILL5gtolAZ06dPx+LFi7F06VJcvHgRL730ErKysjBu3DgAwOjRozFz5kzT/uHh4fj222+xcuVKREREYMeOHZg1axbCw8NNofaeY+yZ1YqeWZlMVjg9FxdOICIiIqqWSpcZvP/+++jTpw8ee+wxAMDZs2fx/PPPY+zYsWjRogU+/fRT+Pn54b333qv0wUeMGIHExETMnj0bcXFxaNeuHbZu3WoaFBYVFWXWE/vf//4XMpkM//3vfxETEwNPT0+Eh4fjo48+qvQxrc5UZpBt2qRUyKAzSJyei4iIiKiaZFIlv5/39fXFn3/+iY4dOwIA3nnnHezZswf79+8HAKxZswbvvvsuLly4UHOttYD09HQ4OzsjLS0NTk5ONX/A40uAP6cAzQYCI1cAAELf3YaMPB12zeiDRh72Nd8GIiIiojqkKnmt0mUGd+7cMZtGa8+ePRgwYIDp906dOiE6OvoumlvPFSszAACVUrzsrJklIiIiqp5Kh1lvb29EREQAEAsenDhxAg8++KDp9oyMDKhUKsu3sK4rrcygoGY2n0vaEhEREVVLpcPswIED8dZbb2Hfvn2YOXMm7Ozs0LNnT9PtZ86cQXBwcI00sk4rNpsBwCVtiYiIiCyl0gPAPvjgAwwdOhS9e/eGg4MDli5dCrVabbr9p59+wiOPPFIjjazTSikzUJqWtGWYJSIiIqqOSodZDw8P7N27F2lpaXBwcCgxFdaaNWtMS91SEaryemZZZkBERERUHZUOs0bOzs6lbndzc6t2Y+qlcmpmdQyzRERERNVS6TA7fvz4Su33008/3XVj6iV1kTIDSQJkMtbMEhEREVlIpcPskiVL0LBhQ7Rv3/7eXTr2XmTsmZX0gD4fUKpNNbMMs0RERETVU+kw+9JLL2HFihWIiIjAuHHj8Oyzz7K0oDKMYRYA8rMApdrUM8vlbImIiIiqp9JTc3399deIjY3FG2+8gT///BMBAQEYPnw4tm3bxp7a8ijVgLzgM0PBIDAVe2aJiIiILKLSYRYANBoNRo4ciR07duDChQto1aoVXn75ZQQFBSEzM7Om2lj3qQqWrNWKQWBKOWczICIiIrKEKoVZszvK5ZDJZJAkCXq93pJtqn9UtuI6X8w1ayozYM8sERERUbVUKczm5eVhxYoV6NevH5o2bYqzZ8/iq6++QlRUFOeYLU+xVcBMZQasmSUiIiKqlkoPAHv55ZexcuVKBAQEYPz48VixYgU8PDxqsm31R7FVwJTsmSUiIiKyiEqH2UWLFiEwMBCNGzfGnj17sGfPnlL3W7duncUaV28UWzhBJecAMCIiIiJLqHSYHT16NGQyWU22pf4qUWbAAWBEREREllClRRPoLpUoM+BytkRERESWcNezGVAVqErvmdUZWGZAREREVB0Ms9ZQbGouZUHNrJY1s0RERETVwjBrDWrzRRNUSuNsBiwzICIiIqoOhllrKF5mIDfWzLJnloiIiKg6GGatwRRmzeeZ1bJnloiIiKhaGGatodjUXIWzGbBnloiIiKg6GGatwTQ1l6iZVZtmM2DPLBEREVF1MMxaQ/EyA64ARkRERGQRDLPWUKLMwLgCGMMsERERUXUwzFqDcZ7Z4mUGHABGREREVC0Ms9agKphnNt98Odt81swSERERVQvDrDWUUWbA2QyIiIiIqodh1hqKzWag4gAwIiIiIotgmLUG02wGBWHWNACMZQZERERE1cEwaw3GAWCGfECfX7hogoE9s0RERETVwTBrDWr7wp+1WaaeWc5mQERERFQ9DLPWoFADMoX4OT/HtGiCljWzRERERNXCMGsNMplZ3axKyZ5ZIiIiIktgmLUWdZEwK+fUXERERESWwDBrLUWm5+KiCURERESWwTBrLaYygyyoFJxnloiIiMgSGGatpcgqYJzNgIiIiMgyGGatxTjXrDbbtJwte2aJiIiIqodh1lpUBXPN5mdxOVsiIiIiC2GYtZZSygwMEmDgIDAiIiKiu8Yway2mMoMs02wGAJDPJW2JiIiI7hrDrLWYygwKe2YBDgIjIiIiqg6GWWsx9szmZ5uWswVYN0tERERUHQyz1qIu6JnVZkEhl0FWkGfz2TNLREREdNcYZq1FVTgATCaTFS5py5pZIiIiorvGMGstRcoMAJgGgbFmloiIiOjuMcxai7HMwBhmC+pmtayZJSIiIrprDLPWYiwz0Iowq1ZySVsiIiKi6mKYtRZTzWwWAEBdMD1XTr6+tlpEREREVOcxzFpLkRXAAMDXRdTQxtzJqa0WEREREdV5DLPWYloBTJQZBLqJcBuVkl1bLSIiIiKq8xhmrcW0ApgoMwhgmCUiIiKqNoZZaylWZtCwIMxGM8wSERER3TWGWWsxDgDTawG9DoHu7JklIiIiqi6GWWsxhlkAyM821czGpOYgn3PNEhEREd0VhllrUWoAiIUSkJ8NTwcNNEo59AYJsam5tdo0IiIiorqKYdZaZLLCVcC0WZDLZRwERkRERFRNDLPWpDIfBMbpuYiIiIiqh2HWmoxzzeZzrlkiIiIiS2CYtSZjmUGJMJtVWy0iIiIiqtMYZq2Jq4ARERERWRTDrDWZamYLwqxxrtlkhlkiIiKiu8Ewa03FygwCXEWYTc/VIS07v7ZaRURERFRnMcxaU7EyA1u1Ap6OGgAsNSAiIiK6Gwyz1qQy9swWDvhqyLpZIiIiorvGMGtNavN5ZoHCQWCRnNGAiIiIqMoYZq2pWJkBANMqYNHsmSUiIiKqMoZZa1KZDwADOD0XERERUXXUepj9+uuvERQUBBsbG3Tp0gVHjx4td//U1FRMmjQJvr6+0Gg0aNq0KTZv3myl1lZTsRXAgCLTczHMEhEREVWZsjYPvmrVKkyfPh2LFi1Cly5dMH/+fPTv3x+XL1+Gl5dXif21Wi369esHLy8vrF27Fg0aNEBkZCRcXFys3/i7YayZ1RbWxxp7Zm+n5iJfb4BKUeufL4iIiIjqjFoNs1988QUmTpyIcePGAQAWLVqETZs24aeffsJbb71VYv+ffvoJKSkpOHjwIFQqFQAgKCjImk2uHlOZQeEAME8HDTRKOfJ0BtxOzUFDd/taahwRERFR3VNr3YBarRbHjx9HWFhYYWPkcoSFheHQoUOl3mfjxo3o2rUrJk2aBG9vb7Ru3Rpz586FXq8v8zh5eXlIT083u9SaUsoM5HIZ62aJiIiI7lKthdmkpCTo9Xp4e3ubbff29kZcXFyp97lx4wbWrl0LvV6PzZs3Y9asWfj888/x4YcflnmcefPmwdnZ2XQJCAiw6POoEnXJAWAAB4ERERER3a06VaBpMBjg5eWF77//Hh06dMCIESPwzjvvYNGiRWXeZ+bMmUhLSzNdoqOjrdjiYkqZmgsonJ6LYZaIiIioamqtZtbDwwMKhQLx8fFm2+Pj4+Hj41PqfXx9faFSqaBQKEzbWrRogbi4OGi1WqjV6hL30Wg00Gg0lm383VIZF00ovWeWc80SERERVU2t9cyq1Wp06NABO3fuNG0zGAzYuXMnunbtWup9unfvjmvXrsFgMJi2XblyBb6+vqUG2XtOBWUGkckMs0RERERVUatlBtOnT8fixYuxdOlSXLx4ES+99BKysrJMsxuMHj0aM2fONO3/0ksvISUlBVOmTMGVK1ewadMmzJ07F5MmTaqtp1A1ZZQZmOaaTc6GJEnWbhURERFRnVWrU3ONGDECiYmJmD17NuLi4tCuXTts3brVNCgsKioKcnlh3g4ICMC2bdswbdo0tGnTBg0aNMCUKVPw5ptv1tZTqBrj1Fz6PMCgB+SiXCLAVYTZjDwd0nLy4WJXB3qZiYiIiO4BMuk+6wpMT0+Hs7Mz0tLS4OTkZN2D5+cAHxXUA8+8BWgcTTd1/uhvJGTkYePk7mjj72LddhERERHdQ6qS1+rUbAZ1ntIGgEz8XLzUgDMaEBEREVUZw6w1yWQVzmjAMEtERERUeQyz1lbKKmBAkblmOaMBERERUaUxzFqbuqBnlmUGRERERNXGMGttqtLnmm3ozjBLREREVFUMs9ZWRpmBsWf2dmoO8vWG4vciIiIiolIwzFpbGauAeTpqoFHKYZBEoCUiIiKiijHMWlsZq4DJZDIua0tERERURQyz1lbG1FwAB4ERERERVRXDrLWVUWYAFE7PFc0wS0RERFQpDLPWVkaZAcAZDYiIiIiqimHW2ipRZnCTNbNERERElcIwa23llBk093WCTAZcjE3HuZg0KzeMiIiIqO5hmLW2csoMGrjY4vG2fgCAz7dftmariIiIiOokhllrK6fMAACmhTWFQi7DrsuJOB6ZYsWGEREREdU9DLPWVkGYDfKwx1Md/AEAn227Yq1WEREREdVJDLPWpi4Is6WUGRi98nAI1Ao5Dt1IxoFrSVZqGBEREVHdwzBrbaqyB4AZNXCxxTNdAgEAn267DEmSrNEyIiIiojqHYdbajAPAygmzAPBy32DYqOQ4FZ2Kfy4lWKFhRERERHUPw6y1GcsM8nPK3c3L0QZjuzUCAHy2/QoMBvbOEhERERXHMGttxgFg2qwKd32xd2M4apS4GJuOzedia7hhRERERHUPw6y1VTCbQVEudmpM6NkYAPDFjivQ6Q012TIiIiKiOodh1tqMK4DpcgFDxeF0fI8guNqpcCMxCxtO3a7hxhERERHVLQyz1mYcAAZUqnfW0UaFF3oFAwCWHIyoqVYRERER1UkMs9amLBpmyx8EZvR0pwColXKci0nHmVupNdMuIiIiojqIYdba5PIidbMVDwIDAFd7NQa29gEALD8SVVMtIyIiIqpzGGZrg7HUoJxVwIp7pktDAMDG07eRkZtfE60iIiIiqnMYZmuDaRWwypUZAECnIFc08XJAtlbPgWBEREREBRhma4NpFbDKlRkAgEwmwzOdxRK3y49EcYlbIiIiIjDM1g7jKmBVKDMAgGEP+EOjlONibDpORqdavl1EREREdQzDbG0wlRlULcw626kwqI0vAA4EIyIiIgIYZmuHqcygamEWAEZ1EaUGf525jbQcDgQjIiKi+xvDbG0wlhlUYQCY0QOBrmju44jcfAPWn7hl4YYRERER1S0Ms7XBOM+stvIDwIxkMhmeKeidXX6UA8GIiIjo/sYwWxtMiyZUvcwAAIa0bwBblQJX4jNxPPKOBRtGREREVLcwzNYGdfXCrJONCuFtORCMiIiIiGG2Nqjubmquoowrgv11NhbXEzMt0SoiIiKiOodhtjao7n4AmFFbf2e0DXCBVmfAoAX78Muhm6yfJSIiovsOw2xtMIXZqg8AM5LJZPju2Q7o3sQdufkGzPrjPEb/dBRxabkWaiQRERHRvY9htjbc5Qpgxfk42+CX8V3wbnhLaJRy7LuahP7z92Lj6dsWaCQRERHRvY9htjZYoMzASC6XYVz3Rtj0ag+ENnBGWk4+Xl1xEtNXn0K+3lDtxyciIiK6lzHM1oaqlhnEXwCWDQEOfgXo8krdpYmXI9a93A2vPhwChVyGdSdi8PJvJ5Cn04sdMuKA3ycAUYer334iIiKiewTDbG2oapnBjlnAjV3A9neArzoB534HShnspVLIMb1fU/wwpiPUSjl2XIjHi78cR26+Hji1HDi7Btj/pQWfCBEREVHtYpitDSp7cV2ZMoPk68C1vwHIAAdvIDUSWDse+OFhIPJgqXfp28wLP43pBBuVHLsuJ2LC0n+hizsvbky6YpnnQERERHQPYJitDSpbcV2ZMoNjP4rrkH7AqyeBvu+IMBxzHPh5ALBmHKDXlbhbjxAPLBnXGXZqBfZfS8KtyyfEDXdullmqcNfuRIoSiDzOd0tERETWxTBbG9SVHACmzQJO/ip+7jQRUNsDvd8QobbDOEAmB86vA65sLfXuDzZ2xy/Pd4aLRgbf/IKVwiQDkHLDQk+kwD8fiBKIU8st+7hEREREFWCYrQ2qIsvZGsqZceDsGiAvDXANApqEFW539AbC5wNtnxG/x54u8yE6NHTDyie9oJEV6b21dKlB7BlxnXjRso9LREREVAGG2dpgDLMAoCujd1aSgKOLxc+dJgLyUk6VbxtxHXe23MM1l98y+z3mevn7V4kuD0i+Jn5Ovm65xyUiIiKqBIbZ2lA0zJZVahB1GIg/ByhtgfajSt/HJ1RcVxBmkWDeY3rt/AnLLX2bdBWQCqb/YpglIiIiK2OYrQ1yOaC0ET9ryxgEdvR7cd3mKcDWtfR9vFuJ6/RbQHZK2ccr+Ppf69cZAOCcHYEdF+Kr2urSFQ3K6beqvaoZERERUVUwzNYWY+9sVmLJ2zLigIsbxc+dJpb9GDbOop4WKL93tiBwqkOfAAA0lsXi/7ZchM4SK4QlXDD//U5E9R+TiIiIqJIYZmuLZzNxvXwEcHO/+W3HlwAGHRDYtbAutiw+FdTN5ucWfv3ffCAkmRxOshxkJMVg1b/Rd918k2IlDKb6WSIiIiIrYJitLU8sArxDgewkYOnjwKFvxKAvnRb49yexT6cJFT+OKcyeKf325IKaVhtnwKUhZAU9uU3kt/HljqvIyis5R22VGHtmnQMKjse6WSIiIrIehtna4hoEPL8dCH1KhM1tM4F1E4Gzq4HMeLHaV4vHK36cigaBJVwS114tAZkM8GgKAOjkkISkzDws3leNOWfzMsWKZADQfJC4ZpglIiIiK2KYrU1qO2DoYqD/PECmEPPK/jFJ3NZhHKBUV/wYxjCbeFmUFBRn7Dn1aiGuPUIAAE8EiFkUvt97A4kZd7kiWOJlce3gDfh3Ej+nMMwSERGR9TDM1jaZDOj6MjD6D8DOQ2yTK4EOYyt3fyc/wNZN9O6WtmiBsabVsyDMuoswG4QYtA1wQbZWj//tvMtFFIoGZfcm4mfWzBIREZEVKWu7AVSgUU/gP3vF0rD+HQEn38rdTyYTvbMRe0SpgV9789tL9MyKMgNZ0lW8Pbg5Rnx/GMuPROHAtWSoFDKoFHKoFHKoFXI093XEKw+FwNNRU/qxjUHZqyXgHix+zkoEctNEjS4RERFRDWOYvZc4NxADw6rKt01hmC2qaE1rsTCLtGh08bfFgNY+2HIuDhFJJee7PXozBetPxGBKWAjGdAuCSlGsI79oUNY4inKDzHhRN9vggao/DyIiIqIqYpitD8qaniupoKbV3guwLyhhsHcXizDk3AFSruN/T7fHS3HpyNMZkK8zQKs3QKeXkKXV4cf9EThzKw0fbrqIVceiMefxVujWxKPw8Yv2zAKi1IBhloiIiKyIYbY+MM1ocA4wGMQKY0CRsNncfH+PpkD0ESDpCtQ+oWjj71Lqw4a38cPqf6PxybbLuJqQiWd+OIKBoT5469EWCLTNBTLjxI7GOXPdGgORBzgIjIiIiKyGA8DqA/cQQKEBtBnmK3AV7zk1KpjRAEnlD9aSy2V4unMgdr3WB2O7BUEuAzafjUOfz3Zh/oqCFcpcAkWJAcBBYERERGR1DLP1gUIJeBcE1qKlBsUHfxkZ62aTKjeLgbOdCu893gqbXu2J3k09YZCApBunAAAnc31x4FoSJEkqHATGuWaJiIjIShhm64vSFk8oumBCUe7GntmqTcnVwtcJS8d3xuZXe+JRzxQAwKFMb4z64QgGf30ARzPcxI7J18VqZkREREQ1jDWz9UXxQWA5d4CM2+JnY02rkbFnNvmaeY1tJbX0cwKcEoFUwCu4HWxuyHHmVhqeu6XFRRsZ5HlpQHZy4aAzIiIiohrCntn6oniYNfbKOvmXnPPVtSEgVwH52YWBt7jUaHEpjSSZShieHPAIDrz5ECb2bARJYYPbkjsA4MuVmxGdkl2dZ0RERERUIYbZ+sK7JQCZCKdZSWXXywKAQgW4NRI/l1ZqkJ0CLOoBLOoOZCWXvD0jDshNFUvwuofA3UGDdwa1xM7XeiPLoSEA4PaNs3jo8934aNMF5ObrLfIUiYiIiIpjmK0vNI5iaixA9M6aZjIoJcwCRQaBXS1528lfRFjNTQOO/1TydmNQdg8GVDamzQFudmjWUqxA1tMtHfl6CYv3ReCpRYfYS0tEREQ1gmG2PjENAjsDJBoHf5UVZo2DwIqFWb0OOLq48PejPwA6rfk+5QXlgum5HvfPxo9jOsLVToWzMWl4bOF+/HMpvgpPhoiIiKhiDLP1iTHMxp4B4s+LnyvsmS1WZnBlC5AWDdi6AQ4+YmGE8+vM9ylr/loAcCuYnivlBh5u4Y2/Xu2JdgEuSMvJx/gl/2LRxn2QvuoE7Hi36s+PiIiIqBiG2frEOAgsYg+QkwJABng0K31f9zJ6Zo98J647jAU6TxQ/H/rafKotY5mBZ7GVxQDzuWYNBjRwscXq/3TFmK6iljbv6E+QJV2B4cgiGLQ5VXp6RERERMXdE2H266+/RlBQEGxsbNClSxccPXq0UvdbuXIlZDIZhgwZUrMNrCt8C8JsVqK4dmsEqO1K39ejYLWujNtAXob4Oe4ccHOfGNjV6Xmg43hAaSvKFiIPiH0MhiIlDKX0zLo0BORKQJcDZMQCANRKOeYMbo3/jWiDJxX7AAByXS5e/Gghnlp0EO9tPI/Vx6Jx4Xa6WHyBiIiIqJJqPcyuWrUK06dPx7vvvosTJ06gbdu26N+/PxISEsq9382bNzFjxgz07NnTSi2tAxy8AXvPwt9LC5tGtq6AvZf42bj87NHvxXWLxwBnf8DODWj7tNh2+FtxnRoppvRSqAsHnBWlUAKuQeaPW2Cwy000kCWafu+sP4FjN+9gycGbeOP3Mxi4YB8e/mIPfth3A3eyitXpEhEREZWi1sPsF198gYkTJ2LcuHFo2bIlFi1aBDs7O/z0Uymj6Avo9XqMGjUKc+bMQePGpQSqIvLy8pCenm52qbdkssK6WaD0MoCiis5okJ0CnFktfu/yYuE+D74kri9tAlJuFNbLejQTwbU0xrrZYmEWp5aLa+cAAMBzntfwxfC2eL5HIzzY2A22KgVuJGbhw00X0WXuTkxZeRKHbySzt5aIiIjKVKthVqvV4vjx4wgLCzNtk8vlCAsLw6FDh8q83/vvvw8vLy88//zzFR5j3rx5cHZ2Nl0CAgIs0vZ7VtEwW9bgLyNjqUHSFeDEMlEa4BMKBHYt3MezGdAkDIAk6mnLm7/WqGBGA6TcKNyWlwlc+EP8POgLQKaA5s5VDG1swKzHWmLlC11x7L9h+OiJ1mjl5wSt3oA/Tt3G098fRr8v92LTmViGWiIiIiqhVsNsUlIS9Ho9vL29zbZ7e3sjLi6u1Pvs378fP/74IxYvXlzq7cXNnDkTaWlppkt0dBmrWtUXxkFgQPllBkBhz2zCReDYD+LnLi+KHt6iHnxZXJ/8FYg+UvDY5YXZgt7yoj2zFzcC+VmiNCGkHxDQWWy/9rdpFweNEqO6NMSmV3viz8k9MLJzIOzVClxLyMSk5Sfw+FcHsP9qUvnPiYiIiO4rtV5mUBUZGRl47rnnsHjxYnh4eFTqPhqNBk5OTmaXes23rbhWaAp7SMtiDLNXtorpuOzcgdZPltwv+CHAswWgzQSubhfbygvKxuMmXy/cZiwxaPuMCMtNHha/X9tZ6kOE+jtj3tBQHH77YUx5OAT2agXOxqTh2R+PYNQPh3E6OrX850ZERET3hTKKHq3Dw8MDCoUC8fHmk+nHx8fDx8enxP7Xr1/HzZs3ER4ebtpmMBgAAEqlEpcvX0ZwcHDNNvpe5xECDPxMDARTqsvf1xg6DTpx3WGs2YpeJjKZqJ3989XCbeX1zBprZu9EiEUY0mPELAmQFQ4oaxIG/PMhcGO3WJShjLY62qgwrV9TPNe1Ib7edQ2/HY7CgWvJGHztAAaF+uLtQS3QwMW2/OdJRERE9Vat9syq1Wp06NABO3cW9s4ZDAbs3LkTXbt2LbF/8+bNcfbsWZw6dcp0efzxx9G3b1+cOnWq/tfDVlbniUCrIRXv5xIoenABMR1Xx3JqkNsMFz23AKB2MA3iKpVTA0BpI0JyWhRwZpXY3qgn4FJwP5+2InBrMwtLF8rh4aDBu+GtsPO13hj2gD9kMmDT2Vg8/PluLNx5Fbn5+oqfLxEREdU7tV5mMH36dCxevBhLly7FxYsX8dJLLyErKwvjxo0DAIwePRozZ84EANjY2KB169ZmFxcXFzg6OqJ169ZQqyvoiSRzckVh72zLxwHnBmXvq7ItDLteLQB5OW8dubxw2q6ka4UlBu1Gme8TbCw1+BuVFeBmh8+Ht8WmV3qic5AbcvMN+HzHFTzy5V7suBDPQWJERET3mVotMwCAESNGIDExEbNnz0ZcXBzatWuHrVu3mgaFRUVFQV5ecKLqCR0GHIoHer5W8b7dp4g5ZluEV7yve7CY+eDUr6LcQO1Q8n5NwoAzK0WY7TenSs1u6eeEVf95EBtP38bczRcRlZKNicv+Rc8QDzTysEd6Tj7ScvKRnqtDWk4+FDIZOgS5oluwOx5s7A4PB02VjkdERET3Jpl0n3Vlpaenw9nZGWlpafV/MFht+vs9YP+Xhb+3exYY8rX5PlnJwKfBACRg+iXAyfeuDpWVp8NXu67hh303kK+v3Nu5qbcDugV74JGW3uga7A5Z8RkciIiIqNZUJa/Ves8s1VNuxQbitRtZch97d6DBA0DMceD6TqD9s3d1KHuNEm8+2hzDOwZg7fFoKGQyONmq4GSjEte2SmTm6nD4RgoOXk/CpbgMXInPxJX4TCw5eBNt/Z3xct8m6NfCG3I5Qy0REVFdwjBLNaPotGAugUBgt9L3axImwuzVHXcdZo0aedjj9f5lr3r2SCsxQ0ZKlhZHbiRj79VErD8Zg9O30vCfX44jxMsBL/cNRngbPygVLG0hIiKqC/g/NtUM9yI9s22fKXvAWJOC1d9u7BLTeFmBm70aA0J9MW9oGxx48yFM6hsMR40SVxMyMW3VafT9fDdWHYuCTm+w6HHj0nKx7Xwc8nSceYGIiMhSWDNLNUOSgP+1BTLjgUlHANeg0vcz6IFPGgO5qcD47UBgF2u20iQ9Nx+/HIrEj/sjkJKlBQA09rDH1H5N8Viob6nlB1qdASei7kCnl9A+0AX2mpJfdEiShBNRd/DzgZvYci4OeoOE1g2c8NXIBxDkYV/jz4uIiKguqkpeY5ilmpMaDWizAK+yv/oHAKwZB5xfB/R6HXjov4Xb83OBU78BGXFAt8mAjXPNthdAjlaP345E4pvd102htrmPI2Y80gwPt/DC7bRc7L6cgN2XE3HwWhKytKKXVSmXoY2/Mx5sLGZLaOPvjJ0XE7Dk4E2cjUkzPb5GKUeezgAHjRLzhoYivK1fpdtmMEg4dCMZp6JT8XALLzT34fuXiIjqJ4bZcjDM3oNO/gb88TLg1x54YbcIwP/+DBxcIHp2AbEQw+MLCssSalhmng4/7Y/A4r03kJEnyh88HDRIyswz28/DQQONUo6Y1JwyH0utlGNIOz+M7dYIrvYqvLriJI7dvAMAGNk5EO+Gt4SNSlHm/RMycrHm31tYdSwaUSnZAMSibE+0b4Dp/ZrC39Wuuk+XiIjonsIwWw6G2XtQRhzweTPxc683gH9/BLKTxe/OAWJxhzs3xe8PjAYe+QiwKeXcabOB5KuAd2txHwtIzdZi0Z4bWHIwArn5BshlQPtAV/Rt5ok+zbzQ0tcJcrkM0SnZOHQjGYdvJOPw9WTcTsuFj5MNnuvaECM7B8LNvnBBD53egPl/X8XXu69BkkTP7/uDW8NOrUCezoA8nR55OgMycnXYdOY2dl5MgM4g/kwdNEq08nPCkYgUAIBaIcezDzbE5IeamB2jpkmShGsJmQhwsys3iBMREd0NhtlyMMzeoxb1AOLOFv7uGiQWcmjzNGDIB3a+DxxZJG5z8gcGLwQCuwLRR4Gb+4Cb+4Fb/4p9G/UChv8C2LpYrHmJGXm4FJeO0AbOcLErPzRKkoSULC2cbVXlzoqw72oipq06haRMbYXHfyDQBU93DsRjbXxhp1bidHQqPt56CQevi9DvoFFi1IOBaOnrBH9XOwS42cLTQVMj8+cmZebh7XVnsf1CPBq42OK/g1rg0dY+nKuXiIgshmG2HAyz96iDC4Ht/wXcQ4BeM4DWTwKKYgOqbu4H/phU2EurUAP6MoKgRzNg1BrAtWGNNru6EjJy8c76c/j3Zgo0SgXUSjk0Srnpum2AC57uFIhmPo4l7itJEvZdTcLHWy/h/O30ErfbqhTwd7VFaANn9G7miZ4hnqX23uZo9TgSkYx9V5NwJ0uLx9r6ok9Tr1IHvW07H4e3151Fcpb5694t2B3vhrcqtZ1ERERVxTBbDobZe5QkiWVvXRqWXyKQlylWFzu2WPzu4AM06gkE9QSCeoh62+UjgIzbgL0nMHIV4N/BKk+hthgMEjafi8Xuy4mITsnGrTs5uJ2Wg+J/2TIZ0MbfBX2aeqJjkCsuxqZj75UkHL2ZAq3OfBqyQDc7PPtgIIZ3DICLnRrpufmYs/ECfj9xC4AojfjoiVDsuZKIRXuuQ6szQCGX4bkHG2JaWFM426kqbPPqf6Ox5OBNeDvZ4NkHG+Kh5l5QcNEKIiICw2y5GGbriTuRgEEHuDUWKa2otBgRaOPPAkpbYNhioEV47bSzlmh1BtxOzcHN5CwcvpGC3ZcTcCkuo8z9fZ1t0CvEE7ZqBdaduIX0XDHoTaOUY1CoLw7fEHXAchnwQq9gTOsXAo1SfOiITsnGR5suYuv5OACAq50Ko7o0xDNdAuHnYlviWGdvpeG/f5zD6ehUs+0NXGzxTBcRoD0dNZV6nlfjM/DtnuuwVSkw9IEGeCDQleUORET1AMNsORhm7xN5GWLKr2s7AMiAfnOALi8BSgsPkkq8DORni5kYypOfC+z/EriyVbSlcR/LtqMS4tJysfdKInZfScDp6DQ09XZAzxBP9GrqgWBPB1MIzNHq8cepGCw7FIkLsYXlCw3d7fD5U23RMcit1MfffzUJc/48j6sJmQAAuQzo19Ibo7sGoVuwO9Jy8vHptstYfjQKkiTqfCc/1AR3srVYfSwad7LzAQAqhQyPtvbFuO5BeCDQtdRj5esNWLT7Ohb+cw3aIotbBLnbYegD/niifQMEuFU8y4NOb8C+q0n48/Rt+Lva4uW+TTigjYjoHsAwWw6G2fuIXgdsKZgdAQBsXICWj4t63KAe1Z/xIOYE8NOjgD4PaNIPCHsP8Gldcr+b+4E/pwDJ18TvCg0w4leg6SPVO34NMy74sPJoNFzt1ZjycEipC0MUpdMbsP1CPJYduonDN1JM24M97ZGSpTUF1iHt/PD2wBbwcrIBAOTm67H5bCx+ORyJk1Gppvs9EOiCCT0bo38rH1MJwrmYNLyx9owpaPdpJmqBt56LQ7a2cHW1zo3c0KWRG1r5OaGVnzP8XW1Ngf1qfAbWHr+FdSdjkJhRON1aIw97fPJkG3QqI7BTHXT7FHDgf8DDswG3RrXdGiKqJIbZcjDM3mckCTi6GNj3OZAZV7jdwQdo9YSY6su7ZdUfNysJ+K43kH6ryEYZ0PZpoO87gEsAkJ0C7JgNnPyl4JjegEdTMfuCXAUMXwo0H1Stp3cvuxKfgV8ORWLdiVumxSWaejvg/cGt8WBj9zLvdy4mDUsO3sTGU7dNva4BbrYY160RkjLz8N3eG9AbJLjYqfBueEsMadcAMpkMWXk6bD0Xh3Unb+Hg9eQSNcOONkq09HVCbr4ep28VLmThZq9G/1Y++OdSPOLT8yCTAaMfbIg3Hm1eYXine5wkAd/3AWJPASH9gVGra7tFRFRJDLPlYJi9Txn0QOQB4Owa4MJGsXwuAMjkQOf/AA+9A2gqORJfrwN+fQKI2Au4NwGG/SB6fs6vF7crNECb4aKkICtRbOs4Hnj4XUBtD6ybKPaVK4Ghi4HWQy3+dCuUnytmg5CXPXWYpWTk5mPj6duQQYanOvpDVc50ZUUlZOTi10OR+OVwpKlH12hQqC/ee7xVmbW1Mak52HkxHudi0nD+djquxGcgX1/4T51CLkPfZl54qqM/+jbzglopR1pOPuZuuohV/0YDAPxdbTFvaCh6NPG4J+twDQYJyVlaeDioLd6+PJ0e2Xl6uFpx7uIacXM/sKTIB8aJ/wAN6veAUKL6gmG2HAyzBJ0WuL4TOPkrcOkvsc3RDxjwf0CLx0sOKCtu2zvAoa8Alb34z9G4XG/McWDHu6Ln1cijGRD+P6Bh18Jtep2YYuzMShGmh3wrenStZd8XwO7/E8f2aCLa6NlM9Br7tr3nvorN0eqx/mQMfj4Qgcw8Hd4Nb4VHW/tU6TG0OgOuJWTi/O005Osl9GvpXWYQ3nc1EW/9ftZsVTeZDFDIZJDLZZDLABuVAr7OtmjgYgt/V3HdwNUWzrYqyGUyKOQyKOSAXCaDSiGHv6tthfMTV4YkSTh9Kw1/nr6Nv87cRnx6Hpp5O2JEpwA80b5BmeEzLi0X/0amwF6jRDt/l1L30+kNOHA9GX+evo1t5+KQkadDiJcDejf1RK+mnujcyK3O1RNLvw2H7Oo26OQaKA15uOrSHd83mIc72flIy9HC0UaF4R39EdbCu9w5oYnI+hhmy8EwS2au/Q1smiGmBQOAkEeAgZ+VPT/tud+BtePFz08tBVoNMb9dksRjHlkEBD4IdHsVUJYSmgx64K+pwIllAGRAj2miZzgnBci5A+SkArlpgFcLoP2zImRWlyQBu+YCez8pf78uLxb0It97y+RKkmSVXtKsPB0+2XoJvxyOhMFC/0J6OGjQ1NsBTb0d0cTLAQ1cbZGek4+ULC1SsrRIztIipWABDXcHNTwcNPBw1MDTQQ1HGxUOXEvCn2duIzql9KWT1Qo5+rXyxoiOAWju64ijESk4eF2sSHcjKcts3yB3O7QLcEG7ABcEuNlh1+UEbD4bh5Ssshfw0Cjl6NLYHb2beqJ3U08Ee9rfcz3WkiQhKiUbB64l4/qF45gVORYGSYbx+TPwo+ozKGQSwvM+xFmpsdn9/JxtMOrBhni6UwDcHSo3kwYR1SyG2XIwzFIJ+Tmipnb/fLGCmNIWCB0mauwa9ylcOjf+PPBDmJi9oPtUMStBdRgMYoCacc7c8vi0EfW9oU8CtqWP8C+XJAF/vyvKIQAxWK3F42I2hqTLQNJVIPGS6F0GALdg4IlFQEDnqh+rHsnK0yEnXw+DQYJBAvSSBINBQrZWj9upObiVmoOYOzmISc1BzJ1sZObpoDfua5CgN0jQ6g1mg8yqy06tQL+W3nisjR/aBbhg67lYrDwWXerCGUZyGdDSzwnZefoSwbYod3s1Bob6IrytH5p4OeDg9STsvZKIvVeSEJeea7ZvAxdb9G4mgm23YHfk6yXEpuUgNjUXsWk5uJ2Wi+w8HQLd7dHY0x7BHiLAF51LOFurw+2C/ePTxWtUdNEQ40IiSrno7VYqZAU/y5GRm4/I5GxEpWQjMjkLUSnZiEjKMj3O/ym/x9PK3fhb6oQlAR9hasbn6Ji2DRHuvXCw81dwsVXj/O00rDwWbQrxaqUc4W388EKvxpVbACQ3HchMEN9wVEK2VocbiVm4npiJ68brhEyk5+SjpZ8z2geKDxht/J3haFP+XM33Iq3OgFt3shHoZseebqo2htlyMMxSmRKvAH9NAyL3F26TK8WyuSGPAP/+JHpwG/cBRv1ecoWyuyFJwJHvRP2trYsIqsaLyg64ug24tKlwpTOFBmg2AHD2FzWvCrWYbkyhEQPMmjwM2LmVPMbWmcCRb8Xvj34MPPhi6e259jfwxyti0QmZXPQs9327ZO+yJIkeZLkCUDtUf2YIS7uyDTi+VHwAaPZobbcGmXk6XEvIxNX4DFxNyMSV+AzEpeXCxU4Fd3sN3OzVcLNXw91BfP2flJGHxEwtkjLzkJSZhztZWjTzccTjbRvgoeZesFWXfL3PxaRh9b/RWH8yBhm5OjT3cUS3YA90DXZH50ZucLYV4Sg1W4vTt9JwKioVp6Lv4GZyNjo2dEV4Wz90C3YvNYRIkoSrCZnYeyURe64k4khEyYU2KkOtkKOhux0Uchli03KRlpNf8Z2qSKWQoY+fhG+TxkAp5SN/zBaoGnUDkq4BX3cCJAPwwh7Arx0AMZPGpjOxWHroJs4UDAxUyGV4oVdjTHk4pOzSCp0WWPwQkHAe0rPrkRPQA2k5+UjNFpfYtBxEpWQjyhi4U7Ir/aFGJgNCvBzQpZE7+rfywYON3aodDvUGCVcTMnAyKhVnY9IglwHu9hp4OKjh7qCBu70aXk42aOhmV+rqf2VJyMjF7kuJ2HU5AfuuJiEzT4cgdztMfigEQ9r5ldtug0FCns6AfIMB+ToDdAYJWp0BBkmCt5NNnStrqSnXEzORmJEHpVwGpUJecC1KmHydbWCnrp8DVRlmy8EwS+WSJCBijwhDV7cXTqdl5BwIvLAbsC97NL7FZacAZ1aLWRHiz5W/r1wJNOoFtBwMNH8MsHUDNr8mgjgAPPalGIxWnpxUYOtbwOkV4nevlsADY4C0aLGUcEqEuM4v0sOnshOhVuMgQnX7Z4HQ4eXP65tyA7i0WQyiC3mk/MFoeRnAqeXiuv1zgKN36ftps8SyyMbnC4hA239u5Qf41XH5MaeRfycadq0GVVz/fZdytHocjkjGnssi3EYU9PZ6OKjh62wLH2cb+DnbwEatQGSS6DGNSM4qNQA7aJTwc7GBt5MN5DIZtDoD8nR65OkMBT8boDdI0BmM1xL0egk2agUautkh0N0ODd3s0dDdDgFudmjh6wi7ffOAfZ8B/p2BCTsKD/b7RODsaqDZQGDkihJtORWdim92XcP2C/EARDnG3CdC0a2Jh9l+Wp0BN9fPQdPz8wEA1yU/PJr3f8hHxaHC3V6NYE8HBHvZi2tPB9hrlDgbk4aTUXdwKjoVt+6Yl5K42KnQr4U3BoT6oHsTD9OCJWXJ1xsQmZyFK/GZOBeThpNRqThzK9U0q0hF7Xsw2B3dgt3RPdgDDd3tTOUk6bn5uJGYhRuJmbgSn4kD15JwNibN7P4yGUwziTR0t8Okvk3wRPsGpoGfCem52H0lEXsuJ2Lf1UTTAi3FyWRAgKsdmng5oImXA4I97dHEywEh3o5wsnCvtU5vQGJmHhIzxCWh4Do5Mw8NXG3xYGN3tPR1KjeYS5J4b1Z2gGtFIpKy8Nfp2/jzzG1cic8sd18fJxsEedihkYcDGnnYwd/VDrYq8+XR1Uo5/F3t4FCHZmhhmC0HwyxVSfJ14OoOEWzTbwNDv7NM/erdkCTg9knRnvws0TOkzyu8jr8AJJwv3F8mF+UCyVcByIDBX4mQWVmXNon5cY0zMlSVoy/w4MtAh7GFpRoGvWj/scWiF9jIoynQdTLQZgSgsincnpko6o+PLRY1xIAoA+n0vCj1cPAs3DfmhJgpwvgBpHFf4MZuAJJYJvmJ78wH4tVH0UeBJY+J90Oft4E+b1rlsClZWtipFeX2pOkNEm6n5uBGUhYMkgQ/Z1v4uthYPJhAmwV80VLMWDL8FzG3tFHiFeCbLqJ39j97y/xb3n4+DrP+OGcqWRje0R9vD2yB6JQc/H7iFk6ePIbVhhnQyPKRJ6mgkeXjo/xn8LMUDhc7FZxsVfB2tDEF7IYFgTvQza7CpZ4BIDEjDyej7uCfSwnYfiHerJbZQaNEQ3c7uNip4GyrgrOtGi52KijlMtxIzMKV+AxEJGVBV0qxt4NGiTb+zmgb4AKVQo7kzDwkZ2qRnCWub6flIDff/AOHcXDjzaQsJJTRs9zG3xl9m3mhb3MvBHva49fDUVi874ap3QFutghr4Y2jESnllsMYexxlkCEnv+zg7edsgxBvRzTzcURTb0c0dLeDu70a7vYaONkqS9RyS5KEzDwd0nLykZSpxY3EzIISD1HqcTM5y2y2k9I4apTo1MgNDzZ2Q2gDFyRm5uFGYiYikrJwIzELEUlZyMzTQSmXwVatgJ1aATu1ErYqBZr7OGJAqC96hniU+TciSRKuJ2Zi58UE/HnmNs7FFL5OKoUMAW52MBgk5Osl04e73HwDMvNK/zBQGnu1Ai/3bYLnezSqUq+33iBq0S/FpuNKfCZeeahJlXrv7xbDbDkYZqleS74OXPhDXGJPiW0yhQhybZ6q+uNlJQO75wHpMYBrI8A1SMx24BoEuASKUJCXCWgLLnmZQPQR4PC3hfP6apxEb7Ctq1jAIjWq8PEbdgfizgJ5Bf9w23sBXV4Amj4qygRO/gLoCmo13UNEKDbW9arsgE4TRAg++Ytop0EnZqZ44ltRDhKxD9jwkuhVhgzoPqX0sonSGPSiXTYuNdbDaVEpEcAPDwPZyYXb+s8Fuk6qvTbVhiPfA1teF+/XV46XLIH5fYKYoq/5Y8DTv5X5MOm5+fhk6yX8eli8X9UKecG8xxJWqD5CV8UF3HB+EIrQoWi4/w1Iantg8r+QOflZ9Ono9AYcvZmCrefisPVcXJmBsjh7tQJNvB3R3NsR7QNd0D7QFU28HMxqlovT6gw4fSsVB64l4eD1ZJyMulMi5Hk6ahDsaY/Gng5oF+CCPs084eVoU+KxsvJ0+PVwJL7fewPJxQYWtvF3Rp+mnujdzAvNfByhUsigkstNAUmSJCRlanEtQYRO4/XV+MwStdvFqRQyuNqJsp08nQFpOflIy8mHvoKRnEq5DB4OGng6auDlKK5d7dW4Gp+JIxHJyCijB7kq7NUKPNzCGwNDfdCrqSduJmXjaEQyjkSk4GhEitnrpJDL0C3YHeFt/dC/pU+ZH4JSs7Xim4+kLNxMysKNpCzEpuUiT6eHtsi3G9lavamsp4GLLd54tBkeb+tXIvjrDRIu3E7H8cgUXIrLwMW4DFyJyzD7cLHvjb6VWmGxuhhmy8EwS/eNOzeBK9vFjAiNelr32Lo8URpxcAGQdMX8NhsX0UPccTzgHiwG0ZxYJgKw2SIUBfzaAz2miwUmZHLRo7trLnD7RMEOMgAF/4y1HAw8Nt+8bjg3DdjyFnB6ufjdyV/UHKvtCy4OYuaG/BwgM77gkiB6pCWDCNgBnYGALuLi29a897jc10ELpFwHnANECUZNyU4BfnxE9ML7thVlG3s/FbeF/0/0jt8PDHpgQXsgNVLMStJ5Ysl9Ei8DX3cBIAH/2Qf4tin3If+9mYK31p3FtYRMaJRyzPY/gVFxn0BS2kI26bAoPfqxHxDzryitGVaJAZ13yWCQcDEuHQkZeUjLzi+s0c3RQqszoJFH4Vfxfs421Z5tIlurw7837yAlS4sgDzGQz9STbjBUap7qbK0OK45G41pCBjoFuaFXU094VGPGiLScfFyNz8CVeFF7fjkuA7FpOUjO1CKjgl5KtUIOV3sVGnkUlng09hQ/+7nYlhn09QYJF2PTcfhGMg7fSMaluAz4OtugkYcI9eLx7OHhoEFOvh7ZWj1ytOI6Izcf+68lYeu5OMSmlR/ENUo5OjR0xcBQXwxo7WPRmTUMBgkbT9/Gx1svmdrRPtAF/x3UArYqJQ7dSMah68k4GpFcaumHRilHMx9HNPdxxOS+IQh0Z5itVQyzRFZkMIjFI44sEoPY2o0CWg8rfdovfb5YTOLAAiD+rOhZ7TFd1AAX/09ZkkTpx665ogda7QgM/FTM11vWf+AX/xRlE0V7Lu+GQg34hIqeYvdgcXEruM5NA24dA279K65vnxJf+ctVYqq2JmHi4t2q4t7evEwg7ZYI+BnxItSXtlqdTgv88oQYuOjkD0z4G3D0Af5+DzgwH4BMLM5xNz3zdc35DcCaMaJWfNr5sqeXWzteTLNXQe+sUZ5Oj4uxGWhsmwWnH7qJEoZ+HwDdXxU7xJwQg8EgAWM3A0HdSz6ILk+UvQR0EYM9LSn5OnD9H/H+t0ZteNRhYM1YwLM5MOKXe6YePU+nF9PcZYrp7jRKOZztVHCxVcPZVgUblbz608lps0Q5T2DXyn+ohQiTp26lYsvZWGw+G4eY1BzYqxXoECSW3e7cyA1t/J0rrIeurhytHj/su4Fv91w3W/67KAeNEh2DXBHawBnNfZzQ3NcRQe725fbq1wSG2XIwzBLd4yRJ/Mdfmf8oJEn8x+oaBDj5Vrx/TqooU9BmFVwyC69VtmLwmoM34OAlrjWOQNw5UToRfUT8J5aVULXno7QFdMXmhnXwEfW7MoUI+fr8gmutaGNadOEqdUUFPyTKKoIfKhxps+ElMVhP7QiM3wr4tC58bTa/LuqNZQpg+DKgxWNVa3tVGfTidbq0Cbi8GciIA1oOET2kDR6o2WNLkpg6L+ZfoNcbYlW/siRcAr55EIAkaq8fmlW52UnWPg+cWyumypu4y/w+f04Fjv8MeLcWsyUUvS36KPDHZDENnnMgMGKZ+HBiCed+FzOQ5GeJ1c2e/f3upu+rrCvbgNWjC8t/GvYARq25J+eltrjru4A/XxWlUh7NgCHfAP4dq/wwkiQhNi0XXo6aWpvCLCE9F59vv4LVx6Nhq1KgU5Abuga748HG7mjtV/5gN2thmC0HwywR3TVJEuUbsadF+UCy8XINyE4SodG7lShL8O8kLm6NxcwN1/4Wl4h9JcNtWWycRW+rjTMQfViUPQCAVytRC5saCez5WBx31GrR61uUwSBWmzu9XPQohy8QpRiVDR7arIKyi0QR4jMTRF2yaVo4jbjWa0XP4JWtZfd8N+gIdH5BLDRSXs2yQS8GOl7fJR4z5boonWjYTQQnv3aAouCr7rxMMfvI1R3AtZ1AWpSYpm7aOfGBpDz/fFS4gEhgN+DJn8r/QHR1B/Dbk6LUZeI/JcNodgqw8AExZd2AT0Xtd14m8M+H4psJFPmvVqEBBn0OPPBc+W0sj04L7JhdOOWesdzGJxR4bgNg71HOne/S6ZXAhpcBSQ8E9RR/B3npYrDlyJVV6qmsU3JSge3viFUji5LJgW6viMGWdfS5Z+XpoFbKLTYLgyUxzJaDYZaIakRumignqCgo5ucCUQdFj69cKYKZMRwqVCK4OvsDTg0KZ4EARIg+vEjUFxedFg0QdcIdx5V+PL0OWDsOuLhR/K60BULCgObhQNP+4itvY0g3lkfcOipG/hc/TmXYuIjHbTZA1BsfXyLKRwwFc8raeYj5kI21yip7cS2Tix7MiL2l90obqezEhwRIQOShwscFREjs937Z8ygXd3696NXUZoh2DVsser2Ly4gDfugnwnLXyUD/j0p/vGM/ApumAxpn4LEvgJ1zCgc8tn0G6P2GmPP5yhaxrcNYYMAnlRuQWFT6bfE1f/QR8XuPaUCrocCvQ0Wtt2dzYPQfotzEUg59A2ybKX5u87SYHSXmOPDLUPE+afqomD2i+HR8MSeA/V8AsWdEKY5nC7EEuGcLsYy2zT3+//ClTcBf0wsHtHaaKMpL/vkQOLNKbPNoCgz+BgjoVLNtyUwU0zPGnxfXiZfFIj76fPF3oNeJa5Ud0GY40PH58j+gpUaLD9iOPuLDoo1zzba/ihhmy8EwS0R1Ws4dERCPfAdkxIoZGvq9X/59dFrRg3t2tflsEnKl6GG8c7PsKdhUdoC9Z2H5hUIl/vPU5RVODSfpRc9r84GiltDYc2qUmQCcWAoc+0ksyFERjTPQuJfo8fNqKXpqIw8AkQfFks9FuQYBTfoBIf2AoB5iUF9VJF8XdbZxZwHIgN5vit5rU2nJEdGzDogSgUmHyz6GQQ983weIO1O4zTkQCP+ysNfcYBArDu76CIAkSgOGLxOzcOSliR7enFTxPA160eOnshNlMEpbsXDLhpfE+dI4i5k7mg8Sj510FVj6uHiN3YKBMRvFByOjxMvApb9Er7fGUZR+NOgg3gNllSZIEvDPB6LNgJhu75GPCgd/RewTPda6XLGq4JM/ixKLqMNiEGLRKfhK491a1PqGDi97/mhLyM8RwTTygHhOcoX4RkOuEB+kZLKCMGi85IsPDdf/Efd3CxYBvmG3wse8tFksS54ZLx6j1RPiMXNTxYfb3DQxwNUlQLw/Qx4RJSrl1e1KkvjwlHSl4HJVlKckXBTHqQq5UryXu7woPgDKZGKGmgvrgbNrgahDhfvK5OIbkKCeYpxC4IO1XgvNMFsOhlkiqhd0WlFm4BFS+ftIkghaF/8SA+ISLxbeJleJ/8z8O4keJp+2osfGkrMw6HViVbukq6JHSZtVcJ0twpBXSyC4L+D3QOk1rAaD+I/dGEga9xW9fdUd1JOfIxYKOb6kjB1kInSFz6+4RjL6qJhZAgC6/EfU45b2Gl79G/j9eRF85CrxgcBYRlIZ3q1FCHYPNt+eEiECbVqUmD5v4GfiQ8ClTQVzTpfBLbig3lomzkV+jrjOTRNLXQPiufR8reTrfe1vYMVIUW7SbJAoPbi5T9wmU4hewtCnxIDGxEsimCVeEh/GjGQK0WPfdqRY1KKir+3TbonnFXlQvHZ+D4hw7tWy8MOUsab+9AoxODAvrdyHLJVMUVBK8Jb4QFFcdorobT+zsnKP5+AtPnw17i1er/TbYurD9NvikhpVOFVhycaIsiXvVqKcxKuF+CZEoRLB1fhNT9IVMUVd1MHCu/q1F98+3Nglwrrx8QI6i9Kg4gsEyVVA2xFA92mVXq7Z0hhmy8EwS0RUIOmaKCtwDxY9RnW07s9izqwGNs8Qodu/Q8F0bA+KAFuVGQhijgNKGxE6ypMSAax+rqBXuIDKXkwtZ+sqwokuVwT+/BxRomLIB0KfFMtSl1XSkhoNLHu8sEfZSKEGGvUWJSC6PNHOmOOit7c8Mjkw6IuyS1kA4PIWYNWzhUFJrgLajxID7NwalX6frGTgwgZRi3vraOF2jbMoQXD0FoMljdcoCKc394sPcqVR2ogPZZ7NRclK0efmHCgW0dA4il5vSV94bWyzKRQqxe/BDxUOqizP9V2ip1PjJL6uN17UDkDcafHh5cbuypXuyORinmSPpuLDqkdT8Xy8WlTtw2XsaRFqz64R36IY+bYVHy5aDQWcG4ht6bfF6xqxV3wQuXPT2BjxmvWYbloC2loYZsvBMEtERGUyGEQPaWVmN7DU8e5EiNIFW9eq18+WJSMO+PVJEUpC+omZLJr0K71GNTtF1LYmXRZBTmlTUNZQcO3epOxAWtTFP4G/54gA2P1V8xKHiiRdEz2op1eWPt90cTJFwdfi3UVIjzkOxJws2fuqsheDDtuOFIu0VGJu3BqjyxM9yVd3iPBu4ww4+YkSEyc/USfv3ED0vlrqfQAAWUnitdXlibKDynybE31M1Dpf3ly4Lfhh0TPfsJtVFpJhmC0HwywREd0XDAVlC7UZ4KrKYBBzR6dFi/mVM+MKr3V5ope8YQ8gsEvJmk6DQcx+EXNcDJLybgW0CK96HTUVij8P7P9STAFnLIN5Zg3Q9JEaPzTDbDkYZomIiIiqIOWGWNAm8iDw0kGrfHNRlbxmpe9RiIiIiKhOcmssBkDqddYrwamCOvTdAxERERHVmnswyAIMs0RERERUhzHMEhEREVGdxTBLRERERHUWwywRERER1VkMs0RERERUZzHMEhEREVGdxTBLRERERHUWwywRERER1VkMs0RERERUZzHMEhEREVGdxTBLRERERHUWwywRERER1VkMs0RERERUZzHMEhEREVGdxTBLRERERHUWwywRERER1VkMs0RERERUZylruwHWJkkSACA9Pb2WW0JEREREpTHmNGNuK899F2YzMjIAAAEBAbXcEiIiIiIqT0ZGBpydncvdRyZVJvLWIwaDAbdv34ajoyNkMlmNHy89PR0BAQGIjo6Gk5NTjR+PagbPY/3A81g/8DzWDzyP9UNNnUdJkpCRkQE/Pz/I5eVXxd53PbNyuRz+/v5WP66TkxP/WOsBnsf6geexfuB5rB94HuuHmjiPFfXIGnEAGBERERHVWQyzRERERFRnMczWMI1Gg3fffRcajaa2m0LVwPNYP/A81g88j/UDz2P9cC+cx/tuABgRERER1R/smSUiIiKiOothloiIiIjqLIZZIiIiIqqzGGaJiIiIqM5imK1hX3/9NYKCgmBjY4MuXbrg6NGjtd0kKse8efPQqVMnODo6wsvLC0OGDMHly5fN9snNzcWkSZPg7u4OBwcHDBs2DPHx8bXUYqrI//3f/0Emk2Hq1KmmbTyHdUNMTAyeffZZuLu7w9bWFqGhofj3339Nt0uShNmzZ8PX1xe2trYICwvD1atXa7HFVJxer8esWbPQqFEj2NraIjg4GB988AGKjj3nebz37N27F+Hh4fDz84NMJsOGDRvMbq/MOUtJScGoUaPg5OQEFxcXPP/888jMzKyR9jLM1qBVq1Zh+vTpePfdd3HixAm0bdsW/fv3R0JCQm03jcqwZ88eTJo0CYcPH8aOHTuQn5+PRx55BFlZWaZ9pk2bhj///BNr1qzBnj17cPv2bQwdOrQWW01lOXbsGL777ju0adPGbDvP4b3vzp076N69O1QqFbZs2YILFy7g888/h6urq2mfTz75BAsWLMCiRYtw5MgR2Nvbo3///sjNza3FllNRH3/8Mb799lt89dVXuHjxIj7++GN88sknWLhwoWkfnsd7T1ZWFtq2bYuvv/661Nsrc85GjRqF8+fPY8eOHfjrr7+wd+9evPDCCzXTYIlqTOfOnaVJkyaZftfr9ZKfn580b968WmwVVUVCQoIEQNqzZ48kSZKUmpoqqVQqac2aNaZ9Ll68KAGQDh06VFvNpFJkZGRIISEh0o4dO6TevXtLU6ZMkSSJ57CuePPNN6UePXqUebvBYJB8fHykTz/91LQtNTVV0mg00ooVK6zRRKqEQYMGSePHjzfbNnToUGnUqFGSJPE81gUApPXr15t+r8w5u3DhggRAOnbsmGmfLVu2SDKZTIqJibF4G9kzW0O0Wi2OHz+OsLAw0za5XI6wsDAcOnSoFltGVZGWlgYAcHNzAwAcP34c+fn5Zue1efPmCAwM5Hm9x0yaNAmDBg0yO1cAz2FdsXHjRnTs2BFPPfUUvLy80L59eyxevNh0e0REBOLi4szOo7OzM7p06cLzeA/p1q0bdu7ciStXrgAATp8+jf3792PAgAEAeB7rosqcs0OHDsHFxQUdO3Y07RMWFga5XI4jR45YvE1Kiz8iAQCSkpKg1+vh7e1ttt3b2xuXLl2qpVZRVRgMBkydOhXdu3dH69atAQBxcXFQq9VwcXEx29fb2xtxcXG10EoqzcqVK3HixAkcO3asxG08h3XDjRs38O2332L69Ol4++23cezYMbz66qtQq9UYM2aM6VyV9m8sz+O946233kJ6ejqaN28OhUIBvV6Pjz76CKNGjQIAnsc6qDLnLC4uDl5eXma3K5VKuLm51ch5ZZglKsOkSZNw7tw57N+/v7abQlUQHR2NKVOmYMeOHbCxsant5tBdMhgM6NixI+bOnQsAaN++Pc6dO4dFixZhzJgxtdw6qqzVq1fjt99+w/Lly9GqVSucOnUKU6dOhZ+fH88jWQzLDGqIh4cHFApFiRHS8fHx8PHxqaVWUWVNnjwZf/31F3bt2gV/f3/Tdh8fH2i1WqSmpprtz/N67zh+/DgSEhLwwAMPQKlUQqlUYs+ePViwYAGUSiW8vb15DusAX19ftGzZ0mxbixYtEBUVBQCmc8V/Y+9tr7/+Ot566y08/fTTCA0NxXPPPYdp06Zh3rx5AHge66LKnDMfH58Sg911Oh1SUlJq5LwyzNYQtVqNDh06YOfOnaZtBoMBO3fuRNeuXWuxZVQeSZIwefJkrF+/Hv/88w8aNWpkdnuHDh2gUqnMzuvly5cRFRXF83qPePjhh3H27FmcOnXKdOnYsSNGjRpl+pnn8N7XvXv3EtPiXblyBQ0bNgQANGrUCD4+PmbnMT09HUeOHOF5vIdkZ2dDLjePGor/b+9uQqJa4ziO/07XGh3NnJJMhKEkMSuKorehNuUiDaLEiERidCOTJW6iwJKMClrZIkgoyhZKgtGLRS9Q1iLBrDAVMmkREaj0RmRmbuZ/F8HQ3Lr3yr3peOj7gQMz5zzq7+FZ+OPM4/GPPxQOhyWxjm40ljULBAL6+PGjnjx5EhnT2tqqcDis1atX//pQv/xPyhDR1NRkHo/Hzp8/b8+ePbOysjJLSUmxwcHBWEfD39i1a5fNmDHD7t+/bwMDA5Hjy5cvkTGhUMj8fr+1trba48ePLRAIWCAQiGFq/Jvvn2Zgxhq6QUdHh8XFxdmxY8fsxYsX1tjYaF6v1xoaGiJjjh8/bikpKXb16lXr7u62LVu22Lx582xkZCSGyfG9YDBoGRkZdv36dXv58qVdunTJUlNTbd++fZExrOPkMzQ0ZJ2dndbZ2WmSrLa21jo7O+3Vq1dmNrY1y8vLs2XLltnDhw/twYMHlpWVZUVFReOSlzI7zk6ePGl+v9+mTZtmq1atsvb29lhHwj+Q9NOjvr4+MmZkZMTKy8vN5/OZ1+u1goICGxgYiF1o/Ku/llnW0B2uXbtmixcvNo/HYwsWLLDTp09HXQ+Hw1ZdXW1paWnm8XgsNzfX+vr6YpQWP/Pp0yerrKw0v99v8fHxlpmZaQcOHLDR0dHIGNZx8rl3795PfxcGg0EzG9uavX//3oqKiiwpKcmSk5OttLTUhoaGxiWvY/bdv+EAAAAAXIQ9swAAAHAtyiwAAABcizILAAAA16LMAgAAwLUoswAAAHAtyiwAAABcizILAAAA16LMAgAAwLUoswDwm3IcR1euXIl1DAD4XyizABADJSUlchznhyMvLy/W0QDAVeJiHQAAfld5eXmqr6+POufxeGKUBgDciTuzABAjHo9Hc+bMiTp8Pp+kb1sA6urqlJ+fr4SEBGVmZurixYtRX9/T06MNGzYoISFBs2bNUllZmT5//hw15ty5c1q0aJE8Ho/S09O1Z8+eqOvv3r1TQUGBvF6vsrKy1NLSMr6TBoBfjDILAJNUdXW1CgsL1dXVpeLiYu3YsUO9vb2SpOHhYW3cuFE+n0+PHj1Sc3Oz7ty5E1VW6+rqtHv3bpWVlamnp0ctLS2aP39+1M84fPiwtm/fru7ubm3atEnFxcX68OHDhM4TAP4Px8ws1iEA4HdTUlKihoYGxcfHR52vqqpSVVWVHMdRKBRSXV1d5NqaNWu0fPlynTp1SmfOnNH+/fv1+vVrJSYmSpJu3LihzZs3q7+/X2lpacrIyFBpaamOHj360wyO4+jgwYM6cuSIpG8FOSkpSTdv3mTvLgDXYM8sAMTI+vXro8qqJM2cOTPyOhAIRF0LBAJ6+vSpJKm3t1dLly6NFFlJWrt2rcLhsPr6+uQ4jvr7+5Wbm/uPGZYsWRJ5nZiYqOTkZL158+a/TgkAJhxlFgBiJDEx8YeP/X+VhISEMY2bOnVq1HvHcRQOh8cjEgCMC/bMAsAk1d7e/sP7nJwcSVJOTo66uro0PDwcud7W1qYpU6YoOztb06dP19y5c3X37t0JzQwAE407swAQI6OjoxocHIw6FxcXp9TUVElSc3OzVqxYoXXr1qmxsVEdHR06e/asJKm4uFiHDh1SMBhUTU2N3r59q4qKCu3cuVNpaWmSpJqaGoVCIc2ePVv5+fkaGhpSW1ubKioqJnaiADCOKLMAECO3bt1Senp61Lns7Gw9f/5c0rcnDTQ1Nam8vFzp6em6cOGCFi5cKEnyer26ffu2KisrtXLlSnm9XhUWFqq2tjbyvYLBoL5+/aoTJ05o7969Sk1N1bZt2yZuggAwAXiaAQBMQo7j6PLly9q6dWusowDApMaeWQAAALgWZRYAAACuxZ5ZAJiE2AEGAGPDnVkAAAC4FmUWAAAArkWZBQAAgGtRZgEAAOBalFkAAAC4FmUWAAAArkWZBQAAgGtRZgEAAOBafwIYBYbkVFZYDQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history_reg.history['loss'], label='Training Loss')\n",
    "plt.plot(history_reg.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Regularized Model Training vs. Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ada8fa-f3e5-4985-9972-9218c1242261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
